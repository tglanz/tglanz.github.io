{"pageProps":{"article":{"id":"computer-science/probabalistic-method","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/computer-science/probabalistic-method.md","metadata":{"title":"The Probabilistic Method","description":null,"priority":0,"tags":["Probabilistic Method","Probability","Algorithms"],"categories":["Computer Science","Probabilistic Method"],"toc":true},"content":{"raw":"\n# Introduction\n\nIn this page we will discuss the probabilistic method which is a powerful tool to prove the existence of a combinatorial object. For a long time we have used conventional approaches for this purpose - Either we provided a proof by contruction or we provided a non-constructive proof. The probabilistic method is a non-constructive method first introduced by [Paul Erdos](https://en.wikipedia.org/wiki/Paul_Erd%C5%91s) while he was working on the development of the [Ramsey Theory](https://en.wikipedia.org/wiki/Ramsey_theory).\n\nIn essence, the method shows that the probability that some object with the desired property exist is greater than 0 and therefore one such instance surely exist, otherwise the probability was strictly 0. \n\nWe will use many practical examples and uses of this method which we will link to throughout this page.\n\n# Probability Background\n\nBefore we continue we need to review some basic probability concepts.\n\n### Definition\n\nA **probability space** is a triplet $(\\Omega, \\Sigma, Pr)$ where\n\n1. $\\Omega$ is a non-empty set known as the **sample space**. It represents all possible outcomes of some experiment.\n    - We will limit ourselves to a finite sample space.\n\n2. $\\Sigma$ is the collection of subsets of $\\Omega$ which is closed under the **complement ($x'$)**, **union ($x \\cup y$)** and **intersection ($x \\cap y$)** operations.\n    - An element $A \\in \\Sigma$ is called an **event**.\n\n3. $Pr : \\Sigma \\rightarrow [0, 1]$ is a function with the following properties:\n    - $Pr(\\Omega) = 1$\n    - $\\forall A, B \\in \\Sigma ; A \\cap B = \\phi \\implies Pr(A) + Pr(B) = Pr(A \\cup B)$\n    - $\\forall \\omega \\in \\Omega ; $  we will denote $Pr(\\omega) = Pr(\\\\{\\omega\\\\})$\n\n> Methematically, a probability space is a measure space with the measure function over $\\Omega$ where $\\Sigma$ is the $\\sigma$-algebra over $\\Omega$ and $Pr$ is the measure of the space such that $Pr(\\Omega) = 1$.\n\n### Union Bound\n\nThe measue function is sub-additive with respect to the union operation. Meaning, every two events $A, B$ satisfies $Pr(A \\cup B) \\leq Pr(A) + Pr(B)$.\n\nIt makes sense, if the two events are not disjointed, the intersection part must be calculated once, not twice as is calculated in $Pr(A) + $Pr(B)$.\n\nMore generally, the **Union Bound** theorem states that for any set of events $\\\\{ A_i \\\\}$ it holds that:\n\n$$\n  Pr(\\bigcup_i A_i) \\leq \\sum_i Pr(A_i)\n$$\n\n### Conditional Probability\n\nThe probability of some event $A$, given that we know that the event $B$ happened is called the **conditional probability of $A$ given $B$** and is notated and given by\n\n$$\n  Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)}\n$$\n\nThis definition is intuitive. The probability $A$ happens given $B$ happens is firstly at the intersection between them. Then, we scale this probability of the intersection to limit ourselves to the \"world\" of $B$ only.\n\nAnother variant of this definition is known as the **product rule**:\n\n$$\n  Pr(A \\cap B) = Pr(A | B) Pr(B)\n$$\n\nLet's see an example - Consider the experiment of rolling a six-sided die and let $A$ be the event that the number $2$ was thrown and $B$ the event that an even number was thrown. Formally, $A = \\\\{ 2 \\\\}, B = \\\\{2, 4, 6 \\\\}$. It is obvious that $Pr(A) = \\frac{1}{6}$ and $Pr(B) = \\frac{3}{6} = \\frac{1}{2}$. Intuitively, the probability that $A$ given $B$ is $\\frac{1}{3}$ since if we know an even number was rolled it means that one of three numbers 2, 4 and 6 were rolled - from those, the probability that 2 was rolled is $\\frac{1}{3}$. We can verify the intuition using the formula: $Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)} = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}$.\n\nNow, what happens when what we know about $B$ doesn't affect $A$? For example, consider $A$ to be the result of a die roll and $B$ the event that it is Sunday - the result of the roll is not affected by the day of week at all. Such events are called **independent**, let's define it:\n\nTwo events $A$ and $B$ such that $Pr(A | B) = Pr(A)$ are said to be **independent**.\n\nFor two independent events $A$ and $B$ we can see that:\n\n$$\n    Pr(A) = Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)} \\implies Pr(A)Pr(B) = Pr(A \\cap B)\n$$\n\nUsing a bit of algebra, we can get the **very** important rule, **Bayes Rule** which states that if we can always invert the conditional causality:\n\n$$\n    Pr(A | B) = \\frac{Pr(B | A) Pr(A)}{Pr(B)}\n$$\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <nav class=\"toc\">\n      <ol class=\"toc-level toc-level-1\">\n        <li class=\"toc-item toc-item-h1\"><a class=\"toc-link toc-link-h1\" href=\"#introduction\">Introduction</a></li>\n        <li class=\"toc-item toc-item-h1\"><a class=\"toc-link toc-link-h1\" href=\"#probability-background\">Probability Background</a></li>\n      </ol>\n    </nav>\n    <h1 id=\"introduction\">Introduction</h1>\n    <p>In this page we will discuss the probabilistic method which is a powerful tool to prove the existence of a combinatorial object. For a long time we have used conventional approaches for this purpose - Either we provided a proof by contruction or we provided a non-constructive proof. The probabilistic method is a non-constructive method first introduced by <a href=\"https://en.wikipedia.org/wiki/Paul_Erd%C5%91s\">Paul Erdos</a> while he was working on the development of the <a href=\"https://en.wikipedia.org/wiki/Ramsey_theory\">Ramsey Theory</a>.</p>\n    <p>In essence, the method shows that the probability that some object with the desired property exist is greater than 0 and therefore one such instance surely exist, otherwise the probability was strictly 0.</p>\n    <p>We will use many practical examples and uses of this method which we will link to throughout this page.</p>\n    <h1 id=\"probability-background\">Probability Background</h1>\n    <p>Before we continue we need to review some basic probability concepts.</p>\n    <h3 id=\"definition\">Definition</h3>\n    <p>A <strong>probability space</strong> is a triplet $(\\Omega, \\Sigma, Pr)$ where</p>\n    <ol>\n      <li>\n        <p>$\\Omega$ is a non-empty set known as the <strong>sample space</strong>. It represents all possible outcomes of some experiment.</p>\n        <ul>\n          <li>We will limit ourselves to a finite sample space.</li>\n        </ul>\n      </li>\n      <li>\n        <p>$\\Sigma$ is the collection of subsets of $\\Omega$ which is closed under the <strong>complement ($x'$)</strong>, <strong>union ($x \\cup y$)</strong> and <strong>intersection ($x \\cap y$)</strong> operations.</p>\n        <ul>\n          <li>An element $A \\in \\Sigma$ is called an <strong>event</strong>.</li>\n        </ul>\n      </li>\n      <li>\n        <p>$Pr : \\Sigma \\rightarrow [0, 1]$ is a function with the following properties:</p>\n        <ul>\n          <li>$Pr(\\Omega) = 1$</li>\n          <li>$\\forall A, B \\in \\Sigma ; A \\cap B = \\phi \\implies Pr(A) + Pr(B) = Pr(A \\cup B)$</li>\n          <li>$\\forall \\omega \\in \\Omega ; $ we will denote $Pr(\\omega) = Pr(\\{\\omega\\})$</li>\n        </ul>\n      </li>\n    </ol>\n    <blockquote>\n      <p>Methematically, a probability space is a measure space with the measure function over $\\Omega$ where $\\Sigma$ is the $\\sigma$-algebra over $\\Omega$ and $Pr$ is the measure of the space such that $Pr(\\Omega) = 1$.</p>\n    </blockquote>\n    <h3 id=\"union-bound\">Union Bound</h3>\n    <p>The measue function is sub-additive with respect to the union operation. Meaning, every two events $A, B$ satisfies $Pr(A \\cup B) \\leq Pr(A) + Pr(B)$.</p>\n    <p>It makes sense, if the two events are not disjointed, the intersection part must be calculated once, not twice as is calculated in $Pr(A) + $Pr(B)$.</p>\n    <p>More generally, the <strong>Union Bound</strong> theorem states that for any set of events $\\{ A_i \\}$ it holds that:</p>\n    <p>\n      $$\n      Pr(\\bigcup_i A_i) \\leq \\sum_i Pr(A_i)\n      $$\n    </p>\n    <h3 id=\"conditional-probability\">Conditional Probability</h3>\n    <p>The probability of some event $A$, given that we know that the event $B$ happened is called the <strong>conditional probability of $A$ given $B$</strong> and is notated and given by</p>\n    <p>\n      $$\n      Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)}\n      $$\n    </p>\n    <p>This definition is intuitive. The probability $A$ happens given $B$ happens is firstly at the intersection between them. Then, we scale this probability of the intersection to limit ourselves to the \"world\" of $B$ only.</p>\n    <p>Another variant of this definition is known as the <strong>product rule</strong>:</p>\n    <p>\n      $$\n      Pr(A \\cap B) = Pr(A | B) Pr(B)\n      $$\n    </p>\n    <p>Let's see an example - Consider the experiment of rolling a six-sided die and let $A$ be the event that the number $2$ was thrown and $B$ the event that an even number was thrown. Formally, $A = \\{ 2 \\}, B = \\{2, 4, 6 \\}$. It is obvious that $Pr(A) = \\frac{1}{6}$ and $Pr(B) = \\frac{3}{6} = \\frac{1}{2}$. Intuitively, the probability that $A$ given $B$ is $\\frac{1}{3}$ since if we know an even number was rolled it means that one of three numbers 2, 4 and 6 were rolled - from those, the probability that 2 was rolled is $\\frac{1}{3}$. We can verify the intuition using the formula: $Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)} = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}$.</p>\n    <p>Now, what happens when what we know about $B$ doesn't affect $A$? For example, consider $A$ to be the result of a die roll and $B$ the event that it is Sunday - the result of the roll is not affected by the day of week at all. Such events are called <strong>independent</strong>, let's define it:</p>\n    <p>Two events $A$ and $B$ such that $Pr(A | B) = Pr(A)$ are said to be <strong>independent</strong>.</p>\n    <p>For two independent events $A$ and $B$ we can see that:</p>\n    <p>\n      $$\n      Pr(A) = Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)} \\implies Pr(A)Pr(B) = Pr(A \\cap B)\n      $$\n    </p>\n    <p>Using a bit of algebra, we can get the <strong>very</strong> important rule, <strong>Bayes Rule</strong> which states that if we can always invert the conditional causality:</p>\n    <p>\n      $$\n      Pr(A | B) = \\frac{Pr(B | A) Pr(A)}{Pr(B)}\n      $$\n    </p>\n  </body>\n</html>\n"}}},"__N_SSG":true}