1:HL["/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
2:HL["/_next/static/css/c96322cf68b97bcb.css","style",{"crossOrigin":""}]
0:["nxCzmbBHqy4Lsw2WZKC_7",[[["",{"children":["articles",{"children":[["slug","kubernetes/simple-on-prem-cluster","c"],{"children":["__PAGE__?{\"slug\":[\"kubernetes\",\"simple-on-prem-cluster\"]}",{}]}]}]},"$undefined","$undefined",true],"$L3",[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/c96322cf68b97bcb.css","precedence":"next","crossOrigin":""}]],"$L4"]]]]
5:HL["/_next/static/css/1cb3813e458884a4.css","style",{"crossOrigin":""}]
6:I[5420,["326","static/chunks/326-dcee1ff54fa4f70c.js","185","static/chunks/app/layout-ce4e325d1f63f2a3.js"],""]
7:I[6954,[],""]
8:I[7264,[],""]
b:I[8326,["954","static/chunks/d3ac728e-1e5d8b71e3d43fec.js","326","static/chunks/326-dcee1ff54fa4f70c.js","496","static/chunks/app/articles/%5B...slug%5D/page-d876e1e9a9f10cb2.js"],""]
c:T518,M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z3:[null,["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__className_e66fe9 Layout_body__oXsmr","children":[["$","header",null,{"className":"Layout_header__XC_Gv","children":["$","$L6",null,{}]}],["$","main",null,{"className":"Layout_main__luTTh","children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"initialChildNode":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","articles","children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","initialChildNode":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","articles","children",["slug","kubernetes/simple-on-prem-cluster","c"],"children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","initialChildNode":["$L9","$La",null],"childPropSegment":"__PAGE__?{\"slug\":[\"kubernetes\",\"simple-on-prem-cluster\"]}","styles":[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/1cb3813e458884a4.css","precedence":"next","crossOrigin":""}]]}],"childPropSegment":["slug","kubernetes/simple-on-prem-cluster","c"],"styles":null}],"childPropSegment":"articles","styles":null}]}],["$","footer",null,{"children":["$","div",null,{"className":"Footer_container__Z8cUU","children":[["$","$Lb",null,{"href":"https://il.linkedin.com/in/tal-glanzman","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 448 512","children":["$undefined",[["$","path","0",{"d":"M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z","children":"$undefined"}]]],"className":"$undefined","style":{"color":"$undefined"},"height":25,"width":25,"xmlns":"http://www.w3.org/2000/svg"}]}],["$","$Lb",null,{"href":"https://github.com/tglanz","children":["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 496 512","children":["$undefined",[["$","path","0",{"d":"$c","children":"$undefined"}]]],"className":"$undefined","style":{"color":"$undefined"},"height":25,"width":25,"xmlns":"http://www.w3.org/2000/svg"}]}]]}]}]]}]}],null]
4:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Article"}],["$","meta","3",{"name":"description","content":"Personal site"}],["$","link","4",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"256x256"}],["$","meta","5",{"name":"next-size-adjust"}]]
d:I[6222,["954","static/chunks/d3ac728e-1e5d8b71e3d43fec.js","326","static/chunks/326-dcee1ff54fa4f70c.js","496","static/chunks/app/articles/%5B...slug%5D/page-d876e1e9a9f10cb2.js"],"ArticleContent"]
e:T1731,
# Kubes

Deploy a kubernetes cluster.

We will setup a simple kubernetes cluster will describe the concepts and process.

The OS on all nodes is debian bullseye - I specifically executing this using vagrant's box ```debian/bullseye64```.

To document the steps we will provide bash script snippets for now. But, the goal is to provide configuration files content for something like ansible or chef.

## Container runtime

Kubernetes is an orchestration infrastructure and does not provide any containerization - It relies on a different containarization platform, a.k.a the [Container Runtime](https://kubernetes.io/docs/setup/production-environment/container-runtimes/).

We will use [docker](https://www.docker.com/). Let's install it by following the documentation [Here](https://docs.docker.com/engine/install/debian/).

```
sudo apt-get remove docker docker-engine docker.io containerd runc

sudo apt-get update
sudo apt-get install ca-certificates curl gnupg lsb-release

curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io
```

Another thing to do is docker to utilize systemd for cgroup management (You can read more about it in the container runtimes documentation). To apply this setting we need to edit docker's configuration. There are multiple to do so, for example - edit systemd's service that initiates docker. Another approach is to edit docker's global configuration file which is at ```/etc/docker/daemon.json```. Hence, edit (create if missing) the mentioned file and add

```json
{
    ... other configurations
    "exec-opts": ["native.cgroupdriver=systemd", ... more exec opts if exists]
}
```

Once done, reboot docker by running ```sudo systemctl restart docker```

## Kube Components

We will not rely on the package manager to install the components.

Define the relevant variables

> Note that the cni directory does not include the version! Later we will install a network plugin, it'll be in the same directory

```
ARCH="amd64"
CNI_VERSION="v0.8.2"
CNI_DIR="/opt/cni/bin"
CRICTL_VERSION="v1.23.0"
CRICTL_DIR="/opt/cri/$CRICTL_VERSION/bin"
KUBERNETES_VERSION="v1.23.3"
KUBERNETES_DIR="/opt/kubernetes/$KUBERNETES_VERSION"

# Install [CNI](https://www.cni.dev/)

sudo mkdir -p $CNI_DIR
curl -L "https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz" | sudo tar -C $CNI_DIR -xz

# Install [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)

sudo mkdir -p $CRICTL_DIR
curl -L "https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz" | sudo tar -C $CRICTL_DIR -xz

# Install Kube components

sudo mkdir -p $KUBERNETES_DIR
cd $KUBERNETES_DIR
for component in kubeadm kubectl kubelet; do
  sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/$KUBERNETES_VERSION/bin/linux/$ARCH/$component
  sudo chmod +x $component
done

# and services

RELEASE_VERSION="v0.4.0"
curl -sSL "https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service" | sed "s:/usr/bin:${KUBERNETES_DIR}:g" | sudo tee /etc/systemd/system/kubelet.service
sudo mkdir -p /etc/systemd/system/kubelet.service.d
curl -sSL "https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf" | sed "s:/usr/bin:${KUBERNETES_DIR}:g" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
```

enable, and start kubelet

```
sudo systemctl enable --now kubelet
```

## Initialization

Install prerequesites for kubeadm

```
sudo apt-get update 
sudo apt install ethtool socat conntrack
```

Create an update alternative

```
sudo update-alternatives --install /usr/bin/kubeadm kubeadm $KUBERNETES_DIR/kubeadm 100
sudo update-alternatives --install /usr/bin/kubelet kubelet $KUBERNETES_DIR/kubelet 100
sudo update-alternatives --install /usr/bin/kubectl kubectl $KUBERNETES_DIR/kubectl 100
```

Run @controlplane

> TODO: load balancer, hostnames

Initialize configuration such that the network is 10.10.0.0/16

```
sudo kubeadm init --pod-network-cidr 10.10.0.0/16 --apiserver-advertise-address {ip}
```

For documentation, you should see something like

```
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.121.210:6443 --token clns4a.b29f6anjipygy0e2 \
	--discovery-token-ca-cert-hash sha256:833f599cc9ab27eb5010c499e9c77e8e3263fb991d8e9e78ef187ba97e1efb59
```

Do as it says, run

```
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

We will use [Weave Net](https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/) as a network plugin

```
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
```
f:T1e24,<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
    <nav class="toc">
      <ol class="toc-level toc-level-1">
        <li class="toc-item toc-item-h1"><a class="toc-link toc-link-h1" href="#kubes">Kubes</a>
          <ol class="toc-level toc-level-2">
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#container-runtime">Container runtime</a></li>
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#kube-components">Kube Components</a></li>
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#initialization">Initialization</a></li>
          </ol>
        </li>
      </ol>
    </nav>
    <h1 id="kubes">Kubes</h1>
    <p>Deploy a kubernetes cluster.</p>
    <p>We will setup a simple kubernetes cluster will describe the concepts and process.</p>
    <p>The OS on all nodes is debian bullseye - I specifically executing this using vagrant's box <code>debian/bullseye64</code>.</p>
    <p>To document the steps we will provide bash script snippets for now. But, the goal is to provide configuration files content for something like ansible or chef.</p>
    <h2 id="container-runtime">Container runtime</h2>
    <p>Kubernetes is an orchestration infrastructure and does not provide any containerization - It relies on a different containarization platform, a.k.a the <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">Container Runtime</a>.</p>
    <p>We will use <a href="https://www.docker.com/">docker</a>. Let's install it by following the documentation <a href="https://docs.docker.com/engine/install/debian/">Here</a>.</p>
    <pre><code>sudo apt-get remove docker docker-engine docker.io containerd runc

sudo apt-get update
sudo apt-get install ca-certificates curl gnupg lsb-release

curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io
</code></pre>
    <p>Another thing to do is docker to utilize systemd for cgroup management (You can read more about it in the container runtimes documentation). To apply this setting we need to edit docker's configuration. There are multiple to do so, for example - edit systemd's service that initiates docker. Another approach is to edit docker's global configuration file which is at <code>/etc/docker/daemon.json</code>. Hence, edit (create if missing) the mentioned file and add</p>
    <pre><code class="hljs language-json"><span class="hljs-punctuation">{</span>
    ... other configurations
    <span class="hljs-attr">"exec-opts"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">"native.cgroupdriver=systemd"</span><span class="hljs-punctuation">,</span> ... more exec opts if exists<span class="hljs-punctuation">]</span>
<span class="hljs-punctuation">}</span>
</code></pre>
    <p>Once done, reboot docker by running <code>sudo systemctl restart docker</code></p>
    <h2 id="kube-components">Kube Components</h2>
    <p>We will not rely on the package manager to install the components.</p>
    <p>Define the relevant variables</p>
    <blockquote>
      <p>Note that the cni directory does not include the version! Later we will install a network plugin, it'll be in the same directory</p>
    </blockquote>
    <pre><code>ARCH="amd64"
CNI_VERSION="v0.8.2"
CNI_DIR="/opt/cni/bin"
CRICTL_VERSION="v1.23.0"
CRICTL_DIR="/opt/cri/$CRICTL_VERSION/bin"
KUBERNETES_VERSION="v1.23.3"
KUBERNETES_DIR="/opt/kubernetes/$KUBERNETES_VERSION"

# Install [CNI](https://www.cni.dev/)

sudo mkdir -p $CNI_DIR
curl -L "https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz" | sudo tar -C $CNI_DIR -xz

# Install [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)

sudo mkdir -p $CRICTL_DIR
curl -L "https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz" | sudo tar -C $CRICTL_DIR -xz

# Install Kube components

sudo mkdir -p $KUBERNETES_DIR
cd $KUBERNETES_DIR
for component in kubeadm kubectl kubelet; do
  sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/$KUBERNETES_VERSION/bin/linux/$ARCH/$component
  sudo chmod +x $component
done

# and services

RELEASE_VERSION="v0.4.0"
curl -sSL "https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service" | sed "s:/usr/bin:${KUBERNETES_DIR}:g" | sudo tee /etc/systemd/system/kubelet.service
sudo mkdir -p /etc/systemd/system/kubelet.service.d
curl -sSL "https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf" | sed "s:/usr/bin:${KUBERNETES_DIR}:g" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</code></pre>
    <p>enable, and start kubelet</p>
    <pre><code>sudo systemctl enable --now kubelet
</code></pre>
    <h2 id="initialization">Initialization</h2>
    <p>Install prerequesites for kubeadm</p>
    <pre><code>sudo apt-get update 
sudo apt install ethtool socat conntrack
</code></pre>
    <p>Create an update alternative</p>
    <pre><code>sudo update-alternatives --install /usr/bin/kubeadm kubeadm $KUBERNETES_DIR/kubeadm 100
sudo update-alternatives --install /usr/bin/kubelet kubelet $KUBERNETES_DIR/kubelet 100
sudo update-alternatives --install /usr/bin/kubectl kubectl $KUBERNETES_DIR/kubectl 100
</code></pre>
    <p>Run @controlplane</p>
    <blockquote>
      <p>TODO: load balancer, hostnames</p>
    </blockquote>
    <p>Initialize configuration such that the network is 10.10.0.0/16</p>
    <pre><code>sudo kubeadm init --pod-network-cidr 10.10.0.0/16 --apiserver-advertise-address {ip}
</code></pre>
    <p>For documentation, you should see something like</p>
    <pre><code>Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.121.210:6443 --token clns4a.b29f6anjipygy0e2 \
	--discovery-token-ca-cert-hash sha256:833f599cc9ab27eb5010c499e9c77e8e3263fb991d8e9e78ef187ba97e1efb59
</code></pre>
    <p>Do as it says, run</p>
    <pre><code>mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre>
    <p>We will use <a href="https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/">Weave Net</a> as a network plugin</p>
    <pre><code>kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
</code></pre>
  </body>
</html>
a:["$","div",null,{"className":"article-page_container__5yaZl","children":[["$","h1",null,{"children":"Simple on-prem Kuberenetes cluster"}],["$","div",null,{"className":"Taxonomy_container__C2Vdb","children":["$","div",null,{"className":"Taxonomy_values__yvK16","children":[["$","$Lb","0",{"href":"/tags/Kubernetes","children":["$","div",null,{"className":"Chip_container__q1AW2","children":"Kubernetes"}]}]]}]}],["$","$Ld",null,{"content":{"raw":"$e","html":"$f"}}]]}]
9:null
