{"pageProps":{"content":{"articles":[{"id":"about","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/about.md","metadata":{"title":"About","description":null,"permalink":null,"priority":0,"tags":[],"categories":[]},"content":{"raw":"\nThis site was made by [Me](https://github.com/tglanz) using [NextJS](https://nextjs.org/). The source repository can be found [Here](https://github.com/tglanz/tglanz.github.io). I initially used [jekyll](https://jekyllrb.com/), then [hugo](https://gohugo.io/).\n\nThe site is still in development:\n- Article content styling\n- Comment sections\n- General site styling","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>This site was made by <a href=\"https://github.com/tglanz\">Me</a> using <a href=\"https://nextjs.org/\">NextJS</a>. The source repository can be found <a href=\"https://github.com/tglanz/tglanz.github.io\">Here</a>. I initially used <a href=\"https://jekyllrb.com/\">jekyll</a>, then <a href=\"https://gohugo.io/\">hugo</a>.</p>\n    <p>The site is still in development:</p>\n    <ul>\n      <li>Article content styling</li>\n      <li>Comment sections</li>\n      <li>General site styling</li>\n    </ul>\n  </body>\n</html>\n"}},{"id":"algorithms/bloom","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/algorithms/bloom.md","metadata":{"title":"Bloom Filter","description":"Illustrate the Bloomfilter data structure","permalink":null,"priority":0,"tags":[],"categories":["Algorithms","Probabalistic Datastructures"]},"content":{"raw":"\n## Summary\n\nA _Bloom Filter_ is an data structure that given a set of elements $S$ and a subset $X \\subset S$, answers the question whether some element $s \\in S$ is in $X$.\n\nThe main difference between this and standard data structures using sets and lists is in the fact that this is a probabilistic data structure. Specifically, it can return False Positives but never False Negatives.\n\n|           | Positive      | Negative\n|-----------|---------------|---------\n| **True**  | Always        | Always\n| **False** | Probabilistic | Never\n\nA standard implementation of _Bloom Filters_ support adding elements to $X$ but does not support removal requiring the application to reconstruct the data structure accordingly.\n\n_Bloom Filter_ provides a more efficient memory usage than most other constructs such as lists and sets in the cost of a chance for False Positives.\n\nTo illustrate, consider the following interface\n\n```c#\ninterface BloomFilter<S> {\n    // Add {element} to the container\n    void add(S element);\n\n    // Determines whether {element} is in the container\n    bool contains(S element);\n}\n```\n\n## Implementation\n\n- Set __A__ to be an $m$ bits bit array.\n- Set __H__ to be a set of $k$ functions mapping $S$ onto $\\\\{1, 2, ..., m \\\\}$\n\n__add(x)__\n\nApply all hash functions of $H$ on $x$ and set the corresponding bit in $A$ to 1.\n\n- $\\forall h \\in H$  \n  - $A[h(x)] \\leftarrow 1$\n\n__contains(x)__\n\nApply all hash functions of $H$ on $x$ and return true if and only if all of the corresponding bits in $A$ are set to 1.\n\n- $\\forall h \\in H$\n  - $A[h(x)] = 1 \\Rightarrow True$\n\nNow we can easily understand where the False Positives comes from.\n\n## False Positives\n\nAssume \n\n- $S = \\\\{x_1, x_2, x_3\\\\}$\n- $m=5$\n- $k=2$\n\nWith the hash functions  \n\n- $h_1(x_1)=1 ~~ h_1(x_2)=3 ~~ h_1(x_3)=3$\n- $h_2(x_1)=4 ~~ h_2(x_2)=1 ~~ h_2(x_3)=4$\n\nAnd the scenario of $X = \\\\{x_1, x_2\\\\}$ as shown below\n\n| 1 | 2 | 3 | 4 | 5 |\n|:-:|:-:|:-:|:-:|:-:|\n|$x_1, x_2$||$x_2$|$x_1$||\n\nApplying __contains($x_3$)__ will yield a False Positive.\n\nWhat was the chance of that happening?\n\nAssuming equal distribution of the hash functions, the probability that a specific bit is unset after applying $k$ functions on an element is $(1 - \\frac {1}{m})^k \\approx e^{-\\frac{k}{m}}$ for large $m$.\n\nNow we can conclude that after the addition of $n$ elements (using __add(x)__) to the data structure the probability for a specific bit to be unset is $e^{-\\frac{kn}{m}}$ and for it to be set is $1 - e^{-\\frac{kn}{m}}$.\n\nFor the containment check to return true it is enough for $k$ specific bits to be set. From the above, the probability for this is $(1 - e^{-\\frac{kn}{m}})^k$.\n\n__To summarize, the probability for a _False Positive_ is $(1 - e^{-\\frac{kn}{m}})^k$.__\n\n## Picking the hash functions\n\n[This paper](https://www.eecs.harvard.edu/~michaelm/postscripts/tr-02-05.pdf) describes a technique of constructing a set of $k$ hash functions based upon exactly 2 hash functions $h_1$ and $h_2$.\n\nThe usefulness of this approach relies in the fact that not all scenarios require the same number of hash functions $k$. Thus, allowing us to provide only 2 base functions $h_1$ and $h_2$ and construct a set of hash functions for any arbitrary $k$.\n\nThere they describe a partitioning of the bit array, each partition of a primary size $p$, such that each hash function maps to $\\\\{ 1, 2, ..., p \\\\}$ within it's own unique partition. (Note that this is just a restatement of the original view).\n\nNow, forall $i$ we can have\n$$\n    g_i(x) = h_1(x) + ih_2(x) \\mod p\n$$\n\n> The paper discusses a lot more and more in-depth","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h2>Summary</h2>\n    <p>A <em>Bloom Filter</em> is an data structure that given a set of elements $S$ and a subset $X \\subset S$, answers the question whether some element $s \\in S$ is in $X$.</p>\n    <p>The main difference between this and standard data structures using sets and lists is in the fact that this is a probabilistic data structure. Specifically, it can return False Positives but never False Negatives.</p>\n    <table>\n      <thead>\n        <tr>\n          <th></th>\n          <th>Positive</th>\n          <th>Negative</th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <td><strong>True</strong></td>\n          <td>Always</td>\n          <td>Always</td>\n        </tr>\n        <tr>\n          <td><strong>False</strong></td>\n          <td>Probabilistic</td>\n          <td>Never</td>\n        </tr>\n      </tbody>\n    </table>\n    <p>A standard implementation of <em>Bloom Filters</em> support adding elements to $X$ but does not support removal requiring the application to reconstruct the data structure accordingly.</p>\n    <p><em>Bloom Filter</em> provides a more efficient memory usage than most other constructs such as lists and sets in the cost of a chance for False Positives.</p>\n    <p>To illustrate, consider the following interface</p>\n    <pre><code class=\"hljs language-c#\"><span class=\"hljs-keyword\">interface</span> <span class=\"hljs-title\">BloomFilter</span>&#x3C;<span class=\"hljs-title\">S</span>> {\n    <span class=\"hljs-comment\">// Add {element} to the container</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">add</span>(<span class=\"hljs-params\">S element</span>)</span>;\n\n    <span class=\"hljs-comment\">// Determines whether {element} is in the container</span>\n    <span class=\"hljs-function\"><span class=\"hljs-built_in\">bool</span> <span class=\"hljs-title\">contains</span>(<span class=\"hljs-params\">S element</span>)</span>;\n}\n</code></pre>\n    <h2>Implementation</h2>\n    <ul>\n      <li>Set <strong>A</strong> to be an $m$ bits bit array.</li>\n      <li>Set <strong>H</strong> to be a set of $k$ functions mapping $S$ onto $\\{1, 2, ..., m \\}$</li>\n    </ul>\n    <p><strong>add(x)</strong></p>\n    <p>Apply all hash functions of $H$ on $x$ and set the corresponding bit in $A$ to 1.</p>\n    <ul>\n      <li>$\\forall h \\in H$\n        <ul>\n          <li>$A[h(x)] \\leftarrow 1$</li>\n        </ul>\n      </li>\n    </ul>\n    <p><strong>contains(x)</strong></p>\n    <p>Apply all hash functions of $H$ on $x$ and return true if and only if all of the corresponding bits in $A$ are set to 1.</p>\n    <ul>\n      <li>$\\forall h \\in H$\n        <ul>\n          <li>$A[h(x)] = 1 \\Rightarrow True$</li>\n        </ul>\n      </li>\n    </ul>\n    <p>Now we can easily understand where the False Positives comes from.</p>\n    <h2>False Positives</h2>\n    <p>Assume</p>\n    <ul>\n      <li>$S = \\{x_1, x_2, x_3\\}$</li>\n      <li>$m=5$</li>\n      <li>$k=2$</li>\n    </ul>\n    <p>With the hash functions</p>\n    <ul>\n      <li>$h_1(x_1)=1 ~~ h_1(x_2)=3 ~~ h_1(x_3)=3$</li>\n      <li>$h_2(x_1)=4 ~~ h_2(x_2)=1 ~~ h_2(x_3)=4$</li>\n    </ul>\n    <p>And the scenario of $X = \\{x_1, x_2\\}$ as shown below</p>\n    <table>\n      <thead>\n        <tr>\n          <th align=\"center\">1</th>\n          <th align=\"center\">2</th>\n          <th align=\"center\">3</th>\n          <th align=\"center\">4</th>\n          <th align=\"center\">5</th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <td align=\"center\">$x_1, x_2$</td>\n          <td align=\"center\"></td>\n          <td align=\"center\">$x_2$</td>\n          <td align=\"center\">$x_1$</td>\n          <td align=\"center\"></td>\n        </tr>\n      </tbody>\n    </table>\n    <p>Applying <strong>contains($x_3$)</strong> will yield a False Positive.</p>\n    <p>What was the chance of that happening?</p>\n    <p>Assuming equal distribution of the hash functions, the probability that a specific bit is unset after applying $k$ functions on an element is $(1 - \\frac {1}{m})^k \\approx e^{-\\frac{k}{m}}$ for large $m$.</p>\n    <p>Now we can conclude that after the addition of $n$ elements (using <strong>add(x)</strong>) to the data structure the probability for a specific bit to be unset is $e^{-\\frac{kn}{m}}$ and for it to be set is $1 - e^{-\\frac{kn}{m}}$.</p>\n    <p>For the containment check to return true it is enough for $k$ specific bits to be set. From the above, the probability for this is $(1 - e^{-\\frac{kn}{m}})^k$.</p>\n    <p><strong>To summarize, the probability for a <em>False Positive</em> is $(1 - e^{-\\frac{kn}{m}})^k$.</strong></p>\n    <h2>Picking the hash functions</h2>\n    <p><a href=\"https://www.eecs.harvard.edu/~michaelm/postscripts/tr-02-05.pdf\">This paper</a> describes a technique of constructing a set of $k$ hash functions based upon exactly 2 hash functions $h_1$ and $h_2$.</p>\n    <p>The usefulness of this approach relies in the fact that not all scenarios require the same number of hash functions $k$. Thus, allowing us to provide only 2 base functions $h_1$ and $h_2$ and construct a set of hash functions for any arbitrary $k$.</p>\n    <p>There they describe a partitioning of the bit array, each partition of a primary size $p$, such that each hash function maps to $\\{ 1, 2, ..., p \\}$ within it's own unique partition. (Note that this is just a restatement of the original view).</p>\n    <p>\n      Now, forall $i$ we can have\n      $$\n      g_i(x) = h_1(x) + ih_2(x) \\mod p\n      $$\n    </p>\n    <blockquote>\n      <p>The paper discusses a lot more and more in-depth</p>\n    </blockquote>\n  </body>\n</html>\n"}},{"id":"algorithms/dynamic-programming/longest-increasing-subsequence","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/algorithms/dynamic-programming/longest-increasing-subsequence.md","metadata":{"title":"Longest increasing subsequence","description":null,"permalink":null,"priority":0,"tags":["Dynamic Programming"],"categories":["Algorithms"]},"content":{"raw":"\n\n**The problem**\n\nGiven a sequence of numbers $N$, find the length of longest subsequence of numbers that is increasing\n\n**Illustration**\n\n- [1, 2, 3, 4] $\\rightarrow$ [1, 2, 3, 4]\n- [1, 4, 2, 6, 3, 7] $\\rightarrow$ [1, 4, 6, 7]\n\n**Solution**\n\nlet $(a_i)_{i=1}^n = N$.\n\n$a_i$ can contribute to a subsequence of previous elements only if it is greater than all those elements.\n\nWe can also realize the the longest increasing subsequence that ends with $a_i$ is the previous longest subsequence containing elements less that $a_i$, adding $a_i$ to it.\n\nWe shall define opt(i) to indicate the length of the longest increasing subsequence that ends with $a_i$.\n\nTrivially,\n$$\nopt(0) = 0\n$$\n\nRecursively,\n$$\n\\forall i > 0; ~ opt(i) = 1 + \\max \\\\{ \\\\{0\\\\} \\cup \\\\{ opt(j) | j < i \\land a_j < a_i \\\\} \\\\}\n$$\n\n**Psuedo**\n\n- Initialize opt\n  - $opt \\leftarrow array(n+1)$\n  - $opt[0] \\leftarrow 0$\n\n- Build opt in a bottom up fashion\n  - $for ~ i = 1, 2, ... n$\n    - $opt[i] = 1 + \\max_{j < i \\land a_j < a_i}{opt[j]}$\n- Return the final answer\n  - $ans \\leftarrow 0$\n  - $for ~ i = 1, 2, ... n$\n    - $ans \\leftarrow max \\\\{ ans, opt[i] \\\\}$\n  - Return $ans$\n\n\n**Time Complexity**\n\n- Initialization of opt is $O(1)$ (single access to opt)\n  - We exclude the actual array creation\n- Building opt takes $O(n)$ iterations\n  - Each iteration takes $O(n)$ accesses at the worst case\n\nSo in total, the time complexity is $O(n^2)$\n\n**Finding the subsequence using a Journal**\n\nWe will keep another data structure $S$ that will act as the journal.\n\nFor each $i$, $S$ will contain the index $j$ that contains the previous element in the subsequence.\n\nWe can fill it during the algorithm by modifying \"Build opt in a bottom up fashion\" to be\n\n- Build opt in a bottom up fashion\n  - $for ~ i = 1, 2, ... n$\n    - $opt[i] = 1 + \\max_{j < i \\land a_j < a_i}{opt[j]}$\n    - $S[i] = $ the $j$ that achieved the max\n\nFinally, to print we shall go back from the position of the result using the indices at the journal. \n\n**Finding the subsequence using Traceback**\n\nLets review an example.\n\nAssume $N=[3, 4, 2, 7, 5]$\n\nThe final tabulation of opt will be\n\ni|0|1|2|3|4|5\n-|-|-|-|-|-|-\n$a_i$| |3|4|2|7|5\nopt(i)|0|1|2|1|3|2\n\nHere, we need to find $7 \\leftarrow 4 \\leftarrow 3$. Specifically\n- $opt(\"7\") = 3, opt(\"4\") = 2, opt(\"3\") = 1$\n\nGenerally, to traceback, we shall find the index i that contains the maximum of opt as we did finding the answer. We notice that the previous element in the relevant subsequence is ending a subsequence of length $opt(i) - 1$. So we traverse back in the opt array until we find an element $a_j$ such that $a_j < a_i$ and $opt(j) = opt(i) - 1$. This $j$ is the index of the previous element in the answer. We will keep going in this manner until index 0. \n\n**Actual Code**\n\n{{<codepen RwVdYyO>}}","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p><strong>The problem</strong></p>\n    <p>Given a sequence of numbers $N$, find the length of longest subsequence of numbers that is increasing</p>\n    <p><strong>Illustration</strong></p>\n    <ul>\n      <li>[1, 2, 3, 4] $\\rightarrow$ [1, 2, 3, 4]</li>\n      <li>[1, 4, 2, 6, 3, 7] $\\rightarrow$ [1, 4, 6, 7]</li>\n    </ul>\n    <p><strong>Solution</strong></p>\n    <p>let $(a_i)_{i=1}^n = N$.</p>\n    <p>$a_i$ can contribute to a subsequence of previous elements only if it is greater than all those elements.</p>\n    <p>We can also realize the the longest increasing subsequence that ends with $a_i$ is the previous longest subsequence containing elements less that $a_i$, adding $a_i$ to it.</p>\n    <p>We shall define opt(i) to indicate the length of the longest increasing subsequence that ends with $a_i$.</p>\n    <p>\n      Trivially,\n      $$\n      opt(0) = 0\n      $$\n    </p>\n    <p>\n      Recursively,\n      $$\n      \\forall i > 0; ~ opt(i) = 1 + \\max \\{ \\{0\\} \\cup \\{ opt(j) | j &#x3C; i \\land a_j &#x3C; a_i \\} \\}\n      $$\n    </p>\n    <p><strong>Psuedo</strong></p>\n    <ul>\n      <li>\n        <p>Initialize opt</p>\n        <ul>\n          <li>$opt \\leftarrow array(n+1)$</li>\n          <li>$opt[0] \\leftarrow 0$</li>\n        </ul>\n      </li>\n      <li>\n        <p>Build opt in a bottom up fashion</p>\n        <ul>\n          <li>$for ~ i = 1, 2, ... n$\n            <ul>\n              <li>$opt[i] = 1 + \\max_{j &#x3C; i \\land a_j &#x3C; a_i}{opt[j]}$</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>\n        <p>Return the final answer</p>\n        <ul>\n          <li>$ans \\leftarrow 0$</li>\n          <li>$for ~ i = 1, 2, ... n$\n            <ul>\n              <li>$ans \\leftarrow max \\{ ans, opt[i] \\}$</li>\n            </ul>\n          </li>\n          <li>Return $ans$</li>\n        </ul>\n      </li>\n    </ul>\n    <p><strong>Time Complexity</strong></p>\n    <ul>\n      <li>Initialization of opt is $O(1)$ (single access to opt)\n        <ul>\n          <li>We exclude the actual array creation</li>\n        </ul>\n      </li>\n      <li>Building opt takes $O(n)$ iterations\n        <ul>\n          <li>Each iteration takes $O(n)$ accesses at the worst case</li>\n        </ul>\n      </li>\n    </ul>\n    <p>So in total, the time complexity is $O(n^2)$</p>\n    <p><strong>Finding the subsequence using a Journal</strong></p>\n    <p>We will keep another data structure $S$ that will act as the journal.</p>\n    <p>For each $i$, $S$ will contain the index $j$ that contains the previous element in the subsequence.</p>\n    <p>We can fill it during the algorithm by modifying \"Build opt in a bottom up fashion\" to be</p>\n    <ul>\n      <li>Build opt in a bottom up fashion\n        <ul>\n          <li>$for ~ i = 1, 2, ... n$\n            <ul>\n              <li>$opt[i] = 1 + \\max_{j &#x3C; i \\land a_j &#x3C; a_i}{opt[j]}$</li>\n              <li>$S[i] = $ the $j$ that achieved the max</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n    <p>Finally, to print we shall go back from the position of the result using the indices at the journal.</p>\n    <p><strong>Finding the subsequence using Traceback</strong></p>\n    <p>Lets review an example.</p>\n    <p>Assume $N=[3, 4, 2, 7, 5]$</p>\n    <p>The final tabulation of opt will be</p>\n    <table>\n      <thead>\n        <tr>\n          <th>i</th>\n          <th>0</th>\n          <th>1</th>\n          <th>2</th>\n          <th>3</th>\n          <th>4</th>\n          <th>5</th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <td>$a_i$</td>\n          <td></td>\n          <td>3</td>\n          <td>4</td>\n          <td>2</td>\n          <td>7</td>\n          <td>5</td>\n        </tr>\n        <tr>\n          <td>opt(i)</td>\n          <td>0</td>\n          <td>1</td>\n          <td>2</td>\n          <td>1</td>\n          <td>3</td>\n          <td>2</td>\n        </tr>\n      </tbody>\n    </table>\n    <p>Here, we need to find $7 \\leftarrow 4 \\leftarrow 3$. Specifically</p>\n    <ul>\n      <li>$opt(\"7\") = 3, opt(\"4\") = 2, opt(\"3\") = 1$</li>\n    </ul>\n    <p>Generally, to traceback, we shall find the index i that contains the maximum of opt as we did finding the answer. We notice that the previous element in the relevant subsequence is ending a subsequence of length $opt(i) - 1$. So we traverse back in the opt array until we find an element $a_j$ such that $a_j &#x3C; a_i$ and $opt(j) = opt(i) - 1$. This $j$ is the index of the previous element in the answer. We will keep going in this manner until index 0.</p>\n    <p><strong>Actual Code</strong></p>\n    <p>{{}}</p>\n  </body>\n</html>\n"}},{"id":"algorithms/dynamic-programming/longest-path-in-ordered-graph","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/algorithms/dynamic-programming/longest-path-in-ordered-graph.md","metadata":{"title":"Longest Path in Ordered Graph","description":null,"permalink":null,"priority":0,"tags":["Dynamic Programming"],"categories":["Algorithms"]},"content":{"raw":"\nA directed graph $G=(V, E)$ is **ordererd**  \n\nif\n$$\n  \\forall (v_i, v_j) \\in E \\Rightarrow i < j\n$$\n\nand\n$$\n  \\forall v_i \\in V / \\\\{ v_n \\\\} ~;~ \\exists j>i, e=(v_i, v_j) \\in E\n$$\n\n**The problem**\n\nGiven such graph, find the length of the longest path from $v_1$ to $v_n$ where $n = |V|$.\n\n**Illustration**\n\n{{< mermaid >}}\n  graph LR\n    v1 --> v2\n    v3 --> v4\n    v4 --> v5\n    v1 --> v4\n    v2 --> v4\n    v2 --> v5\n{{</ mermaid >}}\n\nFor this example, the longest path is $(v_1, v_2) \\rightarrow (v_2, v_4) \\rightarrow (v_4, v_5)$.\n\n**Solution**\n\nWe shall define $opt(i)$ to indicate the length of the longest path from $v_1$ to $v_i$ by\n\n$$\n  opt(0) = 0\n$$\n\n$$\n  opt(i)_{1 > 0} = 1 + \\max \\\\{ opt(k) | (v_k, v_i) \\in E \\\\}\n$$\n\nThe answer we are looking for is given by $opt(n)$.\n\nThe intuition here is breaking the problem into smaller subproblems. The most straight forward way of doing so is by starting from $v_1$ and incrementally adding more vertices into consideration.\n\n**Psuedo**\n\nAs always, pseudo is very important in dynamic programming algorithms in order to illustrate pattenr of building the data structure (bottom up).\n\n- Initialize opt\n  - $opt \\leftarrow array(n)$\n  - $opt[0] \\leftarrow 0$\n  - $\\forall i \\in \\\\{ 1, 2, ..., n \\\\}$\n    - $opt[i] \\leftarrow nil$\n- Build opt in a bottom up fashion\n  - $for ~ i \\leftarrow 1 ~ to ~ n$\n    - $opt[i] \\leftarrow 1 + \\max \\\\{ opt(k) | (v_k, v_i) \\in E \\\\}$\n- Return $opt[n]$\n\n**Time Complexity**\n\n- Initialization of opt is $O(n)$\n- Building opt takes $O(n)$ iterations\n  - Each iteration takes $O(n)$ accesses to opt\n\nSo in total, the time complexity is $O(n^2)$","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>A directed graph $G=(V, E)$ is <strong>ordererd</strong></p>\n    <p>\n      if\n      $$\n      \\forall (v_i, v_j) \\in E \\Rightarrow i &#x3C; j\n      $$\n    </p>\n    <p>\n      and\n      $$\n      \\forall v_i \\in V / \\{ v_n \\} <del>;</del> \\exists j>i, e=(v_i, v_j) \\in E\n      $$\n    </p>\n    <p><strong>The problem</strong></p>\n    <p>Given such graph, find the length of the longest path from $v_1$ to $v_n$ where $n = |V|$.</p>\n    <p><strong>Illustration</strong></p>\n    <p>\n      {{&#x3C; mermaid >}}\n      graph LR\n      v1 --> v2\n      v3 --> v4\n      v4 --> v5\n      v1 --> v4\n      v2 --> v4\n      v2 --> v5\n      {{&#x3C;/ mermaid >}}\n    </p>\n    <p>For this example, the longest path is $(v_1, v_2) \\rightarrow (v_2, v_4) \\rightarrow (v_4, v_5)$.</p>\n    <p><strong>Solution</strong></p>\n    <p>We shall define $opt(i)$ to indicate the length of the longest path from $v_1$ to $v_i$ by</p>\n    <p>\n      $$\n      opt(0) = 0\n      $$\n    </p>\n    <p>\n      $$\n      opt(i)_{1 > 0} = 1 + \\max \\{ opt(k) | (v_k, v_i) \\in E \\}\n      $$\n    </p>\n    <p>The answer we are looking for is given by $opt(n)$.</p>\n    <p>The intuition here is breaking the problem into smaller subproblems. The most straight forward way of doing so is by starting from $v_1$ and incrementally adding more vertices into consideration.</p>\n    <p><strong>Psuedo</strong></p>\n    <p>As always, pseudo is very important in dynamic programming algorithms in order to illustrate pattenr of building the data structure (bottom up).</p>\n    <ul>\n      <li>Initialize opt\n        <ul>\n          <li>$opt \\leftarrow array(n)$</li>\n          <li>$opt[0] \\leftarrow 0$</li>\n          <li>$\\forall i \\in \\{ 1, 2, ..., n \\}$\n            <ul>\n              <li>$opt[i] \\leftarrow nil$</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>Build opt in a bottom up fashion\n        <ul>\n          <li>$for ~ i \\leftarrow 1 ~ to ~ n$\n            <ul>\n              <li>$opt[i] \\leftarrow 1 + \\max \\{ opt(k) | (v_k, v_i) \\in E \\}$</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>Return $opt[n]$</li>\n    </ul>\n    <p><strong>Time Complexity</strong></p>\n    <ul>\n      <li>Initialization of opt is $O(n)$</li>\n      <li>Building opt takes $O(n)$ iterations\n        <ul>\n          <li>Each iteration takes $O(n)$ accesses to opt</li>\n        </ul>\n      </li>\n    </ul>\n    <p>So in total, the time complexity is $O(n^2)$</p>\n  </body>\n</html>\n"}},{"id":"algorithms/dynamic-programming/longest-substring-that-is-a-palindrom","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/algorithms/dynamic-programming/longest-substring-that-is-a-palindrom.md","metadata":{"title":"Longest substring that is a Palindrom","description":null,"permalink":null,"priority":0,"tags":["Dynamic Programming","Palindrom"],"categories":["Algorithms"]},"content":{"raw":"\n# Overview\n\nA string $S$ is a palindrom iff $S = reverse(S)$\n\n**The Problem**\n\nGiven a string S, find the longest *substring* of S that is also a palindrom\n\n> Remember that substrings are consequtive\n\n**To illustrate**\n\n- a**bcb**ea $\\rightarrow$ bcb (not abcba)\n- **abbcbba**dad $\\rightarrow$ abbcbba\n\n# Solution\n\nWe shall define $opt(i, j)$ to indicate the length of the longest palindrom substring between the i'th character to the j'th character by the recurrence relation\n\nfor all i, opt(i, i) = true since a single character is a palindrom of itself.\n\nfor all i and $j > i$, opt(i, j) true if S[i] = S[j] and also opt(i + 1, j - 1) = true.\n\nFinally, to figure out the length of the longest substring that is a palindrom we need to find i and j that maximizes $j - i$ and such that opt(i, j) = true.\n\n**Psuedo**\n\n- Initialize opt\n  - $opt \\leftarrow matrix(n, n)$\n    - initialize all values false by default\n    - $\\forall i$\n      - $opt(i, i) = true$\n      - $opt(i, i + 1) \\leftarrow S[i]=S[i+1]$\n\n- Build opt in a bottom up fashion\n  - $for ~ l = 2, 3, ... n - 1$\n    - $for ~ i = 1, ..., n - l$\n      - $j \\leftarrow i +  - 1$\n      - $opt(i, j) \\leftarrow S[i] = S[j] \\land opt(i + 1, j - 1)$\n- Find the length of the longest substring that is a palindrom\n  - $for~ l = n-1, n-2, ..., 1$\n    - $for~ i = 1, 2, ..., n - l$\n      - $if~ opt(i, i + l)$\n        - return l\n\n**Time Complexity**\n\n- Initialization of opt is $O(n^2)$\n- Building opt takes $O(n^2)$ iterations\n  - Each iteration takes $O(1)$ accesses to opt\n\nSo in total, the time complexity is $O(n^2)$","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Overview</h1>\n    <p>A string $S$ is a palindrom iff $S = reverse(S)$</p>\n    <p><strong>The Problem</strong></p>\n    <p>Given a string S, find the longest <em>substring</em> of S that is also a palindrom</p>\n    <blockquote>\n      <p>Remember that substrings are consequtive</p>\n    </blockquote>\n    <p><strong>To illustrate</strong></p>\n    <ul>\n      <li>a<strong>bcb</strong>ea $\\rightarrow$ bcb (not abcba)</li>\n      <li><strong>abbcbba</strong>dad $\\rightarrow$ abbcbba</li>\n    </ul>\n    <h1>Solution</h1>\n    <p>We shall define $opt(i, j)$ to indicate the length of the longest palindrom substring between the i'th character to the j'th character by the recurrence relation</p>\n    <p>for all i, opt(i, i) = true since a single character is a palindrom of itself.</p>\n    <p>for all i and $j > i$, opt(i, j) true if S[i] = S[j] and also opt(i + 1, j - 1) = true.</p>\n    <p>Finally, to figure out the length of the longest substring that is a palindrom we need to find i and j that maximizes $j - i$ and such that opt(i, j) = true.</p>\n    <p><strong>Psuedo</strong></p>\n    <ul>\n      <li>\n        <p>Initialize opt</p>\n        <ul>\n          <li>$opt \\leftarrow matrix(n, n)$\n            <ul>\n              <li>initialize all values false by default</li>\n              <li>$\\forall i$\n                <ul>\n                  <li>$opt(i, i) = true$</li>\n                  <li>$opt(i, i + 1) \\leftarrow S[i]=S[i+1]$</li>\n                </ul>\n              </li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>\n        <p>Build opt in a bottom up fashion</p>\n        <ul>\n          <li>$for ~ l = 2, 3, ... n - 1$\n            <ul>\n              <li>$for ~ i = 1, ..., n - l$\n                <ul>\n                  <li>$j \\leftarrow i + - 1$</li>\n                  <li>$opt(i, j) \\leftarrow S[i] = S[j] \\land opt(i + 1, j - 1)$</li>\n                </ul>\n              </li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n      <li>\n        <p>Find the length of the longest substring that is a palindrom</p>\n        <ul>\n          <li>$for~ l = n-1, n-2, ..., 1$\n            <ul>\n              <li>$for~ i = 1, 2, ..., n - l$\n                <ul>\n                  <li>$if~ opt(i, i + l)$\n                    <ul>\n                      <li>return l</li>\n                    </ul>\n                  </li>\n                </ul>\n              </li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n    <p><strong>Time Complexity</strong></p>\n    <ul>\n      <li>Initialization of opt is $O(n^2)$</li>\n      <li>Building opt takes $O(n^2)$ iterations\n        <ul>\n          <li>Each iteration takes $O(1)$ accesses to opt</li>\n        </ul>\n      </li>\n    </ul>\n    <p>So in total, the time complexity is $O(n^2)$</p>\n  </body>\n</html>\n"}},{"id":"aws/best-practices","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/aws/best-practices.md","metadata":{"title":"AWS, Best practices","description":null,"permalink":null,"priority":0,"tags":[],"categories":["AWS"]},"content":{"raw":"\n### Do not use the root acount for any task that is not required to be performed by a root user\n\nWhat else can we do then? Create a different user and specifically control permissions.\n\nEven ceating an Administrator user is good - The point is, the use the account owner.","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h3>Do not use the root acount for any task that is not required to be performed by a root user</h3>\n    <p>What else can we do then? Create a different user and specifically control permissions.</p>\n    <p>Even ceating an Administrator user is good - The point is, the use the account owner.</p>\n  </body>\n</html>\n"}},{"id":"aws/bullets","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/aws/bullets.md","metadata":{"title":"AWS, Bullets","description":null,"permalink":null,"priority":0,"tags":[],"categories":["AWS"]},"content":{"raw":"\n# Available Storage Types\n\n- Block\n    - EBS\n- File\n    - EFS\n    - FSx Lustre\n    - FSx Windows\n- Block\n    - S3\n    - Glacier\n\n# EBS Volume Types\n\n**EBS** is a block storage.\n\nIt provides one of the following volume types, with the following categories\n\n- Solid state (SSD)\n    - General Purpose SSD - Provides a sane cost/performance balance\n    - Provisioned IOPS SSD - High performance, mission-critical, low latency and high-throughput\n- Hard disk drives (HDD)\n    - Throughput Optimized HDD - Low cost HDD for throughput intensive workloads\n    - Cold HDD - Lowest cost HDD for less frequently accessed workloads\n- Previous generation\n\n# ELB\n\n- Application Load Balancer (ALB) - Works at application layer (layer 7 osi) HTTP/HTTPS\n    - Host based routing - Balance using the host and port portion of the url (scheme://host:port/path)\n    - Path based routing - Balance using the path portion of the url (scheme://host:port/path)\n\n- Network Load Balancer (NLB) - Works at the network layer (layer 4 osi) IP\n\n# Route53 routing policies\n\n- Simple Round Robin - Route the user in a round robin fashion accross servers\n- Weighted - Weight precentage of routes for each server\n- Geolocation - Route the user to the geographically nearest server\n\n# EC2 Instance Types\n\n- General Purpose (m4)\n- Compute Optimized\n- Memory Optimized\n- Accelerated Computing - Using hardware accelerators\n- Storage Optimized\n- High Memory - Acquired only using special request\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Available Storage Types</h1>\n    <ul>\n      <li>Block\n        <ul>\n          <li>EBS</li>\n        </ul>\n      </li>\n      <li>File\n        <ul>\n          <li>EFS</li>\n          <li>FSx Lustre</li>\n          <li>FSx Windows</li>\n        </ul>\n      </li>\n      <li>Block\n        <ul>\n          <li>S3</li>\n          <li>Glacier</li>\n        </ul>\n      </li>\n    </ul>\n    <h1>EBS Volume Types</h1>\n    <p><strong>EBS</strong> is a block storage.</p>\n    <p>It provides one of the following volume types, with the following categories</p>\n    <ul>\n      <li>Solid state (SSD)\n        <ul>\n          <li>General Purpose SSD - Provides a sane cost/performance balance</li>\n          <li>Provisioned IOPS SSD - High performance, mission-critical, low latency and high-throughput</li>\n        </ul>\n      </li>\n      <li>Hard disk drives (HDD)\n        <ul>\n          <li>Throughput Optimized HDD - Low cost HDD for throughput intensive workloads</li>\n          <li>Cold HDD - Lowest cost HDD for less frequently accessed workloads</li>\n        </ul>\n      </li>\n      <li>Previous generation</li>\n    </ul>\n    <h1>ELB</h1>\n    <ul>\n      <li>\n        <p>Application Load Balancer (ALB) - Works at application layer (layer 7 osi) HTTP/HTTPS</p>\n        <ul>\n          <li>Host based routing - Balance using the host and port portion of the url (scheme://host:port/path)</li>\n          <li>Path based routing - Balance using the path portion of the url (scheme://host:port/path)</li>\n        </ul>\n      </li>\n      <li>\n        <p>Network Load Balancer (NLB) - Works at the network layer (layer 4 osi) IP</p>\n      </li>\n    </ul>\n    <h1>Route53 routing policies</h1>\n    <ul>\n      <li>Simple Round Robin - Route the user in a round robin fashion accross servers</li>\n      <li>Weighted - Weight precentage of routes for each server</li>\n      <li>Geolocation - Route the user to the geographically nearest server</li>\n    </ul>\n    <h1>EC2 Instance Types</h1>\n    <ul>\n      <li>General Purpose (m4)</li>\n      <li>Compute Optimized</li>\n      <li>Memory Optimized</li>\n      <li>Accelerated Computing - Using hardware accelerators</li>\n      <li>Storage Optimized</li>\n      <li>High Memory - Acquired only using special request</li>\n    </ul>\n  </body>\n</html>\n"}},{"id":"aws/cli","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/aws/cli.md","metadata":{"title":"AWS, The cli","description":null,"permalink":null,"priority":0,"tags":[],"categories":["AWS"]},"content":{"raw":"\nThe _aws cli_ is a utility that captures all of the administration capabilities with aws.\n\n## Configuration\n\nWe can apply initial configuration using the `configure` command which will create a default configuration. This configuration is called a __profile__. For any action, if no profile is specified, the default one will be used.\n\n\nAlternatively, we can create named profiles and use each separately and specifically. The selected profile is determined using a cli argument or by an environment variable (AWS_PROFILE).\n\n{{< alert \"Perhaps providing a test environment as the default is the safest option!\" >}}\n\n## Cli vs Console\n\nThis is probably subjective, but I highly advocate the use of the cli.","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>The <em>aws cli</em> is a utility that captures all of the administration capabilities with aws.</p>\n    <h2>Configuration</h2>\n    <p>We can apply initial configuration using the <code>configure</code> command which will create a default configuration. This configuration is called a <strong>profile</strong>. For any action, if no profile is specified, the default one will be used.</p>\n    <p>Alternatively, we can create named profiles and use each separately and specifically. The selected profile is determined using a cli argument or by an environment variable (AWS_PROFILE).</p>\n    <p>{{&#x3C; alert \"Perhaps providing a test environment as the default is the safest option!\" >}}</p>\n    <h2>Cli vs Console</h2>\n    <p>This is probably subjective, but I highly advocate the use of the cli.</p>\n  </body>\n</html>\n"}},{"id":"aws/kinesis","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/aws/kinesis.md","metadata":{"title":"AWS, Kinesis","description":null,"permalink":null,"priority":0,"tags":["Cheatsheet"],"categories":["AWS"]},"content":{"raw":"\nList streams\n\n    aws kinesis list-streams\n\nDescribe a _Stream_, listing it's _Shards_, _Stream's_ ARN, current _SequenceNumbers_ etc...\n\n    aws kinesis list-streams --stream-name {stream-name}\n\nTo list the consumers/producers of a given _Stream_\n\n    aws kinesis list-stream-consumers --stream-arn {stream-arn}\n\n## Getting records\n\n_ShardIterator_ is an object used to iterate _Records_ within a specific _Shard_. So, in order to get a _Shard's_ _Records_ we need to acquire a reference to a specific _ShardIterator_.\n\n    aws kines get-shard-iterator --stream-name {stream-name} --shard-id {shard-id} --shard-iterator-type {shard-iterator-type}\n\nThe ```shard-iterator-type``` has multiple choices, advise the documentation for those.\n\nThe ```get-shard-iterator``` command provided us with an identifier of the _ShardIterator_, we can use it to get _Records_ using\n\n    aws kinesis get-records --shard-iterator {shard-iterator}\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>List streams</p>\n    <pre><code class=\"hljs language-dsconfig\"><span class=\"hljs-string\">aws</span> <span class=\"hljs-string\">kinesis</span> <span class=\"hljs-built_in\">list-streams</span>\n</code></pre>\n    <p>Describe a <em>Stream</em>, listing it's <em>Shards</em>, <em>Stream's</em> ARN, current <em>SequenceNumbers</em> etc...</p>\n    <pre><code class=\"hljs language-dsconfig\"><span class=\"hljs-string\">aws</span> <span class=\"hljs-string\">kinesis</span> <span class=\"hljs-built_in\">list-streams</span> <span class=\"hljs-built_in\">--stream-name</span> {<span class=\"hljs-string\">stream-name</span>}\n</code></pre>\n    <p>To list the consumers/producers of a given <em>Stream</em></p>\n    <pre><code class=\"hljs language-dsconfig\"><span class=\"hljs-string\">aws</span> <span class=\"hljs-string\">kinesis</span> <span class=\"hljs-built_in\">list-stream-consumers</span> <span class=\"hljs-built_in\">--stream-arn</span> {<span class=\"hljs-string\">stream-arn</span>}\n</code></pre>\n    <h2>Getting records</h2>\n    <p><em>ShardIterator</em> is an object used to iterate <em>Records</em> within a specific <em>Shard</em>. So, in order to get a <em>Shard's</em> <em>Records</em> we need to acquire a reference to a specific <em>ShardIterator</em>.</p>\n    <pre><code class=\"hljs language-dsconfig\"><span class=\"hljs-string\">aws</span> <span class=\"hljs-string\">kines</span> <span class=\"hljs-built_in\">get-shard-iterator</span> <span class=\"hljs-built_in\">--stream-name</span> {<span class=\"hljs-string\">stream-name</span>} <span class=\"hljs-built_in\">--shard-id</span> {<span class=\"hljs-string\">shard-id</span>} <span class=\"hljs-built_in\">--shard-iterator-type</span> {<span class=\"hljs-string\">shard-iterator-type</span>}\n</code></pre>\n    <p>The <code>shard-iterator-type</code> has multiple choices, advise the documentation for those.</p>\n    <p>The <code>get-shard-iterator</code> command provided us with an identifier of the <em>ShardIterator</em>, we can use it to get <em>Records</em> using</p>\n    <pre><code class=\"hljs language-dsconfig\"><span class=\"hljs-string\">aws</span> <span class=\"hljs-string\">kinesis</span> <span class=\"hljs-built_in\">get-records</span> <span class=\"hljs-built_in\">--shard-iterator</span> {<span class=\"hljs-string\">shard-iterator</span>}\n</code></pre>\n  </body>\n</html>\n"}},{"id":"aws/services","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/aws/services.md","metadata":{"title":"Services","description":null,"permalink":null,"priority":0,"tags":[],"categories":["AWS"]},"content":{"raw":"\n# S3\n\n- Object-Based, Serverless, Unlimited storage service\n- Data is replicated across at least 3 AZs which ensures 99.99% __Availability__ and 11' 9s of __Durability__\n- Objects contain data and can have size for 0 Byts to 5 Terabytes\n- Buckets names are unique globally and contain either Objects or Folders (which in turn contain Objects)\n\n- __Lifecycle Management__ is a mechanism to delete/move objects between __Storage Classes__ based on schedule or some criteria\n\n[Exampro Cheatsheet](https://youtu.be/Ia-UEYYR44s?t=3524)\n\nTypes of Replication\n- Cross-Region Replication (CRR) - Bucket is **asynchronously** replicated to another region\n- Same-Region Replication (SRR) - Bucket is **asynchronously** replicated to the same region\n\n# Snowball\n\n- Snowball\n- Snoball Edge\n- Snowmobile\n\n# VPC\n\n- VPC Peering\n- Route Tables\n- Internet Gateway\n- Bastion / Jumpbox\n- Direct Connect\n\n## VPC Endpoints\n\n- Interface Endpoints\n- Gateway Endpoints\n\n## VPC Flow Logs\n\n# NACL\n\n# Security Groups \n\n# NAT\n\n# IAM\n\n# COGNITO\n\n# DNS\n\n# Route 53\n\n# EC2\n\n## EC2 Pricing\n\n## AMI\n\n## Auto Scaling Groups\n\n## ELB\n\n# EFS\n\n# EBS\n\n# Cloud Front\n\n# Aurora\n\n# Redshift\n\n# DynamoDB\n\n# CloudFormation\n\n# CloudWatch\n\n# CloudTrail\n\n# Lambda\n\n# SQS\n\n# SNS\n\n# ElasticCache\n\n# High Availability\n\n# Elastic Beanstalk\n\n# Kinesis\n\nRealtime processing platform.\n\n# Storage Gateway\n\nProvides on-premise storage access to cloud storage.\n\nPractically you install a VM on the on-premise host which will can be connected as NFS/SMB.\n\nStorage Types\n- S3 File Gateway\n- FSx File Gateway\n- Tape Gateway\n- Volume Gateway\n\nModes\n- Gateway Stored - Access data in the VM and synchronously get data from remote\n- Cached Stored - Frequently accessed data is cached at the VM and data is invalidated asynchronously\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>S3</h1>\n    <ul>\n      <li>\n        <p>Object-Based, Serverless, Unlimited storage service</p>\n      </li>\n      <li>\n        <p>Data is replicated across at least 3 AZs which ensures 99.99% <strong>Availability</strong> and 11' 9s of <strong>Durability</strong></p>\n      </li>\n      <li>\n        <p>Objects contain data and can have size for 0 Byts to 5 Terabytes</p>\n      </li>\n      <li>\n        <p>Buckets names are unique globally and contain either Objects or Folders (which in turn contain Objects)</p>\n      </li>\n      <li>\n        <p><strong>Lifecycle Management</strong> is a mechanism to delete/move objects between <strong>Storage Classes</strong> based on schedule or some criteria</p>\n      </li>\n    </ul>\n    <p><a href=\"https://youtu.be/Ia-UEYYR44s?t=3524\">Exampro Cheatsheet</a></p>\n    <p>Types of Replication</p>\n    <ul>\n      <li>Cross-Region Replication (CRR) - Bucket is <strong>asynchronously</strong> replicated to another region</li>\n      <li>Same-Region Replication (SRR) - Bucket is <strong>asynchronously</strong> replicated to the same region</li>\n    </ul>\n    <h1>Snowball</h1>\n    <ul>\n      <li>Snowball</li>\n      <li>Snoball Edge</li>\n      <li>Snowmobile</li>\n    </ul>\n    <h1>VPC</h1>\n    <ul>\n      <li>VPC Peering</li>\n      <li>Route Tables</li>\n      <li>Internet Gateway</li>\n      <li>Bastion / Jumpbox</li>\n      <li>Direct Connect</li>\n    </ul>\n    <h2>VPC Endpoints</h2>\n    <ul>\n      <li>Interface Endpoints</li>\n      <li>Gateway Endpoints</li>\n    </ul>\n    <h2>VPC Flow Logs</h2>\n    <h1>NACL</h1>\n    <h1>Security Groups</h1>\n    <h1>NAT</h1>\n    <h1>IAM</h1>\n    <h1>COGNITO</h1>\n    <h1>DNS</h1>\n    <h1>Route 53</h1>\n    <h1>EC2</h1>\n    <h2>EC2 Pricing</h2>\n    <h2>AMI</h2>\n    <h2>Auto Scaling Groups</h2>\n    <h2>ELB</h2>\n    <h1>EFS</h1>\n    <h1>EBS</h1>\n    <h1>Cloud Front</h1>\n    <h1>Aurora</h1>\n    <h1>Redshift</h1>\n    <h1>DynamoDB</h1>\n    <h1>CloudFormation</h1>\n    <h1>CloudWatch</h1>\n    <h1>CloudTrail</h1>\n    <h1>Lambda</h1>\n    <h1>SQS</h1>\n    <h1>SNS</h1>\n    <h1>ElasticCache</h1>\n    <h1>High Availability</h1>\n    <h1>Elastic Beanstalk</h1>\n    <h1>Kinesis</h1>\n    <p>Realtime processing platform.</p>\n    <h1>Storage Gateway</h1>\n    <p>Provides on-premise storage access to cloud storage.</p>\n    <p>Practically you install a VM on the on-premise host which will can be connected as NFS/SMB.</p>\n    <p>Storage Types</p>\n    <ul>\n      <li>S3 File Gateway</li>\n      <li>FSx File Gateway</li>\n      <li>Tape Gateway</li>\n      <li>Volume Gateway</li>\n    </ul>\n    <p>Modes</p>\n    <ul>\n      <li>Gateway Stored - Access data in the VM and synchronously get data from remote</li>\n      <li>Cached Stored - Frequently accessed data is cached at the VM and data is invalidated asynchronously</li>\n    </ul>\n  </body>\n</html>\n"}},{"id":"ddd/applying","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/ddd/applying.md","metadata":{"title":"Applying","description":null,"permalink":null,"priority":0,"tags":[],"categories":["Domain Driven Design"]},"content":{"raw":"\n## Identify the possible Subdomains\n\n1. Core\n2. Support\n3. Generic\n\n## Split the Domain into Subdomains\n\nIf possible apply a single _Bounded Context_ for each _Subdomain_","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h2>Identify the possible Subdomains</h2>\n    <ol>\n      <li>Core</li>\n      <li>Support</li>\n      <li>Generic</li>\n    </ol>\n    <h2>Split the Domain into Subdomains</h2>\n    <p>If possible apply a single <em>Bounded Context</em> for each <em>Subdomain</em></p>\n  </body>\n</html>\n"}},{"id":"ddd/model-refinement-steps","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/ddd/model-refinement-steps.md","metadata":{"title":"Model Refinement Steps","description":null,"permalink":null,"priority":0,"tags":[],"categories":["Domain Driven Design"]},"content":{"raw":"\n# Distinguishing Entities and Value Objects\n\nConsider each object in turn and try to identify an identity.\n\nConsider\n- How to track the entity?\n- Are to instances with same values are the same?\n- Can it exist without some parent object?\n\n# Designing Associations\n\nSpecify traversal directions.\n\nConsider\n- How the is application used?\n\nAvoid\n- Bi-Directional associations\n\n# Identifying Aggregate Boundaries\n\n# Selecting Repositories\n\n# Walking through scenarios\n\n# Iterate\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Distinguishing Entities and Value Objects</h1>\n    <p>Consider each object in turn and try to identify an identity.</p>\n    <p>Consider</p>\n    <ul>\n      <li>How to track the entity?</li>\n      <li>Are to instances with same values are the same?</li>\n      <li>Can it exist without some parent object?</li>\n    </ul>\n    <h1>Designing Associations</h1>\n    <p>Specify traversal directions.</p>\n    <p>Consider</p>\n    <ul>\n      <li>How the is application used?</li>\n    </ul>\n    <p>Avoid</p>\n    <ul>\n      <li>Bi-Directional associations</li>\n    </ul>\n    <h1>Identifying Aggregate Boundaries</h1>\n    <h1>Selecting Repositories</h1>\n    <h1>Walking through scenarios</h1>\n    <h1>Iterate</h1>\n  </body>\n</html>\n"}},{"id":"ddd/prologue","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/ddd/prologue.md","metadata":{"title":"Domain Driven Design, Prologue","description":null,"permalink":null,"priority":0,"tags":[],"categories":["Domain Driven Design"]},"content":{"raw":"","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body></body>\n</html>\n"}},{"id":"ddd/tactical-design","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/ddd/tactical-design.md","metadata":{"title":"Tactical Design","description":null,"permalink":null,"priority":0,"tags":[],"categories":["Domain Driven Design"]},"content":{"raw":"\n# Entities\n\nEntities are the building blocks of the model.\n\nEntities are differentiated by their Id, not by their attributes.\n\n# Value Objects\n\nValue objects are differentiated by their attributes and contain no Id.\n\nValue objects should be able to implemented in an immutable fashion.\n\n# Services\n\nIn the exact same words\n\n> A SERVICE is an operation offered as an interface that stands alone in the model, without encapsulating state, as ENTITIES and VALUE OBJECTS do.\n\nCharacterisitcs of a good SERVICE\n1. The operation relates to a domain concept that is not a natural part of an ENTITY or VALUE OBJECT\n1. The interface is defined in terms of other elements of the domain model\n1. The operation is stateless\n\n# Aggregates\n\nIn the exact same words\n\n> An AGGREGATE is a cluster of associated objects that we treat as a unit for the purpose of data changes\n\nEach AGGREGATE has a **root** and a **boundary**.\n\nThe **boundary** delineate objects within the AGGREGATE.\n\nThe **root** is a *single*, *specific* ENTITY that the outside can hold references to.\n\n# Factories\n\nIn the exact same words\n\n> When creation of an object, or an entire AGGREGATE, becomes complicated or reveals too much of the internal structure, FACTORIES provide encapsulation\n\nWhile every ENTITY has a constructor receiving it's idetity, FACTORIES will provide mechanisms to create complex ENTITIES and AGGREGATES.\n\nFACTORIES are responsible for ensuring that all invariants are met for the AGGREGATE's objects.\n\n# Repositories\n\nIn the exact same words\n\n> A REPOSITORY represents all objects of a certain type as a conceptual set (usually emulated).\n\nThe REPOSITORIES act like collections but they often provide additional query mechanisms/options.\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Entities</h1>\n    <p>Entities are the building blocks of the model.</p>\n    <p>Entities are differentiated by their Id, not by their attributes.</p>\n    <h1>Value Objects</h1>\n    <p>Value objects are differentiated by their attributes and contain no Id.</p>\n    <p>Value objects should be able to implemented in an immutable fashion.</p>\n    <h1>Services</h1>\n    <p>In the exact same words</p>\n    <blockquote>\n      <p>A SERVICE is an operation offered as an interface that stands alone in the model, without encapsulating state, as ENTITIES and VALUE OBJECTS do.</p>\n    </blockquote>\n    <p>Characterisitcs of a good SERVICE</p>\n    <ol>\n      <li>The operation relates to a domain concept that is not a natural part of an ENTITY or VALUE OBJECT</li>\n      <li>The interface is defined in terms of other elements of the domain model</li>\n      <li>The operation is stateless</li>\n    </ol>\n    <h1>Aggregates</h1>\n    <p>In the exact same words</p>\n    <blockquote>\n      <p>An AGGREGATE is a cluster of associated objects that we treat as a unit for the purpose of data changes</p>\n    </blockquote>\n    <p>Each AGGREGATE has a <strong>root</strong> and a <strong>boundary</strong>.</p>\n    <p>The <strong>boundary</strong> delineate objects within the AGGREGATE.</p>\n    <p>The <strong>root</strong> is a <em>single</em>, <em>specific</em> ENTITY that the outside can hold references to.</p>\n    <h1>Factories</h1>\n    <p>In the exact same words</p>\n    <blockquote>\n      <p>When creation of an object, or an entire AGGREGATE, becomes complicated or reveals too much of the internal structure, FACTORIES provide encapsulation</p>\n    </blockquote>\n    <p>While every ENTITY has a constructor receiving it's idetity, FACTORIES will provide mechanisms to create complex ENTITIES and AGGREGATES.</p>\n    <p>FACTORIES are responsible for ensuring that all invariants are met for the AGGREGATE's objects.</p>\n    <h1>Repositories</h1>\n    <p>In the exact same words</p>\n    <blockquote>\n      <p>A REPOSITORY represents all objects of a certain type as a conceptual set (usually emulated).</p>\n    </blockquote>\n    <p>The REPOSITORIES act like collections but they often provide additional query mechanisms/options.</p>\n  </body>\n</html>\n"}},{"id":"elastic/overview","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/elastic/overview.md","metadata":{"title":"Elasticsearch Notes","description":null,"permalink":null,"priority":0,"tags":["Elasticsearch"],"categories":["Elasticsearch","Notes"]},"content":{"raw":"\nConcepts and examples to get reminded of once in a whilei\n\n## What is Elasticsearch \n\n_Elasticsearch_ is a distributed search and analytics engine, providing a _near real-time_ search for a large array of data types, structured or un-structured.\n\nSome of the usecases\n- Backend for search boxes\n- Metrics and Log analysis\n\nElasticsearch uses _Apache Lucene_ under the hood as it's underlying search engine.\n\n## Documents & Indices\n\nTechnically, and I quote - \"Elasticsearch is a distributed documented store\". It serializes any kind of structure into JSON documents. In an Elasticsearch cluster, the documents are distributed accross multiple nodes and are accessible from any (really?) of the nodes.\n\n__TODO__ Are the documents distributed accross all nodes, or a part of the cluster? It actually seems unreasonable to me that it is a full replication.\n\nElasticsearch maintains an _Inverted Index_ to provide fast search capabilities on all of a document's fields (They say that a document is fully searchable within 1 sec). Practically, the index is the data structure the collects multiple documents and provides fast access to them according to search criteria.\n\nWe can think of the model as such\n```\nField\n    key: String\n    value: Any\n\nDocument\n    fields: Field[]\n\nIndex\n    documents: Document[]\n```\n\nBy default, Elasticsearch index all fields in all documents, and it has different mehcanisms to index different data types.\n\n## Search & Aggregations\n\nElasticsearch provides a REST API that supports\n- Structured queries -  Queries that are structurely similiar to SQL queries\n- Full text queries - Queries that return all documents that match the query, sorted by relevance\n- Complex queries - A combination of the above\n\nElasticsearch can maintain aggregations of the data enabling us to analyze summaries providing insights regarding metrics, patterns and trends. For example, we can query for\n- Total numbers that match X\n- The average that match Y\n\nFurthermore, aggregations can operate alongside the search requests, meaning that we can gain aggregative information for all search results.\n\n### cat API\n\nThe ```_cat``` endpoint provides \"Compact and Aligned Text\" meaning, a general, __consumed by humans__ information.\n\nGet the list of cat APIs\n\n    /_cat\n\nGet information about indices using [cat indices API](https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-indices.html)\n\n    /_cat/indices\n    /_cat/indices/_all\n    /_cat/indices?format=json\n    /_cat/indices/my-index\n    /_cat/indices/my-index?format=json\n\n### search API\n\nThe ```<target>/_search``` endpoint provides searching functionality.\n\nThe ```<target>``` parameter is optional and is a comma seperated list indicating data streams, indices and aliases to search. It supports wildcards (*).\n\nThere are many query parameters that affects how the search is being performed and how the results are being returned. We won't list them all here but here is a small list that give a vibe on the kind of possible parameters\n\n- q(string) - The query. Note that it can alternetively be provided through the body\n- explain(boolean) - If true, returns a defailed information about the score computation  \n- timeout(time units) - Sets the timeout for the request  \n- from(integer) - Starting document offset  \n- size(integer) - Number of hits to return  \n\nThe body also contains important information the important one is the \"query\" field.\n\n### shards\n\nShow shards\n\n    /_cat/shards\n    /_cat/shards?h=index,shard\n\n### Usage\n\n#### Basics, insert and retrieve documents\n\nAssume the scenario with indices ```tglanzma-small-1,2,3``` and a document model\n\n```\n{\n    _id: string\n    x: string\n    y: string\n    z: number\n    tags: string[]\n}\n```\n\nTo add documents to and index we use the [Index API](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html). For example\n\n```\nPUT tglanzma-small-1/_doc/1\n{\n  \"x\": \"x of 1\",\n  \"y\": \"y of 1\",\n  \"z\": 1,\n  \"tags\": [\n    \"first tag of 1\",\n    \"second tag of 1\"\n  ]\n}\n```\n\nTo get a specific document by it's id we use the [Document's Get API](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html). For example\n\n```\nGET tglanzma-small-1/_doc/1\n```\n\nTo get multiple documents by their ids, use the [Multi get API](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-multi-get.html). For example\n\n```\nGET _mget\n{\n  \"docs\": [{\n    \"_index\": \"tglanzma-small-1\",\n    \"_id\": 1\n  }, {\n    \"_index\": \"tglanzma-small-1\",\n    \"_id\": 2\n  }]\n}\n```\n\n### Searching an index\n\nTo search for documents we use the [Search API](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html).\n\nTo search for all documents within a specific index\n\n```\nGET tglanzma-small-1/_search\n```\n\nTo specify exactly what fields we want returned from each document we will use the ```_source``` parameter, as so\n\n```\nGET tglanzma-small-1/_search\n{\n  \"_source\": [\n    \"x\",\n    \"y\"\n  ]\n}\n```\n\nTo specify the search query we use the ```query``` parameter. This is a query object and we specify it using the [Query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html).\n\nThe Query DSL is an AST defined as\n\n```\nQuery := Leaf | Compound\nCompound := [Compound | Leaf]\n```\n\n\nSearch documents where ```x === x of 1``` we use the [Match phrase query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase.html)\n\n```\nGET tglanzma-small-1/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"match_phrase\": {\n            \"x\": \"x of 1\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\nFor a fuzzy search, we use the [Match query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html).\n\n```\nGET tglanzma-small-1/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"match\": {\n            \"x\": \"x of 1\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\nThe returned documents might not have an exact match because we fuzzy searched. Each document is assigned with a score determining how close it is to a full match. We can control the minimum we want using the ```min_score``` parameter\n\n```\nGET tglanzma-small-1/_search\n{\n  \"min_score\": 0.6,\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"match\": {\n            \"x\": \"x of 1\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\nThe [Boolean query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html) matches boolean combinations over documents.\n\nThe ```must``` acts as an AND operator and the ```should``` acts as an OR operator. Intuitively, the ```must_not``` acts as negation.\n\nTo search for query that have either ```x = x of 1``` and ```y = y of 1``` we use the ```must``` query\n\n```\nGET tglanzma-small-1/_search\n{\n  \"min_score\": 0.6,\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"match_phrase\": {\n            \"x\": \"x of 1\"\n          }\n        },\n        {\n          \"match_phrase\": {\n            \"y\": \"y of 1\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\nTo search for query that have either ```x = x of 1``` or ```y = y of 2``` we use the ```should``` query\n\n```\nGET tglanzma-small-1/_search\n{\n  \"min_score\": 0.6,\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"match_phrase\": {\n            \"x\": \"x of 1\"\n          }\n        },\n        {\n          \"match_phrase\": {\n            \"y\": \"y of 2\"\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\nAs mentioned, compound queries are recursively defined so we can compose combinations. For example, to match documents where (```x = x of 1``` AND ```y = y of 1```) OR (```x = x of 2``` AND ```y = y of 2```)\n\n```\nGET tglanzma-small-1/_search\n{\n  \"min_score\": 0.6,\n  \"query\": {\n    \"bool\": {\n      \"should\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"match_phrase\": {\n                  \"x\": \"x of 1\"\n                }\n              },\n              {\n                \"match_phrase\": {\n                  \"y\": \"y of 1\"\n                }\n              }\n            ]\n          }\n        },\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"match_phrase\": {\n                  \"x\": \"x of 2\"\n                }\n              },\n              {\n                \"match_phrase\": {\n                  \"y\": \"y of 2\"\n                }\n              }\n            ]\n          }\n        }\n      ]\n    }\n  }\n}\n```\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>Concepts and examples to get reminded of once in a whilei</p>\n    <h2>What is Elasticsearch</h2>\n    <p><em>Elasticsearch</em> is a distributed search and analytics engine, providing a <em>near real-time</em> search for a large array of data types, structured or un-structured.</p>\n    <p>Some of the usecases</p>\n    <ul>\n      <li>Backend for search boxes</li>\n      <li>Metrics and Log analysis</li>\n    </ul>\n    <p>Elasticsearch uses <em>Apache Lucene</em> under the hood as it's underlying search engine.</p>\n    <h2>Documents &#x26; Indices</h2>\n    <p>Technically, and I quote - \"Elasticsearch is a distributed documented store\". It serializes any kind of structure into JSON documents. In an Elasticsearch cluster, the documents are distributed accross multiple nodes and are accessible from any (really?) of the nodes.</p>\n    <p><strong>TODO</strong> Are the documents distributed accross all nodes, or a part of the cluster? It actually seems unreasonable to me that it is a full replication.</p>\n    <p>Elasticsearch maintains an <em>Inverted Index</em> to provide fast search capabilities on all of a document's fields (They say that a document is fully searchable within 1 sec). Practically, the index is the data structure the collects multiple documents and provides fast access to them according to search criteria.</p>\n    <p>We can think of the model as such</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">Field</span>\n    <span class=\"hljs-attr\">key</span>: <span class=\"hljs-string\">String</span>\n    <span class=\"hljs-attr\">value</span>: <span class=\"hljs-string\">Any</span>\n\n<span class=\"hljs-attr\">Document</span>\n    <span class=\"hljs-attr\">fields</span>: <span class=\"hljs-string\">Field[]</span>\n\n<span class=\"hljs-attr\">Index</span>\n    <span class=\"hljs-attr\">documents</span>: <span class=\"hljs-string\">Document[]</span>\n</code></pre>\n    <p>By default, Elasticsearch index all fields in all documents, and it has different mehcanisms to index different data types.</p>\n    <h2>Search &#x26; Aggregations</h2>\n    <p>Elasticsearch provides a REST API that supports</p>\n    <ul>\n      <li>Structured queries - Queries that are structurely similiar to SQL queries</li>\n      <li>Full text queries - Queries that return all documents that match the query, sorted by relevance</li>\n      <li>Complex queries - A combination of the above</li>\n    </ul>\n    <p>Elasticsearch can maintain aggregations of the data enabling us to analyze summaries providing insights regarding metrics, patterns and trends. For example, we can query for</p>\n    <ul>\n      <li>Total numbers that match X</li>\n      <li>The average that match Y</li>\n    </ul>\n    <p>Furthermore, aggregations can operate alongside the search requests, meaning that we can gain aggregative information for all search results.</p>\n    <h3>cat API</h3>\n    <p>The <code>_cat</code> endpoint provides \"Compact and Aligned Text\" meaning, a general, <strong>consumed by humans</strong> information.</p>\n    <p>Get the list of cat APIs</p>\n    <pre><code class=\"hljs language-bash\">/_cat\n</code></pre>\n    <p>Get information about indices using <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-indices.html\">cat indices API</a></p>\n    <pre><code class=\"hljs language-awk\"><span class=\"hljs-regexp\">/_cat/i</span>ndices\n<span class=\"hljs-regexp\">/_cat/i</span>ndices/_all\n<span class=\"hljs-regexp\">/_cat/i</span>ndices?format=json\n<span class=\"hljs-regexp\">/_cat/i</span>ndices/my-index\n<span class=\"hljs-regexp\">/_cat/i</span>ndices/my-index?format=json\n</code></pre>\n    <h3>search API</h3>\n    <p>The <code>&#x3C;target>/_search</code> endpoint provides searching functionality.</p>\n    <p>The <code>&#x3C;target></code> parameter is optional and is a comma seperated list indicating data streams, indices and aliases to search. It supports wildcards (*).</p>\n    <p>There are many query parameters that affects how the search is being performed and how the results are being returned. We won't list them all here but here is a small list that give a vibe on the kind of possible parameters</p>\n    <ul>\n      <li>q(string) - The query. Note that it can alternetively be provided through the body</li>\n      <li>explain(boolean) - If true, returns a defailed information about the score computation</li>\n      <li>timeout(time units) - Sets the timeout for the request</li>\n      <li>from(integer) - Starting document offset</li>\n      <li>size(integer) - Number of hits to return</li>\n    </ul>\n    <p>The body also contains important information the important one is the \"query\" field.</p>\n    <h3>shards</h3>\n    <p>Show shards</p>\n    <pre><code class=\"hljs language-awk\"><span class=\"hljs-regexp\">/_cat/</span>shards\n<span class=\"hljs-regexp\">/_cat/</span>shards?h=index,shard\n</code></pre>\n    <h3>Usage</h3>\n    <h4>Basics, insert and retrieve documents</h4>\n    <p>Assume the scenario with indices <code>tglanzma-small-1,2,3</code> and a document model</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">{</span>\n    <span class=\"hljs-attr\">_id</span>: <span class=\"hljs-string\">string</span>\n    <span class=\"hljs-attr\">x</span>: <span class=\"hljs-string\">string</span>\n    <span class=\"hljs-attr\">y</span>: <span class=\"hljs-string\">string</span>\n    <span class=\"hljs-attr\">z</span>: <span class=\"hljs-string\">number</span>\n    <span class=\"hljs-attr\">tags</span>: <span class=\"hljs-string\">string[]</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>To add documents to and index we use the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html\">Index API</a>. For example</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">PUT</span> <span class=\"hljs-string\">tglanzma-small-1/_doc/1</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">\"x of 1\",</span>\n  <span class=\"hljs-attr\">\"y\"</span>: <span class=\"hljs-string\">\"y of 1\",</span>\n  <span class=\"hljs-attr\">\"z\"</span>: <span class=\"hljs-string\">1,</span>\n  <span class=\"hljs-attr\">\"tags\"</span>: <span class=\"hljs-string\">[</span>\n    <span class=\"hljs-attr\">\"first</span> <span class=\"hljs-string\">tag of 1\",</span>\n    <span class=\"hljs-attr\">\"second</span> <span class=\"hljs-string\">tag of 1\"</span>\n  <span class=\"hljs-attr\">]</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>To get a specific document by it's id we use the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html\">Document's Get API</a>. For example</p>\n    <pre><code class=\"hljs language-apache\"><span class=\"hljs-attribute\">GET</span> tglanzma-small-<span class=\"hljs-number\">1</span>/_doc/<span class=\"hljs-number\">1</span>\n</code></pre>\n    <p>To get multiple documents by their ids, use the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-multi-get.html\">Multi get API</a>. For example</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">_mget</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"docs\"</span>: <span class=\"hljs-string\">[{</span>\n    <span class=\"hljs-attr\">\"_index\"</span>: <span class=\"hljs-string\">\"tglanzma-small-1\",</span>\n    <span class=\"hljs-attr\">\"_id\"</span>: <span class=\"hljs-string\">1</span>\n  <span class=\"hljs-attr\">},</span> <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"_index\"</span>: <span class=\"hljs-string\">\"tglanzma-small-1\",</span>\n    <span class=\"hljs-attr\">\"_id\"</span>: <span class=\"hljs-string\">2</span>\n  <span class=\"hljs-attr\">}]</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <h3>Searching an index</h3>\n    <p>To search for documents we use the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html\">Search API</a>.</p>\n    <p>To search for all documents within a specific index</p>\n    <pre><code class=\"hljs language-excel\">GET tglanzma-<span class=\"hljs-built_in\">small</span>-<span class=\"hljs-number\">1</span>/_<span class=\"hljs-built_in\">search</span>\n</code></pre>\n    <p>To specify exactly what fields we want returned from each document we will use the <code>_source</code> parameter, as so</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">tglanzma-small-1/_search</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"_source\"</span>: <span class=\"hljs-string\">[</span>\n    <span class=\"hljs-attr\">\"x\",</span>\n    <span class=\"hljs-attr\">\"y\"</span>\n  <span class=\"hljs-attr\">]</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>To specify the search query we use the <code>query</code> parameter. This is a query object and we specify it using the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html\">Query DSL</a>.</p>\n    <p>The Query DSL is an AST defined as</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">Query</span> :<span class=\"hljs-string\">= Leaf | Compound</span>\n<span class=\"hljs-attr\">Compound</span> :<span class=\"hljs-string\">= [Compound | Leaf]</span>\n</code></pre>\n    <p>Search documents where <code>x === x of 1</code> we use the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase.html\">Match phrase query</a></p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">tglanzma-small-1/_search</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"query\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"bool\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"must\"</span>: <span class=\"hljs-string\">[</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">\"x of 1\"</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">}</span>\n      <span class=\"hljs-attr\">]</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>For a fuzzy search, we use the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html\">Match query</a>.</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">tglanzma-small-1/_search</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"query\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"bool\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"must\"</span>: <span class=\"hljs-string\">[</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"match\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">\"x of 1\"</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">}</span>\n      <span class=\"hljs-attr\">]</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>The returned documents might not have an exact match because we fuzzy searched. Each document is assigned with a score determining how close it is to a full match. We can control the minimum we want using the <code>min_score</code> parameter</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">tglanzma-small-1/_search</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"min_score\"</span>: <span class=\"hljs-string\">0.6,</span>\n  <span class=\"hljs-attr\">\"query\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"bool\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"must\"</span>: <span class=\"hljs-string\">[</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"match\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">\"x of 1\"</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">}</span>\n      <span class=\"hljs-attr\">]</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>The <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html\">Boolean query</a> matches boolean combinations over documents.</p>\n    <p>The <code>must</code> acts as an AND operator and the <code>should</code> acts as an OR operator. Intuitively, the <code>must_not</code> acts as negation.</p>\n    <p>To search for query that have either <code>x = x of 1</code> and <code>y = y of 1</code> we use the <code>must</code> query</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">tglanzma-small-1/_search</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"min_score\"</span>: <span class=\"hljs-string\">0.6,</span>\n  <span class=\"hljs-attr\">\"query\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"bool\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"must\"</span>: <span class=\"hljs-string\">[</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">\"x of 1\"</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">},</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"y\"</span>: <span class=\"hljs-string\">\"y of 1\"</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">}</span>\n      <span class=\"hljs-attr\">]</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>To search for query that have either <code>x = x of 1</code> or <code>y = y of 2</code> we use the <code>should</code> query</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">tglanzma-small-1/_search</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"min_score\"</span>: <span class=\"hljs-string\">0.6,</span>\n  <span class=\"hljs-attr\">\"query\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"bool\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"should\"</span>: <span class=\"hljs-string\">[</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">\"x of 1\"</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">},</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"y\"</span>: <span class=\"hljs-string\">\"y of 2\"</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">}</span>\n      <span class=\"hljs-attr\">]</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>As mentioned, compound queries are recursively defined so we can compose combinations. For example, to match documents where (<code>x = x of 1</code> AND <code>y = y of 1</code>) OR (<code>x = x of 2</code> AND <code>y = y of 2</code>)</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">tglanzma-small-1/_search</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"min_score\"</span>: <span class=\"hljs-string\">0.6,</span>\n  <span class=\"hljs-attr\">\"query\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"bool\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"should\"</span>: <span class=\"hljs-string\">[</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"bool\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"must\"</span>: <span class=\"hljs-string\">[</span>\n              <span class=\"hljs-attr\">{</span>\n                <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n                  <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">\"x of 1\"</span>\n                <span class=\"hljs-attr\">}</span>\n              <span class=\"hljs-attr\">},</span>\n              <span class=\"hljs-attr\">{</span>\n                <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n                  <span class=\"hljs-attr\">\"y\"</span>: <span class=\"hljs-string\">\"y of 1\"</span>\n                <span class=\"hljs-attr\">}</span>\n              <span class=\"hljs-attr\">}</span>\n            <span class=\"hljs-attr\">]</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">},</span>\n        <span class=\"hljs-attr\">{</span>\n          <span class=\"hljs-attr\">\"bool\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"must\"</span>: <span class=\"hljs-string\">[</span>\n              <span class=\"hljs-attr\">{</span>\n                <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n                  <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">\"x of 2\"</span>\n                <span class=\"hljs-attr\">}</span>\n              <span class=\"hljs-attr\">},</span>\n              <span class=\"hljs-attr\">{</span>\n                <span class=\"hljs-attr\">\"match_phrase\"</span>: <span class=\"hljs-string\">{</span>\n                  <span class=\"hljs-attr\">\"y\"</span>: <span class=\"hljs-string\">\"y of 2\"</span>\n                <span class=\"hljs-attr\">}</span>\n              <span class=\"hljs-attr\">}</span>\n            <span class=\"hljs-attr\">]</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">}</span>\n      <span class=\"hljs-attr\">]</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n  </body>\n</html>\n"}},{"id":"elastic/reference-queries","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/elastic/reference-queries.md","metadata":{"title":"Elasticsearch, Reference Queries","description":null,"permalink":null,"priority":0,"tags":["Elastissearch"],"categories":["Elasticsearch"]},"content":{"raw":"\n# Reference Queries\n\nCount docs in ```some-index```\n\n```GET some-index/_count```\n\nFind min of ```field-a``` and max of ```field-b``` in ```some-index```\n\n```\nPOST some-index/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"min-field-a\": {\n      \"min\": {\n        \"field\": \"field-a\"\n      }\n    },\n    \"max-field-b\": {\n      \"max\": {\n        \"field\": \"field-b\"\n      }\n    }\n  }\n}\n```\n\nDelete by query - where ```x = 1```.\n\n```\nPOST some-index/_delete_by_query\n{\n  \"query\": {\n    \"match\": {\n      \"x\": 1\n    }\n  }\n}\n```","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Reference Queries</h1>\n    <p>Count docs in <code>some-index</code></p>\n    <p><code>GET some-index/_count</code></p>\n    <p>Find min of <code>field-a</code> and max of <code>field-b</code> in <code>some-index</code></p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">POST</span> <span class=\"hljs-string\">some-index/_search</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"size\"</span>: <span class=\"hljs-string\">0,</span>\n  <span class=\"hljs-attr\">\"aggs\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"min-field-a\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"min\"</span>: <span class=\"hljs-string\">{</span>\n        <span class=\"hljs-attr\">\"field\"</span>: <span class=\"hljs-string\">\"field-a\"</span>\n      <span class=\"hljs-attr\">}</span>\n    <span class=\"hljs-attr\">},</span>\n    <span class=\"hljs-attr\">\"max-field-b\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"max\"</span>: <span class=\"hljs-string\">{</span>\n        <span class=\"hljs-attr\">\"field\"</span>: <span class=\"hljs-string\">\"field-b\"</span>\n      <span class=\"hljs-attr\">}</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>Delete by query - where <code>x = 1</code>.</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">POST</span> <span class=\"hljs-string\">some-index/_delete_by_query</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"query\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"match\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"x\"</span>: <span class=\"hljs-string\">1</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n  </body>\n</html>\n"}},{"id":"elastic/usecase-1","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/elastic/usecase-1.md","metadata":{"title":"Elasticsearch, Usecase 1, Simple rollover","description":null,"permalink":null,"priority":0,"tags":["Elasticsearch","ILM"],"categories":["Elasticsearch"]},"content":{"raw":"\n# Use case\n\nCreate ILM policy with the following\n\n- Rollover daily\n- Delete indexes that are older than 3 days \n\n# Steps\n\n## ILM Policy\n\nCreate an ILM policy named ```tal``` using the [ILM Policy API](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-lifecycle-management-api.html).\n\nAt first we specify that the ```hot``` phase should rollover on a daily basis.\n\nWe also specify that the ```delete``` phase contains indices with a minimum age of 3 days. To delete the indices that are in the delete phase  we need to add the ```delete``` action to the phase - It is not implicit.\n\n```\nPUT _ilm/policy/tal\n{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\": {\n            \"max_age\": \"1d\"\n          }\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"3d\",\n        \"actions\": {\n          \"delete\": {} \n        }\n      }\n    }\n  }\n}\n```\n\nTo verify, get the newly created policy by\n\n```\nGET _ilm/policy/tal\n```\n\n## Index Template\n\nCreate an index template.\n\nOur intention is to have rollover that will create 3 indices in the form ```tal-00001```, ```tal-00002``` and ```tal-00003```. In order to interact with those as a single index we provide an ```alias``` for them. For example, we could have searched them by pattern or individually, but it's preferable to have a virtual, single ```tal``` index that we could interact with. On a technical level, Elasticsearch needs an alias so it can manage the rollovers with.\n\nSo we will apply an index template using a pattern of ```tal-*```, specify the alias ```tal``` and attach the ILM policy ```tal``` which has been created beforehand.\n\n```\nPUT _index_template/tal\n{\n  \"index_patterns\": [\"tal-*\"], \n  \"template\": {\n    \"settings\": {\n      \"index.lifecycle.name\": \"tal\",\n      \"index.lifecycle.rollover_alias\": \"tal\"\n    }\n  }\n}\n```\n\nTo verify, get the newly created template by\n\n```\nGET _index_template/tal\n```\n\n## Create the index\n\nThe index ```tal``` should be just an alias. If we will insert documents to ```tal``` it will be created concretely which is not what we want.\n\nWe need to create the first aliased index ```tal-00001``` and specify that it is the current write index.\n\n```\nPUT tal-00001\n{\n  \"aliases\": {\n    \"tal\": {\n      \"is_write_index\": true,\n      \"is_hidden\": false\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"timestamp\": {\n        \"type\": \"date\" \n      }\n    }\n  }\n}\n```\n\nNow we can insert documents to ```tal``` - Notice it is inserted to the managed indices.\n\n# Further notes\n\n## Explaining ILM state\n\nTo review the state of the policy with respect to the indices we can run\n\n```\nGET tal/_ilm/explain\n```\n\nIt indicates what phase every index is at, it's age, size etc...\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Use case</h1>\n    <p>Create ILM policy with the following</p>\n    <ul>\n      <li>Rollover daily</li>\n      <li>Delete indexes that are older than 3 days</li>\n    </ul>\n    <h1>Steps</h1>\n    <h2>ILM Policy</h2>\n    <p>Create an ILM policy named <code>tal</code> using the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/index-lifecycle-management-api.html\">ILM Policy API</a>.</p>\n    <p>At first we specify that the <code>hot</code> phase should rollover on a daily basis.</p>\n    <p>We also specify that the <code>delete</code> phase contains indices with a minimum age of 3 days. To delete the indices that are in the delete phase we need to add the <code>delete</code> action to the phase - It is not implicit.</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">PUT</span> <span class=\"hljs-string\">_ilm/policy/tal</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"policy\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"phases\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"hot\"</span>: <span class=\"hljs-string\">{</span>\n        <span class=\"hljs-attr\">\"actions\"</span>: <span class=\"hljs-string\">{</span>\n          <span class=\"hljs-attr\">\"rollover\"</span>: <span class=\"hljs-string\">{</span>\n            <span class=\"hljs-attr\">\"max_age\"</span>: <span class=\"hljs-string\">\"1d\"</span>\n          <span class=\"hljs-attr\">}</span>\n        <span class=\"hljs-attr\">}</span>\n      <span class=\"hljs-attr\">},</span>\n      <span class=\"hljs-attr\">\"delete\"</span>: <span class=\"hljs-string\">{</span>\n        <span class=\"hljs-attr\">\"min_age\"</span>: <span class=\"hljs-string\">\"3d\",</span>\n        <span class=\"hljs-attr\">\"actions\"</span>: <span class=\"hljs-string\">{</span>\n          <span class=\"hljs-attr\">\"delete\"</span>: <span class=\"hljs-string\">{} </span>\n        <span class=\"hljs-attr\">}</span>\n      <span class=\"hljs-attr\">}</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>To verify, get the newly created policy by</p>\n    <pre><code class=\"hljs language-awk\">GET _ilm<span class=\"hljs-regexp\">/policy/</span>tal\n</code></pre>\n    <h2>Index Template</h2>\n    <p>Create an index template.</p>\n    <p>Our intention is to have rollover that will create 3 indices in the form <code>tal-00001</code>, <code>tal-00002</code> and <code>tal-00003</code>. In order to interact with those as a single index we provide an <code>alias</code> for them. For example, we could have searched them by pattern or individually, but it's preferable to have a virtual, single <code>tal</code> index that we could interact with. On a technical level, Elasticsearch needs an alias so it can manage the rollovers with.</p>\n    <p>So we will apply an index template using a pattern of <code>tal-*</code>, specify the alias <code>tal</code> and attach the ILM policy <code>tal</code> which has been created beforehand.</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">PUT</span> <span class=\"hljs-string\">_index_template/tal</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"index_patterns\"</span>: <span class=\"hljs-string\">[\"tal-*\"], </span>\n  <span class=\"hljs-attr\">\"template\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"settings\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"index.lifecycle.name\"</span>: <span class=\"hljs-string\">\"tal\",</span>\n      <span class=\"hljs-attr\">\"index.lifecycle.rollover_alias\"</span>: <span class=\"hljs-string\">\"tal\"</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>To verify, get the newly created template by</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">GET</span> <span class=\"hljs-string\">_index_template/tal</span>\n</code></pre>\n    <h2>Create the index</h2>\n    <p>The index <code>tal</code> should be just an alias. If we will insert documents to <code>tal</code> it will be created concretely which is not what we want.</p>\n    <p>We need to create the first aliased index <code>tal-00001</code> and specify that it is the current write index.</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">PUT</span> <span class=\"hljs-string\">tal-00001</span>\n<span class=\"hljs-attr\">{</span>\n  <span class=\"hljs-attr\">\"aliases\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"tal\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"is_write_index\"</span>: <span class=\"hljs-string\">true,</span>\n      <span class=\"hljs-attr\">\"is_hidden\"</span>: <span class=\"hljs-string\">false</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">},</span>\n  <span class=\"hljs-attr\">\"mappings\"</span>: <span class=\"hljs-string\">{</span>\n    <span class=\"hljs-attr\">\"properties\"</span>: <span class=\"hljs-string\">{</span>\n      <span class=\"hljs-attr\">\"timestamp\"</span>: <span class=\"hljs-string\">{</span>\n        <span class=\"hljs-attr\">\"type\"</span>: <span class=\"hljs-string\">\"date\" </span>\n      <span class=\"hljs-attr\">}</span>\n    <span class=\"hljs-attr\">}</span>\n  <span class=\"hljs-attr\">}</span>\n<span class=\"hljs-attr\">}</span>\n</code></pre>\n    <p>Now we can insert documents to <code>tal</code> - Notice it is inserted to the managed indices.</p>\n    <h1>Further notes</h1>\n    <h2>Explaining ILM state</h2>\n    <p>To review the state of the policy with respect to the indices we can run</p>\n    <pre><code class=\"hljs language-awk\">GET tal<span class=\"hljs-regexp\">/_ilm/</span>explain\n</code></pre>\n    <p>It indicates what phase every index is at, it's age, size etc...</p>\n  </body>\n</html>\n"}},{"id":"kubernetes/deployments","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/deployments.md","metadata":{"title":"Kubernetes Deployments","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Deployments\n\nA _Deployment_ manages _ReplicaSets_ and _ReplicaSets_ manage _Pods_.\n\n_ReplicaSet_ manage _Pods_ and bring self-healing and scaling capabilities while _Deployments_ manage _ReplicaSets_ and add rollout and rollback capabilities.\n\n### Self-healing and scalability\n\nIf _Pods_ managed by a _Deployment_ fail, they will be replaced - this is known as _self healing_.\n\nIf _Pods_ managed by a _Deployment_ see increased/decreased load, they will be _scaled_.\n\nIn Kubernetes there are 3 related concepts\n\n- _desired state_\n- _observerd state_\n- _reconciliation_\n\n_ReplicaSets_ are implemented as a controller running background process comparing the _desired state_ vs the _observed state_. If they are different it contacts the cluster to perform _reconciliation_.\n\n### Rolling updates\n\nZero downtime, rolling updates (a.k.a rollouts) can be supported when a service has backward and forward compatibility. One by one, the _ReplicaSet_ bring a replica down and introduces a new one with the designated version until all of the _Pods_ are updated with the desired version.\n\nIt is crucial that the services be stateless and backward/forward compatible for this to work.\n\n### Rollbacks\n\n### Commands\n\nTo scale a _Deployment_\n\n    kubectl scale deployment {deployment-name} --replicas {number-of-replicas}\n\nAfter changing image versions, initiate rollouts simply by reaplying a manifest\n\n    kubectl apply -f {manifest-path}\n\nWe can monitor the rollout progress by\n\n    kubectl rollout status deployment {deployment-name}\n\nTo pause a rollout\n\n    kubectl rollout pause deployment {deployment-name}\n\nTo resume a rollout\n\n    kubectl rollout resume deployment {deployment-name}\n\nIn the manifests we can specify ```revisionHistoryLimit``` for containers. \n\nTo show rollout history\n\n    kubectl rollout history deployment {deployment-name}\n\nTo rollback to a revision\n\n    kubectl rollout undo deployment {deployment-name} --to-revision={revision-number}\n\n\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Deployments</h1>\n    <p>A <em>Deployment</em> manages <em>ReplicaSets</em> and <em>ReplicaSets</em> manage <em>Pods</em>.</p>\n    <p><em>ReplicaSet</em> manage <em>Pods</em> and bring self-healing and scaling capabilities while <em>Deployments</em> manage <em>ReplicaSets</em> and add rollout and rollback capabilities.</p>\n    <h3>Self-healing and scalability</h3>\n    <p>If <em>Pods</em> managed by a <em>Deployment</em> fail, they will be replaced - this is known as <em>self healing</em>.</p>\n    <p>If <em>Pods</em> managed by a <em>Deployment</em> see increased/decreased load, they will be <em>scaled</em>.</p>\n    <p>In Kubernetes there are 3 related concepts</p>\n    <ul>\n      <li><em>desired state</em></li>\n      <li><em>observerd state</em></li>\n      <li><em>reconciliation</em></li>\n    </ul>\n    <p><em>ReplicaSets</em> are implemented as a controller running background process comparing the <em>desired state</em> vs the <em>observed state</em>. If they are different it contacts the cluster to perform <em>reconciliation</em>.</p>\n    <h3>Rolling updates</h3>\n    <p>Zero downtime, rolling updates (a.k.a rollouts) can be supported when a service has backward and forward compatibility. One by one, the <em>ReplicaSet</em> bring a replica down and introduces a new one with the designated version until all of the <em>Pods</em> are updated with the desired version.</p>\n    <p>It is crucial that the services be stateless and backward/forward compatible for this to work.</p>\n    <h3>Rollbacks</h3>\n    <h3>Commands</h3>\n    <p>To scale a <em>Deployment</em></p>\n    <pre><code class=\"hljs language-fortran\">kubectl <span class=\"hljs-built_in\">scale</span> deployment {deployment-<span class=\"hljs-keyword\">name</span>} --replicas {<span class=\"hljs-keyword\">number</span>-of-replicas}\n</code></pre>\n    <p>After changing image versions, initiate rollouts simply by reaplying a manifest</p>\n    <pre><code class=\"hljs language-puppet\">kubectl apply -<span class=\"hljs-keyword\">f</span> {<span class=\"hljs-literal\">manifest</span>-<span class=\"hljs-built_in\">path</span>}\n</code></pre>\n    <p>We can monitor the rollout progress by</p>\n    <pre><code class=\"hljs language-fortran\">kubectl rollout <span class=\"hljs-keyword\">status</span> deployment {deployment-<span class=\"hljs-keyword\">name</span>}\n</code></pre>\n    <p>To pause a rollout</p>\n    <pre><code class=\"hljs language-fortran\">kubectl rollout <span class=\"hljs-keyword\">pause</span> deployment {deployment-<span class=\"hljs-keyword\">name</span>}\n</code></pre>\n    <p>To resume a rollout</p>\n    <pre><code class=\"hljs language-basic\">kubectl rollout <span class=\"hljs-keyword\">resume</span> deployment {deployment-<span class=\"hljs-keyword\">name</span>}\n</code></pre>\n    <p>In the manifests we can specify <code>revisionHistoryLimit</code> for containers.</p>\n    <p>To show rollout history</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">kubectl</span> <span class=\"hljs-string\">rollout history deployment {deployment-name}</span>\n</code></pre>\n    <p>To rollback to a revision</p>\n    <pre><code class=\"hljs language-vim\">kubectl rollout <span class=\"hljs-keyword\">undo</span> deployment {deployment-name} --<span class=\"hljs-keyword\">to</span>-revision={revision-<span class=\"hljs-keyword\">number</span>}\n</code></pre>\n  </body>\n</html>\n"}},{"id":"kubernetes/notes","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/notes.md","metadata":{"title":"Notes","description":null,"permalink":null,"priority":0,"tags":[],"categories":["Kubernetes"]},"content":{"raw":"\n## Cert Manager ClusterIssuer fails to connect to webhook\n\nIf installing through helm, make sure that the leader election is on a specific namespace:\n\n```yaml\nvalues:\n  global:\n    leaderElection:\n      namespace: cert-manager\n```\n\n## Check space left in PV\n\nJust execute `df` inside the pod that has the volume mounted.\n\n    kubectl -n {namespace} exec {pod}  -- df -ah\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h2>Cert Manager ClusterIssuer fails to connect to webhook</h2>\n    <p>If installing through helm, make sure that the leader election is on a specific namespace:</p>\n    <pre><code class=\"hljs language-yaml\"><span class=\"hljs-attr\">values:</span>\n  <span class=\"hljs-attr\">global:</span>\n    <span class=\"hljs-attr\">leaderElection:</span>\n      <span class=\"hljs-attr\">namespace:</span> <span class=\"hljs-string\">cert-manager</span>\n</code></pre>\n    <h2>Check space left in PV</h2>\n    <p>Just execute <code>df</code> inside the pod that has the volume mounted.</p>\n    <pre><code class=\"hljs language-fsharp\">kubectl <span class=\"hljs-operator\">-</span><span class=\"hljs-keyword\">n</span> {<span class=\"hljs-keyword\">namespace</span>} <span class=\"hljs-keyword\">exec</span> {pod}  <span class=\"hljs-operator\">--</span> df <span class=\"hljs-operator\">-</span>ah\n</code></pre>\n  </body>\n</html>\n"}},{"id":"kubernetes/service-discovery","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/service-discovery.md","metadata":{"title":"Service Discovery","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Service Discovery\n\nService discovery is a mean for applications to find one another in the cluster.\n\nThere are two major components to service discovery\n\n- Registration\n- Discovery\n\nService registration is when an application registers itself in a _service registry_.\n\nKubernetes uses its internal DNS as a _service registry_, and as we know, _Services_ are automatically registered with DNS.\n\nFor discovery to work, Kubernetes provides a well-known internal DNS services that are called the __cluster DNS__, in the namespace __kube-system__. Every _Pod_ in the cluster is automatically configured to where this service is. The relevant _Pods_ are managed by a _Deployment_ called __coredns__ and frontend by a _Service_ called __kube-dns__. \n\nFor illustration\n\n```\nkubectl get pods --namespace kube-system --selector k8s-app=kube-dns\n\nNAME                       READY   STATUS    RESTARTS   AGE\ncoredns-6d4b75cb6d-4lpv9   1/1     Running   0          139m\ncoredns-6d4b75cb6d-vmkfz   1/1     Running   0          139m\n\n```\n\nWe specify a _Service_ DNS using it's name (in the metadata)\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Service Discovery</h1>\n    <p>Service discovery is a mean for applications to find one another in the cluster.</p>\n    <p>There are two major components to service discovery</p>\n    <ul>\n      <li>Registration</li>\n      <li>Discovery</li>\n    </ul>\n    <p>Service registration is when an application registers itself in a <em>service registry</em>.</p>\n    <p>Kubernetes uses its internal DNS as a <em>service registry</em>, and as we know, <em>Services</em> are automatically registered with DNS.</p>\n    <p>For discovery to work, Kubernetes provides a well-known internal DNS services that are called the <strong>cluster DNS</strong>, in the namespace <strong>kube-system</strong>. Every <em>Pod</em> in the cluster is automatically configured to where this service is. The relevant <em>Pods</em> are managed by a <em>Deployment</em> called <strong>coredns</strong> and frontend by a <em>Service</em> called <strong>kube-dns</strong>.</p>\n    <p>For illustration</p>\n    <pre><code class=\"hljs language-angelscript\">kubectl <span class=\"hljs-keyword\">get</span> pods --<span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-symbol\">kube</span>-<span class=\"hljs-symbol\">system</span> --<span class=\"hljs-symbol\">selector</span> <span class=\"hljs-symbol\">k8s</span>-<span class=\"hljs-symbol\">app</span>=<span class=\"hljs-symbol\">kube</span>-<span class=\"hljs-symbol\">dns</span>\n\n<span class=\"hljs-symbol\">NAME</span>                       <span class=\"hljs-symbol\">READY</span>   <span class=\"hljs-symbol\">STATUS</span>    <span class=\"hljs-symbol\">RESTARTS</span>   <span class=\"hljs-symbol\">AGE</span>\n<span class=\"hljs-symbol\">coredns</span>-<span class=\"hljs-symbol\">6d4b75cb6d</span>-<span class=\"hljs-symbol\">4lpv9</span>   <span class=\"hljs-symbol\">1</span>/<span class=\"hljs-symbol\">1</span>     <span class=\"hljs-symbol\">Running</span>   <span class=\"hljs-symbol\">0</span>          <span class=\"hljs-symbol\">139m</span>\n<span class=\"hljs-symbol\">coredns</span>-<span class=\"hljs-symbol\">6d4b75cb6d</span>-<span class=\"hljs-symbol\">vmkfz</span>   <span class=\"hljs-symbol\">1</span>/<span class=\"hljs-symbol\">1</span>     <span class=\"hljs-symbol\">Running</span>   <span class=\"hljs-symbol\">0</span>          <span class=\"hljs-symbol\">139m</span>\n\n</code></pre>\n    <p>We specify a <em>Service</em> DNS using it's name (in the metadata)</p>\n  </body>\n</html>\n"}},{"id":"kubernetes/services","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/services.md","metadata":{"title":"Kubernetes Services","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Services \n\n_Service_ provides reliable access to _Pods_.\n\nMain _Service_ concepts\n\n- _Services_ are REST objects in the API that we define in a manifest file or post to the API server.\n- Every service gets it's own __stable IP address__, it's own __stable DNS name__ and it's own __stable port__.\n- _Services_ use __labels__ and __selectors__ to dynamically select the _Pods_ they send traffic to.\n\n_Services_ get a list of healthy pods that match the relevant selctors using a Kubernetes object called an _Endpoint_. Kubernetes is continuously monitoring the state of the _Pods_ and updates the relevant _Endpoints'_ lists.\n\n```bash\n              +----------------+     +------------+     +--------------------------+\n{request} --> | DNS resolution | --> | Service IP | --> | Pod in the Endpoint List |\n              +----------------+     +------------+     +--------------------------+\n```\n\nKubernetes native applications can query the API and directly find the _Service_ IP, bypassing DNS resolution.\n\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Services</h1>\n    <p><em>Service</em> provides reliable access to <em>Pods</em>.</p>\n    <p>Main <em>Service</em> concepts</p>\n    <ul>\n      <li><em>Services</em> are REST objects in the API that we define in a manifest file or post to the API server.</li>\n      <li>Every service gets it's own <strong>stable IP address</strong>, it's own <strong>stable DNS name</strong> and it's own <strong>stable port</strong>.</li>\n      <li><em>Services</em> use <strong>labels</strong> and <strong>selectors</strong> to dynamically select the <em>Pods</em> they send traffic to.</li>\n    </ul>\n    <p><em>Services</em> get a list of healthy pods that match the relevant selctors using a Kubernetes object called an <em>Endpoint</em>. Kubernetes is continuously monitoring the state of the <em>Pods</em> and updates the relevant <em>Endpoints'</em> lists.</p>\n    <pre><code class=\"hljs language-bash\">              +----------------+     +------------+     +--------------------------+\n{request} --> | DNS resolution | --> | Service IP | --> | Pod <span class=\"hljs-keyword\">in</span> the Endpoint List |\n              +----------------+     +------------+     +--------------------------+\n</code></pre>\n    <p>Kubernetes native applications can query the API and directly find the <em>Service</em> IP, bypassing DNS resolution.</p>\n  </body>\n</html>\n"}},{"id":"kubernetes/simple-on-prem-cluster","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/simple-on-prem-cluster.md","metadata":{"title":"Simple on-prem Kuberenetes cluster","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Kubes\n\nDeploy a kubernetes cluster.\n\nWe will setup a simple kubernetes cluster will describe the concepts and process.\n\nThe OS on all nodes is debian bullseye - I specifically executing this using vagrant's box ```debian/bullseye64```.\n\nTo document the steps we will provide bash script snippets for now. But, the goal is to provide configuration files content for something like ansible or chef.\n\n## Container runtime\n\nKubernetes is an orchestration infrastructure and does not provide any containerization - It relies on a different containarization platform, a.k.a the [Container Runtime](https://kubernetes.io/docs/setup/production-environment/container-runtimes/).\n\nWe will use [docker](https://www.docker.com/). Let's install it by following the documentation [Here](https://docs.docker.com/engine/install/debian/).\n\n```\nsudo apt-get remove docker docker-engine docker.io containerd runc\n\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg lsb-release\n\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io\n```\n\nAnother thing to do is docker to utilize systemd for cgroup management (You can read more about it in the container runtimes documentation). To apply this setting we need to edit docker's configuration. There are multiple to do so, for example - edit systemd's service that initiates docker. Another approach is to edit docker's global configuration file which is at ```/etc/docker/daemon.json```. Hence, edit (create if missing) the mentioned file and add\n\n```json\n{\n    ... other configurations\n    \"exec-opts\": [\"native.cgroupdriver=systemd\", ... more exec opts if exists]\n}\n```\n\nOnce done, reboot docker by running ```sudo systemctl restart docker```\n\n## Kube Components\n\nWe will not rely on the package manager to install the components.\n\nDefine the relevant variables\n\n> Note that the cni directory does not include the version! Later we will install a network plugin, it'll be in the same directory\n\n```\nARCH=\"amd64\"\nCNI_VERSION=\"v0.8.2\"\nCNI_DIR=\"/opt/cni/bin\"\nCRICTL_VERSION=\"v1.23.0\"\nCRICTL_DIR=\"/opt/cri/$CRICTL_VERSION/bin\"\nKUBERNETES_VERSION=\"v1.23.3\"\nKUBERNETES_DIR=\"/opt/kubernetes/$KUBERNETES_VERSION\"\n\n# Install [CNI](https://www.cni.dev/)\n\nsudo mkdir -p $CNI_DIR\ncurl -L \"https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz\" | sudo tar -C $CNI_DIR -xz\n\n# Install [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)\n\nsudo mkdir -p $CRICTL_DIR\ncurl -L \"https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz\" | sudo tar -C $CRICTL_DIR -xz\n\n# Install Kube components\n\nsudo mkdir -p $KUBERNETES_DIR\ncd $KUBERNETES_DIR\nfor component in kubeadm kubectl kubelet; do\n  sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/$KUBERNETES_VERSION/bin/linux/$ARCH/$component\n  sudo chmod +x $component\ndone\n\n# and services\n\nRELEASE_VERSION=\"v0.4.0\"\ncurl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\" | sed \"s:/usr/bin:${KUBERNETES_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service\nsudo mkdir -p /etc/systemd/system/kubelet.service.d\ncurl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\" | sed \"s:/usr/bin:${KUBERNETES_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n```\n\nenable, and start kubelet\n\n```\nsudo systemctl enable --now kubelet\n```\n\n## Initialization\n\nInstall prerequesites for kubeadm\n\n```\nsudo apt-get update \nsudo apt install ethtool socat conntrack\n```\n\nCreate an update alternative\n\n```\nsudo update-alternatives --install /usr/bin/kubeadm kubeadm $KUBERNETES_DIR/kubeadm 100\nsudo update-alternatives --install /usr/bin/kubelet kubelet $KUBERNETES_DIR/kubelet 100\nsudo update-alternatives --install /usr/bin/kubectl kubectl $KUBERNETES_DIR/kubectl 100\n```\n\nRun @controlplane\n\n> TODO: load balancer, hostnames\n\nInitialize configuration such that the network is 10.10.0.0/16\n\n```\nsudo kubeadm init --pod-network-cidr 10.10.0.0/16 --apiserver-advertise-address {ip}\n```\n\nFor documentation, you should see something like\n\n```\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.121.210:6443 --token clns4a.b29f6anjipygy0e2 \\\n\t--discovery-token-ca-cert-hash sha256:833f599cc9ab27eb5010c499e9c77e8e3263fb991d8e9e78ef187ba97e1efb59\n```\n\nDo as it says, run\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\nWe will use [Weave Net](https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/) as a network plugin\n\n```\nkubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"\n```\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Kubes</h1>\n    <p>Deploy a kubernetes cluster.</p>\n    <p>We will setup a simple kubernetes cluster will describe the concepts and process.</p>\n    <p>The OS on all nodes is debian bullseye - I specifically executing this using vagrant's box <code>debian/bullseye64</code>.</p>\n    <p>To document the steps we will provide bash script snippets for now. But, the goal is to provide configuration files content for something like ansible or chef.</p>\n    <h2>Container runtime</h2>\n    <p>Kubernetes is an orchestration infrastructure and does not provide any containerization - It relies on a different containarization platform, a.k.a the <a href=\"https://kubernetes.io/docs/setup/production-environment/container-runtimes/\">Container Runtime</a>.</p>\n    <p>We will use <a href=\"https://www.docker.com/\">docker</a>. Let's install it by following the documentation <a href=\"https://docs.docker.com/engine/install/debian/\">Here</a>.</p>\n    <pre><code class=\"hljs language-basic\">sudo apt-<span class=\"hljs-keyword\">get</span> <span class=\"hljs-comment\">remove docker docker-engine docker.io containerd runc</span>\n\nsudo apt-<span class=\"hljs-keyword\">get</span> update\nsudo apt-<span class=\"hljs-keyword\">get</span> install ca-certificates curl gnupg lsb-release\n\ncurl -fsSL https://download.docker.<span class=\"hljs-keyword\">com</span>/linux/debian/gpg | sudo gpg --dearmor -o /<span class=\"hljs-keyword\">usr</span>/share/keyrings/docker-archive-keyring.gpg\n\necho \\\n  <span class=\"hljs-string\">\"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\"</span> | sudo tee /etc/apt/sources.<span class=\"hljs-keyword\">list</span>.d/docker.<span class=\"hljs-keyword\">list</span> > /dev/null\n\nsudo apt-<span class=\"hljs-keyword\">get</span> update\nsudo apt-<span class=\"hljs-keyword\">get</span> install docker-ce docker-ce-cli containerd.io\n</code></pre>\n    <p>Another thing to do is docker to utilize systemd for cgroup management (You can read more about it in the container runtimes documentation). To apply this setting we need to edit docker's configuration. There are multiple to do so, for example - edit systemd's service that initiates docker. Another approach is to edit docker's global configuration file which is at <code>/etc/docker/daemon.json</code>. Hence, edit (create if missing) the mentioned file and add</p>\n    <pre><code class=\"hljs language-json\"><span class=\"hljs-punctuation\">{</span>\n    ... other configurations\n    <span class=\"hljs-attr\">\"exec-opts\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"native.cgroupdriver=systemd\"</span><span class=\"hljs-punctuation\">,</span> ... more exec opts if exists<span class=\"hljs-punctuation\">]</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre>\n    <p>Once done, reboot docker by running <code>sudo systemctl restart docker</code></p>\n    <h2>Kube Components</h2>\n    <p>We will not rely on the package manager to install the components.</p>\n    <p>Define the relevant variables</p>\n    <blockquote>\n      <p>Note that the cni directory does not include the version! Later we will install a network plugin, it'll be in the same directory</p>\n    </blockquote>\n    <pre><code class=\"hljs language-bash\">ARCH=<span class=\"hljs-string\">\"amd64\"</span>\nCNI_VERSION=<span class=\"hljs-string\">\"v0.8.2\"</span>\nCNI_DIR=<span class=\"hljs-string\">\"/opt/cni/bin\"</span>\nCRICTL_VERSION=<span class=\"hljs-string\">\"v1.23.0\"</span>\nCRICTL_DIR=<span class=\"hljs-string\">\"/opt/cri/<span class=\"hljs-variable\">$CRICTL_VERSION</span>/bin\"</span>\nKUBERNETES_VERSION=<span class=\"hljs-string\">\"v1.23.3\"</span>\nKUBERNETES_DIR=<span class=\"hljs-string\">\"/opt/kubernetes/<span class=\"hljs-variable\">$KUBERNETES_VERSION</span>\"</span>\n\n<span class=\"hljs-comment\"># Install [CNI](https://www.cni.dev/)</span>\n\nsudo <span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$CNI_DIR</span>\ncurl -L <span class=\"hljs-string\">\"https://github.com/containernetworking/plugins/releases/download/<span class=\"hljs-variable\">${CNI_VERSION}</span>/cni-plugins-linux-<span class=\"hljs-variable\">${ARCH}</span>-<span class=\"hljs-variable\">${CNI_VERSION}</span>.tgz\"</span> | sudo tar -C <span class=\"hljs-variable\">$CNI_DIR</span> -xz\n\n<span class=\"hljs-comment\"># Install [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)</span>\n\nsudo <span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$CRICTL_DIR</span>\ncurl -L <span class=\"hljs-string\">\"https://github.com/kubernetes-sigs/cri-tools/releases/download/<span class=\"hljs-variable\">${CRICTL_VERSION}</span>/crictl-<span class=\"hljs-variable\">${CRICTL_VERSION}</span>-linux-<span class=\"hljs-variable\">${ARCH}</span>.tar.gz\"</span> | sudo tar -C <span class=\"hljs-variable\">$CRICTL_DIR</span> -xz\n\n<span class=\"hljs-comment\"># Install Kube components</span>\n\nsudo <span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$KUBERNETES_DIR</span>\n<span class=\"hljs-built_in\">cd</span> <span class=\"hljs-variable\">$KUBERNETES_DIR</span>\n<span class=\"hljs-keyword\">for</span> component <span class=\"hljs-keyword\">in</span> kubeadm kubectl kubelet; <span class=\"hljs-keyword\">do</span>\n  sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/<span class=\"hljs-variable\">$KUBERNETES_VERSION</span>/bin/linux/<span class=\"hljs-variable\">$ARCH</span>/<span class=\"hljs-variable\">$component</span>\n  sudo <span class=\"hljs-built_in\">chmod</span> +x <span class=\"hljs-variable\">$component</span>\n<span class=\"hljs-keyword\">done</span>\n\n<span class=\"hljs-comment\"># and services</span>\n\nRELEASE_VERSION=<span class=\"hljs-string\">\"v0.4.0\"</span>\ncurl -sSL <span class=\"hljs-string\">\"https://raw.githubusercontent.com/kubernetes/release/<span class=\"hljs-variable\">${RELEASE_VERSION}</span>/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\"</span> | sed <span class=\"hljs-string\">\"s:/usr/bin:<span class=\"hljs-variable\">${KUBERNETES_DIR}</span>:g\"</span> | sudo <span class=\"hljs-built_in\">tee</span> /etc/systemd/system/kubelet.service\nsudo <span class=\"hljs-built_in\">mkdir</span> -p /etc/systemd/system/kubelet.service.d\ncurl -sSL <span class=\"hljs-string\">\"https://raw.githubusercontent.com/kubernetes/release/<span class=\"hljs-variable\">${RELEASE_VERSION}</span>/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\"</span> | sed <span class=\"hljs-string\">\"s:/usr/bin:<span class=\"hljs-variable\">${KUBERNETES_DIR}</span>:g\"</span> | sudo <span class=\"hljs-built_in\">tee</span> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n</code></pre>\n    <p>enable, and start kubelet</p>\n    <pre><code class=\"hljs language-pgsql\">sudo systemctl <span class=\"hljs-keyword\">enable</span> <span class=\"hljs-comment\">--now kubelet</span>\n</code></pre>\n    <h2>Initialization</h2>\n    <p>Install prerequesites for kubeadm</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">sudo</span> <span class=\"hljs-string\">apt-get update </span>\n<span class=\"hljs-attr\">sudo</span> <span class=\"hljs-string\">apt install ethtool socat conntrack</span>\n</code></pre>\n    <p>Create an update alternative</p>\n    <pre><code class=\"hljs language-awk\">sudo update-alternatives --install <span class=\"hljs-regexp\">/usr/</span>bin<span class=\"hljs-regexp\">/kubeadm kubeadm $KUBERNETES_DIR/</span>kubeadm <span class=\"hljs-number\">100</span>\nsudo update-alternatives --install <span class=\"hljs-regexp\">/usr/</span>bin<span class=\"hljs-regexp\">/kubelet kubelet $KUBERNETES_DIR/</span>kubelet <span class=\"hljs-number\">100</span>\nsudo update-alternatives --install <span class=\"hljs-regexp\">/usr/</span>bin<span class=\"hljs-regexp\">/kubectl kubectl $KUBERNETES_DIR/</span>kubectl <span class=\"hljs-number\">100</span>\n</code></pre>\n    <p>Run @controlplane</p>\n    <blockquote>\n      <p>TODO: load balancer, hostnames</p>\n    </blockquote>\n    <p>Initialize configuration such that the network is 10.10.0.0/16</p>\n    <pre><code class=\"hljs language-apache\"><span class=\"hljs-attribute\">sudo</span> kubeadm init --pod-network-cidr <span class=\"hljs-number\">10.10.0.0</span>/<span class=\"hljs-number\">16</span> --apiserver-advertise-address {ip}\n</code></pre>\n    <p>For documentation, you should see something like</p>\n    <pre><code class=\"hljs language-pgsql\">Your Kubernetes control-plane has initialized successfully!\n\n<span class=\"hljs-keyword\">To</span> <span class=\"hljs-keyword\">start</span> <span class=\"hljs-keyword\">using</span> your <span class=\"hljs-keyword\">cluster</span>, you need <span class=\"hljs-keyword\">to</span> run the <span class=\"hljs-keyword\">following</span> <span class=\"hljs-keyword\">as</span> a regular <span class=\"hljs-keyword\">user</span>:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/<span class=\"hljs-keyword\">admin</span>.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, <span class=\"hljs-keyword\">if</span> you are the root <span class=\"hljs-keyword\">user</span>, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/<span class=\"hljs-keyword\">admin</span>.conf\n\nYou should now deploy a pod network <span class=\"hljs-keyword\">to</span> the <span class=\"hljs-keyword\">cluster</span>.\nRun \"kubectl apply -f [podnetwork].yaml\" <span class=\"hljs-keyword\">with</span> one <span class=\"hljs-keyword\">of</span> the <span class=\"hljs-keyword\">options</span> listed at:\n  https://kubernetes.io/docs/concepts/<span class=\"hljs-keyword\">cluster</span>-administration/addons/\n\n<span class=\"hljs-keyword\">Then</span> you can <span class=\"hljs-keyword\">join</span> <span class=\"hljs-keyword\">any</span> number <span class=\"hljs-keyword\">of</span> worker nodes <span class=\"hljs-keyword\">by</span> running the <span class=\"hljs-keyword\">following</span> <span class=\"hljs-keyword\">on</span> <span class=\"hljs-keyword\">each</span> <span class=\"hljs-keyword\">as</span> root:\n\nkubeadm <span class=\"hljs-keyword\">join</span> <span class=\"hljs-number\">192.168</span><span class=\"hljs-number\">.121</span><span class=\"hljs-number\">.210</span>:<span class=\"hljs-number\">6443</span> <span class=\"hljs-comment\">--token clns4a.b29f6anjipygy0e2 \\</span>\n\t<span class=\"hljs-comment\">--discovery-token-ca-cert-hash sha256:833f599cc9ab27eb5010c499e9c77e8e3263fb991d8e9e78ef187ba97e1efb59</span>\n</code></pre>\n    <p>Do as it says, run</p>\n    <pre><code class=\"hljs language-bash\"><span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$HOME</span>/.kube\nsudo <span class=\"hljs-built_in\">cp</span> -i /etc/kubernetes/admin.conf <span class=\"hljs-variable\">$HOME</span>/.kube/config\nsudo <span class=\"hljs-built_in\">chown</span> $(<span class=\"hljs-built_in\">id</span> -u):$(<span class=\"hljs-built_in\">id</span> -g) <span class=\"hljs-variable\">$HOME</span>/.kube/config\n</code></pre>\n    <p>We will use <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/\">Weave Net</a> as a network plugin</p>\n    <pre><code class=\"hljs language-powershell\">kubectl apply <span class=\"hljs-operator\">-f</span> <span class=\"hljs-string\">\"https://cloud.weave.works/k8s/net?k8s-version=<span class=\"hljs-variable\">$</span>(kubectl version | base64 | tr -d '\\n')\"</span>\n</code></pre>\n  </body>\n</html>\n"}},{"id":"kubernetes/storage","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/storage.md","metadata":{"title":"Storage","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\nKubernetes abstracts the storage through a __plugin layer__. The plugin layer is the interface that connects external storage with Kubernetes. The layer can mediate between any kind of storage, be it file based, bloc of object based, on-prem or cloud.\n\nMost plugins are based on the __Container Storage Interface (CSI)__ which is an open standard.\n\n> TBD\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>Kubernetes abstracts the storage through a <strong>plugin layer</strong>. The plugin layer is the interface that connects external storage with Kubernetes. The layer can mediate between any kind of storage, be it file based, bloc of object based, on-prem or cloud.</p>\n    <p>Most plugins are based on the <strong>Container Storage Interface (CSI)</strong> which is an open standard.</p>\n    <blockquote>\n      <p>TBD</p>\n    </blockquote>\n  </body>\n</html>\n"}},{"id":"kubernetes/technical-overview","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/technical-overview.md","metadata":{"title":"Kubernetes technical overview","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n## Application packaging\n\nAn application should be\n\n1. Packaged as a container\n1. Wrapped in a _Pod_\n1. Deployed via a declerative manifest file\n\n## The declerative model \n\nAccording to the _declerative model_, we only declare about how we want the application to look like. It is Kubernetes' jpb to make sure the cluster behaves as intended.\n\n_Manifests_ simple YAML files and they tell Kubernetes how the application should look like - the _desired state_.\n\n_Controllers_ are constantly running and monitor the application's state, reconciling and difference betweeen the _observerd state_ and the _desired state_.\n\n## Pods\n\nIn Kubernetes, _Pods_ are the atomic unit of scheduling. Kubernetes demands that every container runs inside a pod.\n\nA simple model is to run a sigle container in every pod. \n\nEffectively, a _Pod_ is a construct for running one or more containers.\n\nPods are the most basic unit of scaling. We scale applications by adding or removing pods (not containers).\n\nPods are deployed atomiclly. A pod is ready only when all containers are up and running. A single pod executes on a single Node.\n\nWhen a pod dies, a new one takes it's place. The new pod is a different instance with the same semantics, it has different id, ip etc..\n\nPods are immutable. If we want to change a pod's configuration, we must create a new pod to take it's place.\n\n### Pod theory\n\nThere are 3 main reasons for Pods to exist\n\n1. Pods augment containers 1. Pods assist in scheduling\n1. Pods enable resource sharing\n\nThe augmentation is done in the following ways\n\n- Labels / annotations\n- Restart policies\n- Probes (startup, readiness, liveness etc...)\n- Affinity / anti-affinity rules (Affinities are related to specifying how specific pods behave with other pods)\n- Termination control\n- Security policies\n- Resource requests and limits (min/max values on CPU, memory and I/O)\n\nPods have __Labels__ which lets us group Pods and associate them with other objects. \n\nRegarding resource sharing, Pods provide _shared execution environment_ for one or more containers. It includes\n\n- Filesystem\n- Network stack (IP address, routing, ports)\n- Memory\n- Volumes\n\nPods can be deployed either directly via a Pod manifest or indirectly via a controller. Pods deployed directly are called _static pods_.\n\n## Deployments\n\nA _Deployment_ is a higher-level controller. Usually we will deploy pods indirectly via a deployment.\n\nThe deployment controller monitors the state of a wrapped pod providing extra features such as self-healing, scaling, zero-downtime rollouts and versioned rollbacks.\n\n## Services\n\nA _Service_ is a Kubernetes contstruct which provides reliable networking for a set of pods.\n\nAs we know, pods are immutable and modifications due to auto scaling, rollbacks etc... result in replacements of pods - and the effective IPs.\n\n_Services_ provide reliable names and IPs and provide load balancing capabilities over a set of pods.\n\n## Examples of controllers\n\n- Deployments\n- DaemonSets\n- StatefulSets\n\n## Generall usefull commands\n\nList all possible Pod attributes\n\n    kubectl explain pods --recursive\n\n## Multi container patterns\n\nKubernetes offers several well-defined multi-container Pod patterns\n\n### Sidecar pattern\n\nThis pattern has a _main_ application container and a _sidecar_ container. The _sidecar's_ job is to augment and perform secondary tasks for the _main_ application container.\n\n### Adapter pattern\n\nThis pattern is a specific variation of the _sidecar pattern_ where the _sidecar_ container takes non-standardized output from the _main_ container and standardize it as required by an external system.\n\n### Ambassador pattern\n\nThis is another variation of the _sidecar pattern_ where the _sidecar_ brokers connectivity to an external system.\n\n### Init pattern\n\nThis pattern has an _init_ container that's gauranteed to start and complete before your _main_ application container. It is also gauranteed to run exactly once!\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h2>Application packaging</h2>\n    <p>An application should be</p>\n    <ol>\n      <li>Packaged as a container</li>\n      <li>Wrapped in a <em>Pod</em></li>\n      <li>Deployed via a declerative manifest file</li>\n    </ol>\n    <h2>The declerative model</h2>\n    <p>According to the <em>declerative model</em>, we only declare about how we want the application to look like. It is Kubernetes' jpb to make sure the cluster behaves as intended.</p>\n    <p><em>Manifests</em> simple YAML files and they tell Kubernetes how the application should look like - the <em>desired state</em>.</p>\n    <p><em>Controllers</em> are constantly running and monitor the application's state, reconciling and difference betweeen the <em>observerd state</em> and the <em>desired state</em>.</p>\n    <h2>Pods</h2>\n    <p>In Kubernetes, <em>Pods</em> are the atomic unit of scheduling. Kubernetes demands that every container runs inside a pod.</p>\n    <p>A simple model is to run a sigle container in every pod.</p>\n    <p>Effectively, a <em>Pod</em> is a construct for running one or more containers.</p>\n    <p>Pods are the most basic unit of scaling. We scale applications by adding or removing pods (not containers).</p>\n    <p>Pods are deployed atomiclly. A pod is ready only when all containers are up and running. A single pod executes on a single Node.</p>\n    <p>When a pod dies, a new one takes it's place. The new pod is a different instance with the same semantics, it has different id, ip etc..</p>\n    <p>Pods are immutable. If we want to change a pod's configuration, we must create a new pod to take it's place.</p>\n    <h3>Pod theory</h3>\n    <p>There are 3 main reasons for Pods to exist</p>\n    <ol>\n      <li>Pods augment containers 1. Pods assist in scheduling</li>\n      <li>Pods enable resource sharing</li>\n    </ol>\n    <p>The augmentation is done in the following ways</p>\n    <ul>\n      <li>Labels / annotations</li>\n      <li>Restart policies</li>\n      <li>Probes (startup, readiness, liveness etc...)</li>\n      <li>Affinity / anti-affinity rules (Affinities are related to specifying how specific pods behave with other pods)</li>\n      <li>Termination control</li>\n      <li>Security policies</li>\n      <li>Resource requests and limits (min/max values on CPU, memory and I/O)</li>\n    </ul>\n    <p>Pods have <strong>Labels</strong> which lets us group Pods and associate them with other objects.</p>\n    <p>Regarding resource sharing, Pods provide <em>shared execution environment</em> for one or more containers. It includes</p>\n    <ul>\n      <li>Filesystem</li>\n      <li>Network stack (IP address, routing, ports)</li>\n      <li>Memory</li>\n      <li>Volumes</li>\n    </ul>\n    <p>Pods can be deployed either directly via a Pod manifest or indirectly via a controller. Pods deployed directly are called <em>static pods</em>.</p>\n    <h2>Deployments</h2>\n    <p>A <em>Deployment</em> is a higher-level controller. Usually we will deploy pods indirectly via a deployment.</p>\n    <p>The deployment controller monitors the state of a wrapped pod providing extra features such as self-healing, scaling, zero-downtime rollouts and versioned rollbacks.</p>\n    <h2>Services</h2>\n    <p>A <em>Service</em> is a Kubernetes contstruct which provides reliable networking for a set of pods.</p>\n    <p>As we know, pods are immutable and modifications due to auto scaling, rollbacks etc... result in replacements of pods - and the effective IPs.</p>\n    <p><em>Services</em> provide reliable names and IPs and provide load balancing capabilities over a set of pods.</p>\n    <h2>Examples of controllers</h2>\n    <ul>\n      <li>Deployments</li>\n      <li>DaemonSets</li>\n      <li>StatefulSets</li>\n    </ul>\n    <h2>Generall usefull commands</h2>\n    <p>List all possible Pod attributes</p>\n    <pre><code class=\"hljs language-pgsql\">kubectl <span class=\"hljs-keyword\">explain</span> pods <span class=\"hljs-comment\">--recursive</span>\n</code></pre>\n    <h2>Multi container patterns</h2>\n    <p>Kubernetes offers several well-defined multi-container Pod patterns</p>\n    <h3>Sidecar pattern</h3>\n    <p>This pattern has a <em>main</em> application container and a <em>sidecar</em> container. The <em>sidecar's</em> job is to augment and perform secondary tasks for the <em>main</em> application container.</p>\n    <h3>Adapter pattern</h3>\n    <p>This pattern is a specific variation of the <em>sidecar pattern</em> where the <em>sidecar</em> container takes non-standardized output from the <em>main</em> container and standardize it as required by an external system.</p>\n    <h3>Ambassador pattern</h3>\n    <p>This is another variation of the <em>sidecar pattern</em> where the <em>sidecar</em> brokers connectivity to an external system.</p>\n    <h3>Init pattern</h3>\n    <p>This pattern has an <em>init</em> container that's gauranteed to start and complete before your <em>main</em> application container. It is also gauranteed to run exactly once!</p>\n  </body>\n</html>\n"}},{"id":"markdown","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/markdown.md","metadata":{"title":"Markdown","description":null,"permalink":null,"priority":0,"tags":[],"categories":[]},"content":{"raw":"\n# Header 1\n## Header 2\n### Header 3\n#### Header 4\n##### Header 5\n###### Header 6\n\nContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32.\n\nThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.\n\n> This is some quote\n\n__Some Math__\n\n$\\forall h \\in H$\n\n__Ordered list__\n\n1. First Item  \n1. Second Item  \n1. Third Item  \n\n__Unordered list__\n\n- First  \n- Second  \n- Third  \n\n\n| id | name              | phone            | description      |\n|----|-------------------|------------------|------------------|\n| 1  | Ricky Phelps      | +123 123 5555555 | Some description |\n| 2  | Asha Valdez       | +123 123 5555555 |                  |\n| 3  | Katelyn Dougherty | +123 123 5555555 |                  |\n\n```python\n# Some example python code\nclass BinaryOperation:\n  def __init__(self, operation):\n    self.operation = operation\n  \n  def operate(self, x, y):\n    return self.operation(x, y)\n\n  def __call__(self, x, y):\n    return self.operate(x, y)\n```","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Header 1</h1>\n    <h2>Header 2</h2>\n    <h3>Header 3</h3>\n    <h4>Header 4</h4>\n    <h5>Header 5</h5>\n    <h6>Header 6</h6>\n    <p>Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32.</p>\n    <p>The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.</p>\n    <blockquote>\n      <p>This is some quote</p>\n    </blockquote>\n    <p><strong>Some Math</strong></p>\n    <p>$\\forall h \\in H$</p>\n    <p><strong>Ordered list</strong></p>\n    <ol>\n      <li>First Item</li>\n      <li>Second Item</li>\n      <li>Third Item</li>\n    </ol>\n    <p><strong>Unordered list</strong></p>\n    <ul>\n      <li>First</li>\n      <li>Second</li>\n      <li>Third</li>\n    </ul>\n    <table>\n      <thead>\n        <tr>\n          <th>id</th>\n          <th>name</th>\n          <th>phone</th>\n          <th>description</th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <td>1</td>\n          <td>Ricky Phelps</td>\n          <td>+123 123 5555555</td>\n          <td>Some description</td>\n        </tr>\n        <tr>\n          <td>2</td>\n          <td>Asha Valdez</td>\n          <td>+123 123 5555555</td>\n          <td></td>\n        </tr>\n        <tr>\n          <td>3</td>\n          <td>Katelyn Dougherty</td>\n          <td>+123 123 5555555</td>\n          <td></td>\n        </tr>\n      </tbody>\n    </table>\n    <pre><code class=\"hljs language-python\"><span class=\"hljs-comment\"># Some example python code</span>\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BinaryOperation</span>:\n  <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, operation</span>):\n    self.operation = operation\n  \n  <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">operate</span>(<span class=\"hljs-params\">self, x, y</span>):\n    <span class=\"hljs-keyword\">return</span> self.operation(x, y)\n\n  <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__call__</span>(<span class=\"hljs-params\">self, x, y</span>):\n    <span class=\"hljs-keyword\">return</span> self.operate(x, y)\n</code></pre>\n  </body>\n</html>\n"}},{"id":"posts/archlinux-installation-guide","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/archlinux-installation-guide.md","metadata":{"title":"Archlinux Installation Guide","description":null,"permalink":null,"priority":0,"tags":["Archlinux","Linux"],"categories":["Guides"]},"content":{"raw":"\n# arch boot spec\n\nthis is specific to my machine and software of choice\n- efi boot\n- disk at sdb \n- netctl as network manager in boot environment\n- networkmanager as network manager in installation\n\ni edit this file in parallel to the installation and learning process; if you want to do this as well, install git from the boot environment (or use elinks to view the file through github)\n\n## connect to network\n\n```wifi-menu``` and follow instructions\n\ncheck connectivity\n\n```ping 8.8.8.8```\n\nin ```/etc/nsswitch.conf```, at the ```hosts``` entry, make sure ```dns``` is before ```[!UNAVAIL=return]```\n\ncheck dns acquisition\n\n```ping google.com```\n\n## partition, filesystems and mount\n\nbe careful, assume each step to erase all data on partition layout of the disk!\n\nmake sure on which device you want to work on, using ```lsblk```\n\nerase labels ```wipefs -a /dev/sdb```\n\nexample partition scheme below\n\n> you can use ```fdisk``` or ```cfdisk``` for example\n\npartition | size  | type             | desc\n----------|-------|------------------|----------------\nsdb1      | 550MB | EFI System       | boot partition\nsdb2      | 24GB  | Linux swap       | swap partition\nsdb3      | 32GB  | Linux filesystem  | root partition\nsdb4      | rest  | Linux filesystem  | home partition\n\nmake filesystems for the partitions\n\n```bash\nmkfs.fat -F32 /dev/sdb1\n\nmkswap /dev/sdb2\nswapon /dev/sdb2\n\nmkfs.ext4 /dev/sdb3\nmkfs.ext4 /dev/sdb4\n```\n\nmount partitions to filesystem\n\n```bash\nmount /dev/sdb3 /mnt\n\nmkdir /mnt/boot\nmkdir /mnt/boot/efi\nmkdir /mnt/home\n\nmount /dev/sdb4 /mnt/home\nmount /dev/sdb1 /mnt/boot/efi\n```\n\n## archlinux installation\n\n```bash\npacstrap /mnt \\\n    base base-devel \\\n    linux linux-firmware \\\n    grub efibootmgr \\\n    networkmanager \\\n    vim git\n```\n\n## installation setup\n\ngenerate fstab - ```genfstab -U /mnt >> /mnt/etc/fstab```\n\nchange root to installation - ```arch-chroot /mnt```\n\nedit file ```/etc/locale.gen``` and uncomment desired locale\n\ngenerate locale - ```locale-gen```\n\nadd set language - ```echo \"LANG=en_US.UTF-8\" > /etc/locale.conf```\n\nset timezone -\n\n```bash\nln -sf /usr/share/zoneinfo/Asia/Jerusalem /etc/localtime\nhwclock --systohc\n```\n\nset root password for linux installation - ```passwd```\n\n## grub\n\n```bash\ngrub-install --target=x86_64-efi --efi-directory=/boot/efi\ngrub-mkconfig -o /boot/grub/grub.cfg\n```\n\n## finalize\n\nback to bootable environment\n\n```exit```\n\nunmount all partitions\n\n```umount -R /mnt```\n\n```reboot```\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>arch boot spec</h1>\n    <p>this is specific to my machine and software of choice</p>\n    <ul>\n      <li>efi boot</li>\n      <li>disk at sdb</li>\n      <li>netctl as network manager in boot environment</li>\n      <li>networkmanager as network manager in installation</li>\n    </ul>\n    <p>i edit this file in parallel to the installation and learning process; if you want to do this as well, install git from the boot environment (or use elinks to view the file through github)</p>\n    <h2>connect to network</h2>\n    <p><code>wifi-menu</code> and follow instructions</p>\n    <p>check connectivity</p>\n    <p><code>ping 8.8.8.8</code></p>\n    <p>in <code>/etc/nsswitch.conf</code>, at the <code>hosts</code> entry, make sure <code>dns</code> is before <code>[!UNAVAIL=return]</code></p>\n    <p>check dns acquisition</p>\n    <p><code>ping google.com</code></p>\n    <h2>partition, filesystems and mount</h2>\n    <p>be careful, assume each step to erase all data on partition layout of the disk!</p>\n    <p>make sure on which device you want to work on, using <code>lsblk</code></p>\n    <p>erase labels <code>wipefs -a /dev/sdb</code></p>\n    <p>example partition scheme below</p>\n    <blockquote>\n      <p>you can use <code>fdisk</code> or <code>cfdisk</code> for example</p>\n    </blockquote>\n    <table>\n      <thead>\n        <tr>\n          <th>partition</th>\n          <th>size</th>\n          <th>type</th>\n          <th>desc</th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <td>sdb1</td>\n          <td>550MB</td>\n          <td>EFI System</td>\n          <td>boot partition</td>\n        </tr>\n        <tr>\n          <td>sdb2</td>\n          <td>24GB</td>\n          <td>Linux swap</td>\n          <td>swap partition</td>\n        </tr>\n        <tr>\n          <td>sdb3</td>\n          <td>32GB</td>\n          <td>Linux filesystem</td>\n          <td>root partition</td>\n        </tr>\n        <tr>\n          <td>sdb4</td>\n          <td>rest</td>\n          <td>Linux filesystem</td>\n          <td>home partition</td>\n        </tr>\n      </tbody>\n    </table>\n    <p>make filesystems for the partitions</p>\n    <pre><code class=\"hljs language-bash\">mkfs.fat -F32 /dev/sdb1\n\nmkswap /dev/sdb2\nswapon /dev/sdb2\n\nmkfs.ext4 /dev/sdb3\nmkfs.ext4 /dev/sdb4\n</code></pre>\n    <p>mount partitions to filesystem</p>\n    <pre><code class=\"hljs language-bash\">mount /dev/sdb3 /mnt\n\n<span class=\"hljs-built_in\">mkdir</span> /mnt/boot\n<span class=\"hljs-built_in\">mkdir</span> /mnt/boot/efi\n<span class=\"hljs-built_in\">mkdir</span> /mnt/home\n\nmount /dev/sdb4 /mnt/home\nmount /dev/sdb1 /mnt/boot/efi\n</code></pre>\n    <h2>archlinux installation</h2>\n    <pre><code class=\"hljs language-bash\">pacstrap /mnt \\\n    base base-devel \\\n    linux linux-firmware \\\n    grub efibootmgr \\\n    networkmanager \\\n    vim git\n</code></pre>\n    <h2>installation setup</h2>\n    <p>generate fstab - <code>genfstab -U /mnt >> /mnt/etc/fstab</code></p>\n    <p>change root to installation - <code>arch-chroot /mnt</code></p>\n    <p>edit file <code>/etc/locale.gen</code> and uncomment desired locale</p>\n    <p>generate locale - <code>locale-gen</code></p>\n    <p>add set language - <code>echo \"LANG=en_US.UTF-8\" > /etc/locale.conf</code></p>\n    <p>set timezone -</p>\n    <pre><code class=\"hljs language-bash\"><span class=\"hljs-built_in\">ln</span> -sf /usr/share/zoneinfo/Asia/Jerusalem /etc/localtime\nhwclock --systohc\n</code></pre>\n    <p>set root password for linux installation - <code>passwd</code></p>\n    <h2>grub</h2>\n    <pre><code class=\"hljs language-bash\">grub-install --target=x86_64-efi --efi-directory=/boot/efi\ngrub-mkconfig -o /boot/grub/grub.cfg\n</code></pre>\n    <h2>finalize</h2>\n    <p>back to bootable environment</p>\n    <p><code>exit</code></p>\n    <p>unmount all partitions</p>\n    <p><code>umount -R /mnt</code></p>\n    <p><code>reboot</code></p>\n  </body>\n</html>\n"}},{"id":"posts/argocd","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/argocd.md","metadata":{"title":"ArgoCD","description":null,"permalink":null,"priority":0,"tags":["ArgoCD","Kubernetes"],"categories":["ArgoCD"]},"content":{"raw":"\nThis is not formal, but text I keep for my own reference\n\n# Overview\n\n> Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.\n\n## Architecture\n\n### API Server\n\n> gRPC/REST server which exposes the API consumed by the Web UI, CLI and CI/CD systems\n\nPractically, we contact the API Server to define and observer the CD\n\n### Repository Server\n\nManages Git access by caching, generating and returning the Kubernetes manifests.\n\n### Application Controller\n\nThe Application Controller monitors the state of the clusters and reconcile them according to CD definitions.\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>This is not formal, but text I keep for my own reference</p>\n    <h1>Overview</h1>\n    <blockquote>\n      <p>Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.</p>\n    </blockquote>\n    <h2>Architecture</h2>\n    <h3>API Server</h3>\n    <blockquote>\n      <p>gRPC/REST server which exposes the API consumed by the Web UI, CLI and CI/CD systems</p>\n    </blockquote>\n    <p>Practically, we contact the API Server to define and observer the CD</p>\n    <h3>Repository Server</h3>\n    <p>Manages Git access by caching, generating and returning the Kubernetes manifests.</p>\n    <h3>Application Controller</h3>\n    <p>The Application Controller monitors the state of the clusters and reconcile them according to CD definitions.</p>\n  </body>\n</html>\n"}},{"id":"posts/data-engineering-demystified-summary","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/data-engineering-demystified-summary.md","metadata":{"title":"Data Engineering Demistified Summary","description":null,"permalink":null,"priority":0,"tags":[],"categories":[]},"content":{"raw":"\n# Demistified summary\n\nSee http://big-data-demystified.ninja\n\nSpecifically\n- http://big-data-demystified.ninja/2020/07/09/data-lake-architecture-best-practices\n\n## Using Version Control Systems\n\nEnvironment suggestions\n\n- Dev. Has Read only access of Production data.\n- Pre Production. Because some thing can only be tested against production.\n- Production.\n\n\n## Airflow Coding Guidlines\n\n**Keep it simple**. Avoid object oriented abstraction. Very hard to retrospectively understand DAGs, simplicity is king here.\n\n**Avoid using Sensors - Airflow Term?**. Unpredictabilty in production.\n\nIt is prefereable if Jobs are\n\n- Recurrentable - Running the same job again won't change nothing\n- Debugable - can debug the job easily\n- Write after Delete - When deleting data, insert it right after, don't do that in another stage \n**Monitoring is very important!!!**\n\nPros\n- flexibility\n- customizability\n- scale\n- cost\n\nCons\n- learning curve\n- diy\n- time to market\n- open source\n- unclear errors\n\n## Data lake\n\n1. Data quality - MonteCarlo, Great Expectations\n1. Data pipeline stability - Databand and Honey Comb\n1. Data lineage - Apache atlas, amundsen\n1. Data classification\n\n## Cleansing and Preparing data\n\nApproaches\n\n**Python parser**\n\nPros - Simple\nCons - non uniform, hard to maintain\n\n**Dataframe / Pandas**\n\nPros - Simple, Generic, Flexible\nCons - Not scalable, bounded to the RAM\n\n**ELT**\n\nPros - Simple, Generic, Peta-Scale \nCons - Requires Good SQL / Big Data understanding\n\n**Pyspark / Scala**\n\nCons\n- Hard to learn\n- Trivial for simple cases / overkill\n\nPros\n- Good for schema evolution\n\n## 3rd party - APIs, Tips and Tricks\n\n\n## 4 V's\n\n- Volume\n- Veracity\n- Velocity\n- Variety\n\n## Triangle\n\nWhat is the criteria?\n\n```\n       Faster\n\n    /          \\\n\nCheaper  -   Simpler\n```\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Demistified summary</h1>\n    <p>See <a href=\"http://big-data-demystified.ninja\">http://big-data-demystified.ninja</a></p>\n    <p>Specifically</p>\n    <ul>\n      <li><a href=\"http://big-data-demystified.ninja/2020/07/09/data-lake-architecture-best-practices\">http://big-data-demystified.ninja/2020/07/09/data-lake-architecture-best-practices</a></li>\n    </ul>\n    <h2>Using Version Control Systems</h2>\n    <p>Environment suggestions</p>\n    <ul>\n      <li>Dev. Has Read only access of Production data.</li>\n      <li>Pre Production. Because some thing can only be tested against production.</li>\n      <li>Production.</li>\n    </ul>\n    <h2>Airflow Coding Guidlines</h2>\n    <p><strong>Keep it simple</strong>. Avoid object oriented abstraction. Very hard to retrospectively understand DAGs, simplicity is king here.</p>\n    <p><strong>Avoid using Sensors - Airflow Term?</strong>. Unpredictabilty in production.</p>\n    <p>It is prefereable if Jobs are</p>\n    <ul>\n      <li>Recurrentable - Running the same job again won't change nothing</li>\n      <li>Debugable - can debug the job easily</li>\n      <li>\n        Write after Delete - When deleting data, insert it right after, don't do that in another stage\n        <strong>Monitoring is very important!!!</strong>\n      </li>\n    </ul>\n    <p>Pros</p>\n    <ul>\n      <li>flexibility</li>\n      <li>customizability</li>\n      <li>scale</li>\n      <li>cost</li>\n    </ul>\n    <p>Cons</p>\n    <ul>\n      <li>learning curve</li>\n      <li>diy</li>\n      <li>time to market</li>\n      <li>open source</li>\n      <li>unclear errors</li>\n    </ul>\n    <h2>Data lake</h2>\n    <ol>\n      <li>Data quality - MonteCarlo, Great Expectations</li>\n      <li>Data pipeline stability - Databand and Honey Comb</li>\n      <li>Data lineage - Apache atlas, amundsen</li>\n      <li>Data classification</li>\n    </ol>\n    <h2>Cleansing and Preparing data</h2>\n    <p>Approaches</p>\n    <p><strong>Python parser</strong></p>\n    <p>\n      Pros - Simple\n      Cons - non uniform, hard to maintain\n    </p>\n    <p><strong>Dataframe / Pandas</strong></p>\n    <p>\n      Pros - Simple, Generic, Flexible\n      Cons - Not scalable, bounded to the RAM\n    </p>\n    <p><strong>ELT</strong></p>\n    <p>\n      Pros - Simple, Generic, Peta-Scale\n      Cons - Requires Good SQL / Big Data understanding\n    </p>\n    <p><strong>Pyspark / Scala</strong></p>\n    <p>Cons</p>\n    <ul>\n      <li>Hard to learn</li>\n      <li>Trivial for simple cases / overkill</li>\n    </ul>\n    <p>Pros</p>\n    <ul>\n      <li>Good for schema evolution</li>\n    </ul>\n    <h2>3rd party - APIs, Tips and Tricks</h2>\n    <h2>4 V's</h2>\n    <ul>\n      <li>Volume</li>\n      <li>Veracity</li>\n      <li>Velocity</li>\n      <li>Variety</li>\n    </ul>\n    <h2>Triangle</h2>\n    <p>What is the criteria?</p>\n    <pre><code class=\"hljs language-properties\">       <span class=\"hljs-attr\">Faster</span>\n\n    <span class=\"hljs-attr\">/</span>          <span class=\"hljs-string\">\\\n</span>\n<span class=\"hljs-attr\">Cheaper</span>  <span class=\"hljs-string\">-   Simpler</span>\n</code></pre>\n  </body>\n</html>\n"}},{"id":"posts/emacs-cheetsheet","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/emacs-cheetsheet.md","metadata":{"title":"Emacs Cheatsheet","description":null,"permalink":null,"priority":0,"tags":["Emacs"],"categories":["Cheatsheet"]},"content":{"raw":"\n# Overview \n\nSome tasks or workflows are very mature through emacs and less on other enviornments, for example using clojure repl, editing latex files, scheme work etc...\n\nCreated this file because I use vim in my day to I keep forgetting basic emacs stuff\n\n# emacs\n\n#### open emacs in the terminal emulator\n\n    emacs -nw\n\n#### configuration path\n\n    ~/emacs.d/\n\n# help\n\nIt's important to know how to get help and use the documentations within emacs\n\nEnter tutorial\n\n    C-h t\n\nEnter package documentation\n\n    C-h i d m {package}\n\n# basic keys\n\n## core\n\n    C-x C-x        exit\n    C-g            abort command\n\n## navigation\n\n    C-l     Center text around the cursor\n    \n    C-v     Scroll to next screenful\n    M-v     Scroll to previous screenful\n\n    M-f     Move forward a word\n    M-b     Move backward a word\n    \n    C-n     Move to next line\n    C-p     Move to previous line\n    \n    C-a     Move to beginning of line\n    C-e     Move to end of line\n    \n    M-a     Move back to beginning of sentence\n    M-e     Move forward to end of sentence\n\n    M-<     Move to beginning of the document\n    M->     Move to end of the document\n\n    C-s     Initiate search mode\n\n## windowing\n\n    C-x 1   Delete all windows except focused\n    C-x 2   Split current window horizontally\n    C-x 3   Split current window verticall\n    C-x o   Move to other window\n\n## editing\n\n    C-k     Delete from cursor to end of line\n    M-k     Delete from cursor to end of sentence\n    C-_     Undo\n    C-w     Cut selected region\n    M-w     Copy selected region\n    C-y     Paste\n\n## files and buffers\n\n    C-s         Save current file\n    C-x k       Kill buffer\n    C-x b       Switch to buffer\n    C-x C-b     Lits buffers","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Overview</h1>\n    <p>Some tasks or workflows are very mature through emacs and less on other enviornments, for example using clojure repl, editing latex files, scheme work etc...</p>\n    <p>Created this file because I use vim in my day to I keep forgetting basic emacs stuff</p>\n    <h1>emacs</h1>\n    <h4>open emacs in the terminal emulator</h4>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">emacs</span> <span class=\"hljs-string\">-nw</span>\n</code></pre>\n    <h4>configuration path</h4>\n    <pre><code class=\"hljs language-arcade\">~<span class=\"hljs-regexp\">/emacs.d/</span>\n</code></pre>\n    <h1>help</h1>\n    <p>It's important to know how to get help and use the documentations within emacs</p>\n    <p>Enter tutorial</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">C-h</span> <span class=\"hljs-string\">t</span>\n</code></pre>\n    <p>Enter package documentation</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">C-h</span> <span class=\"hljs-string\">i d m {package}</span>\n</code></pre>\n    <h1>basic keys</h1>\n    <h2>core</h2>\n    <pre><code class=\"hljs language-awk\">C-x C-x        <span class=\"hljs-keyword\">exit</span>\nC-g            abort command\n</code></pre>\n    <h2>navigation</h2>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">C-l</span>     <span class=\"hljs-string\">Center text around the cursor</span>\n\n<span class=\"hljs-attr\">C-v</span>     <span class=\"hljs-string\">Scroll to next screenful</span>\n<span class=\"hljs-attr\">M-v</span>     <span class=\"hljs-string\">Scroll to previous screenful</span>\n\n<span class=\"hljs-attr\">M-f</span>     <span class=\"hljs-string\">Move forward a word</span>\n<span class=\"hljs-attr\">M-b</span>     <span class=\"hljs-string\">Move backward a word</span>\n\n<span class=\"hljs-attr\">C-n</span>     <span class=\"hljs-string\">Move to next line</span>\n<span class=\"hljs-attr\">C-p</span>     <span class=\"hljs-string\">Move to previous line</span>\n\n<span class=\"hljs-attr\">C-a</span>     <span class=\"hljs-string\">Move to beginning of line</span>\n<span class=\"hljs-attr\">C-e</span>     <span class=\"hljs-string\">Move to end of line</span>\n\n<span class=\"hljs-attr\">M-a</span>     <span class=\"hljs-string\">Move back to beginning of sentence</span>\n<span class=\"hljs-attr\">M-e</span>     <span class=\"hljs-string\">Move forward to end of sentence</span>\n\n<span class=\"hljs-attr\">M-&#x3C;</span>     <span class=\"hljs-string\">Move to beginning of the document</span>\n<span class=\"hljs-attr\">M-></span>     <span class=\"hljs-string\">Move to end of the document</span>\n\n<span class=\"hljs-attr\">C-s</span>     <span class=\"hljs-string\">Initiate search mode</span>\n</code></pre>\n    <h2>windowing</h2>\n    <pre><code class=\"hljs language-pgsql\">C-x <span class=\"hljs-number\">1</span>   <span class=\"hljs-keyword\">Delete</span> <span class=\"hljs-keyword\">all</span> windows <span class=\"hljs-keyword\">except</span> focused\nC-x <span class=\"hljs-number\">2</span>   Split <span class=\"hljs-keyword\">current</span> <span class=\"hljs-keyword\">window</span> horizontally\nC-x <span class=\"hljs-number\">3</span>   Split <span class=\"hljs-keyword\">current</span> <span class=\"hljs-keyword\">window</span> verticall\nC-x o   <span class=\"hljs-keyword\">Move</span> <span class=\"hljs-keyword\">to</span> other <span class=\"hljs-keyword\">window</span>\n</code></pre>\n    <h2>editing</h2>\n    <pre><code class=\"hljs language-pgsql\">C-k     <span class=\"hljs-keyword\">Delete</span> <span class=\"hljs-keyword\">from</span> <span class=\"hljs-keyword\">cursor</span> <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">end</span> <span class=\"hljs-keyword\">of</span> <span class=\"hljs-type\">line</span>\nM-k     <span class=\"hljs-keyword\">Delete</span> <span class=\"hljs-keyword\">from</span> <span class=\"hljs-keyword\">cursor</span> <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">end</span> <span class=\"hljs-keyword\">of</span> sentence\nC-_     Undo\nC-w     Cut selected region\nM-w     <span class=\"hljs-keyword\">Copy</span> selected region\nC-y     Paste\n</code></pre>\n    <h2>files and buffers</h2>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">C-s</span>         <span class=\"hljs-string\">Save current file</span>\n<span class=\"hljs-attr\">C-x</span> <span class=\"hljs-string\">k       Kill buffer</span>\n<span class=\"hljs-attr\">C-x</span> <span class=\"hljs-string\">b       Switch to buffer</span>\n<span class=\"hljs-attr\">C-x</span> <span class=\"hljs-string\">C-b     Lits buffers</span>\n</code></pre>\n  </body>\n</html>\n"}},{"id":"posts/helm-cheatsheet","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/helm-cheatsheet.md","metadata":{"title":"Helm Cheatsheet","description":null,"permalink":null,"priority":0,"tags":["helm","kubernetes","cheetsheet"],"categories":["helm"]},"content":{"raw":"\n# \n\nList charts in a repo\n\n    helm search repo prometheus-community\n\nShow values of a chart\n\n    helm show values prometheus-community/prometheus\n\nUpgrade or install chart to a specific namespace with a specific version\n\n    helm --namespace observability upgrade --install my-prometheus prometheus-community/prometheus --version \"19.0.1\"\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1></h1>\n    <p>List charts in a repo</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">helm</span> <span class=\"hljs-string\">search repo prometheus-community</span>\n</code></pre>\n    <p>Show values of a chart</p>\n    <pre><code class=\"hljs language-maxima\">helm <span class=\"hljs-built_in\">show</span> <span class=\"hljs-built_in\">values</span> prometheus-community/prometheus\n</code></pre>\n    <p>Upgrade or install chart to a specific namespace with a specific version</p>\n    <pre><code class=\"hljs language-angelscript\">helm --<span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-symbol\">observability</span> <span class=\"hljs-symbol\">upgrade</span> --<span class=\"hljs-symbol\">install</span> <span class=\"hljs-symbol\">my</span>-<span class=\"hljs-symbol\">prometheus</span> <span class=\"hljs-symbol\">prometheus</span>-<span class=\"hljs-symbol\">community</span>/<span class=\"hljs-symbol\">prometheus</span> --<span class=\"hljs-symbol\">version</span> \"<span class=\"hljs-symbol\">19</span>.<span class=\"hljs-symbol\">0</span>.<span class=\"hljs-symbol\">1</span>\"\n</code></pre>\n  </body>\n</html>\n"}},{"id":"posts/kafka","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/kafka.md","metadata":{"title":"Kafka","description":null,"permalink":null,"priority":0,"tags":[],"categories":[]},"content":{"raw":"\n# Overview\n\n## What is kafka?\n\n> Kafka is a streamsing platform for ingesting, storing, accessing and processing streams of data\n\n# High level concepts\n\n## Communication model\n\nOn the contrary of a **Directed Communication** where every service is aware of the other process to send messages to, kafka provides a centralized hub in which processes can send and receieve messages without being aware of each other. Such communication model is known as the **Publish/Subscribe** model which enhance the decoupling between different processes.\n\n> Of course those are not termed by kafka\n\n> Recall the different communication formalization according the sync/async and persistent/transient dimensions. Kafka fills conforms to the asynchronous and persisted model. This is unintuitive since this model is usually used for classical **Queues** rather than **Pubsubs**.\n\n## Core components\n\nA **Topic** is a named stream of data (/ channel - CSP?).\n\n**Producer**s are processes that publish data to a Topic.\n\n**Consumer**s are processes that subscribe to data in one or more Topics.\n\nA **Consumer Group** is a set of Consumers that work together as a group.\n\n## Storage\n\n### Commit Log\n\nA **Commit Log** is an append only data structure which contain an *Ordered Sequence* of events (/records)\n\n- Records in the log are immutable\n- Records are ordered and their ordinal is known as their **Offset**\n\n> It is very similiar to existing transaction logs (Redo Log especially) which can be found in classical Relational Databases.\n\n> To gain perspectives we can find similiarities to STM concurrency mode, Redux stores etc...\n\n### Partitions\n\nIn order to provide distribution capabilities, there is no 1 to 1 correlation of Topic to Log since then each Topic would need to be stored on a single machine. Rather, a Topic is broken into smaller units called **Partitions**.\n\nEffectively, every Partition is a single Log. Such model allows kafka to distribute a Topic with N partitions to at most N workers and we can have K Consumers under the same Consumer Group sharing the load of consumption as long as LEQ(K, N). If K>N than it means that some consumers will be idle.\n\nIt makes sense from a technical POV. Kafka simply assigns a Partition to a Consumer.\n\n- If the number of Consumers is less than the number of Partitions, by the pigenhole principle there is at least a single Consumers that is assigned with more than one partition\n- If the number of Consumers is greather than the number of Partitions, there cannot be a surjective mapping from the Partitions the Consumers\n\n### Event\n\nA unit of data in a Topic has many interchangeable names - Event, Message, Record. We favour the term Event.\n\n> Out of the kafka scope, events in the fotware world are *Entities* that desribe something that *happened in the past*. Therefore, event are past tense verbse. Well, it is the same in kafka\n\nAn **Event** is a timestamped key-value pair the records something that happened.\n\nEvent is composed of **Headers**, **Keys**, a **Timestamp** and a **Value**. We will cover some of those at a later time but for a very brief overview\n\n**Headers** contain optional metadata about the Event. One can use them to annotate, monitor and audit and Event. This is very like HTTP headers.\n\n**Keys** are optional values that affect how data is distributed accross partitions (Again, this is known concept, think of Partition Keys and partitioning schemes in different distributed systems). We will explore this concept independently.\n\n**Timestamp** holds information about when the thing that happened hapenned. There are multiple semantics of time we can speak of - When the Event created? When was it ingested? When was it processed? This is a whole topic of it's own which we will explore independantly.\n\n**Value** is the content of the message. Practically this is just a byte array and should be serialized according to the application.\n\n## The Cluster\n\nTODO: cover concepts below\n\n**Broker** TODO\n\n**Replication** TODO\n\n**Leader** TODO\n\n**Follower** TODO\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Overview</h1>\n    <h2>What is kafka?</h2>\n    <blockquote>\n      <p>Kafka is a streamsing platform for ingesting, storing, accessing and processing streams of data</p>\n    </blockquote>\n    <h1>High level concepts</h1>\n    <h2>Communication model</h2>\n    <p>On the contrary of a <strong>Directed Communication</strong> where every service is aware of the other process to send messages to, kafka provides a centralized hub in which processes can send and receieve messages without being aware of each other. Such communication model is known as the <strong>Publish/Subscribe</strong> model which enhance the decoupling between different processes.</p>\n    <blockquote>\n      <p>Of course those are not termed by kafka</p>\n    </blockquote>\n    <blockquote>\n      <p>Recall the different communication formalization according the sync/async and persistent/transient dimensions. Kafka fills conforms to the asynchronous and persisted model. This is unintuitive since this model is usually used for classical <strong>Queues</strong> rather than <strong>Pubsubs</strong>.</p>\n    </blockquote>\n    <h2>Core components</h2>\n    <p>A <strong>Topic</strong> is a named stream of data (/ channel - CSP?).</p>\n    <p><strong>Producer</strong>s are processes that publish data to a Topic.</p>\n    <p><strong>Consumer</strong>s are processes that subscribe to data in one or more Topics.</p>\n    <p>A <strong>Consumer Group</strong> is a set of Consumers that work together as a group.</p>\n    <h2>Storage</h2>\n    <h3>Commit Log</h3>\n    <p>A <strong>Commit Log</strong> is an append only data structure which contain an <em>Ordered Sequence</em> of events (/records)</p>\n    <ul>\n      <li>Records in the log are immutable</li>\n      <li>Records are ordered and their ordinal is known as their <strong>Offset</strong></li>\n    </ul>\n    <blockquote>\n      <p>It is very similiar to existing transaction logs (Redo Log especially) which can be found in classical Relational Databases.</p>\n    </blockquote>\n    <blockquote>\n      <p>To gain perspectives we can find similiarities to STM concurrency mode, Redux stores etc...</p>\n    </blockquote>\n    <h3>Partitions</h3>\n    <p>In order to provide distribution capabilities, there is no 1 to 1 correlation of Topic to Log since then each Topic would need to be stored on a single machine. Rather, a Topic is broken into smaller units called <strong>Partitions</strong>.</p>\n    <p>Effectively, every Partition is a single Log. Such model allows kafka to distribute a Topic with N partitions to at most N workers and we can have K Consumers under the same Consumer Group sharing the load of consumption as long as LEQ(K, N). If K>N than it means that some consumers will be idle.</p>\n    <p>It makes sense from a technical POV. Kafka simply assigns a Partition to a Consumer.</p>\n    <ul>\n      <li>If the number of Consumers is less than the number of Partitions, by the pigenhole principle there is at least a single Consumers that is assigned with more than one partition</li>\n      <li>If the number of Consumers is greather than the number of Partitions, there cannot be a surjective mapping from the Partitions the Consumers</li>\n    </ul>\n    <h3>Event</h3>\n    <p>A unit of data in a Topic has many interchangeable names - Event, Message, Record. We favour the term Event.</p>\n    <blockquote>\n      <p>Out of the kafka scope, events in the fotware world are <em>Entities</em> that desribe something that <em>happened in the past</em>. Therefore, event are past tense verbse. Well, it is the same in kafka</p>\n    </blockquote>\n    <p>An <strong>Event</strong> is a timestamped key-value pair the records something that happened.</p>\n    <p>Event is composed of <strong>Headers</strong>, <strong>Keys</strong>, a <strong>Timestamp</strong> and a <strong>Value</strong>. We will cover some of those at a later time but for a very brief overview</p>\n    <p><strong>Headers</strong> contain optional metadata about the Event. One can use them to annotate, monitor and audit and Event. This is very like HTTP headers.</p>\n    <p><strong>Keys</strong> are optional values that affect how data is distributed accross partitions (Again, this is known concept, think of Partition Keys and partitioning schemes in different distributed systems). We will explore this concept independently.</p>\n    <p><strong>Timestamp</strong> holds information about when the thing that happened hapenned. There are multiple semantics of time we can speak of - When the Event created? When was it ingested? When was it processed? This is a whole topic of it's own which we will explore independantly.</p>\n    <p><strong>Value</strong> is the content of the message. Practically this is just a byte array and should be serialized according to the application.</p>\n    <h2>The Cluster</h2>\n    <p>TODO: cover concepts below</p>\n    <p><strong>Broker</strong> TODO</p>\n    <p><strong>Replication</strong> TODO</p>\n    <p><strong>Leader</strong> TODO</p>\n    <p><strong>Follower</strong> TODO</p>\n  </body>\n</html>\n"}},{"id":"posts/mariadb-notes","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/mariadb-notes.md","metadata":{"title":"MariaDB Notes","description":null,"permalink":null,"priority":0,"tags":["MariaDB"],"categories":["Databases","Notes"]},"content":{"raw":"\nEverything is well documented in the MySQL/MariaDB documentations, but i'll gather some stuff here which I frequently encounter.\n\n## variables inspection\n\nrun ```mysqladmin variables```\n\n## notable variables/configurations\n\n__data_dir__ - the data directory\n\n> usually ```/var/lib/mysql```\n\n__lower_case_table_names__ - as the name suggests, make all tables lower case.\n\n__local_infile__ - enable loading tables from local files.\n\n> for commands such as: ```mysqlimport --local --fields-terminated-by=\"|\" -h localhost some-file.csv```\n\n## configuration files\n\nat least on the machine i am currently at, the root configuration is at ```/etc/my.cnf```. in turn it includes ```/etc/my.cnf.d```.\n\nin there, ill edit configurations in ```/etc/my.cnf.d/server.cnf```.\n\nfor example; to have all tables names with lower case and enable local in files, ill add the following under ```[mysqld]```\n- lower_case_table_names=1\n- local_infile=1\n\n## datadir notes\n\nwe can check where it is configured to be at using the variables inspection above, but usually it is at ```/var/lib/mysql```.\n\nit should be owned by the user/group running the process; those are usually mysql/mysql, but we can check this as well. assuming we start the process using ```systemd```, open the service file, and check what are the ```User``` and ```Group``` configured to be. the service file on my machine is at ```/usr/lib/systemd/system/mariadb.service```\n\n## complete reboot\n\nstop mariadb service - ```systemctl stop mariadb```\n\ndelete contents of datadir -```rm -rf /var/lib/mysql/*```\n\nremake infrastructure files - ```mysql_install_db --user=mysql --ldata=/var/lib/mysql```\n\nstart mariadb service - ```systemctl start mariadb```\n\n> when we need such a thing?\n> for example; there are configurations that only apply on installation, such as ```lower_case_table_names```\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>Everything is well documented in the MySQL/MariaDB documentations, but i'll gather some stuff here which I frequently encounter.</p>\n    <h2>variables inspection</h2>\n    <p>run <code>mysqladmin variables</code></p>\n    <h2>notable variables/configurations</h2>\n    <p><strong>data_dir</strong> - the data directory</p>\n    <blockquote>\n      <p>usually <code>/var/lib/mysql</code></p>\n    </blockquote>\n    <p><strong>lower_case_table_names</strong> - as the name suggests, make all tables lower case.</p>\n    <p><strong>local_infile</strong> - enable loading tables from local files.</p>\n    <blockquote>\n      <p>for commands such as: <code>mysqlimport --local --fields-terminated-by=\"|\" -h localhost some-file.csv</code></p>\n    </blockquote>\n    <h2>configuration files</h2>\n    <p>at least on the machine i am currently at, the root configuration is at <code>/etc/my.cnf</code>. in turn it includes <code>/etc/my.cnf.d</code>.</p>\n    <p>in there, ill edit configurations in <code>/etc/my.cnf.d/server.cnf</code>.</p>\n    <p>for example; to have all tables names with lower case and enable local in files, ill add the following under <code>[mysqld]</code></p>\n    <ul>\n      <li>lower_case_table_names=1</li>\n      <li>local_infile=1</li>\n    </ul>\n    <h2>datadir notes</h2>\n    <p>we can check where it is configured to be at using the variables inspection above, but usually it is at <code>/var/lib/mysql</code>.</p>\n    <p>it should be owned by the user/group running the process; those are usually mysql/mysql, but we can check this as well. assuming we start the process using <code>systemd</code>, open the service file, and check what are the <code>User</code> and <code>Group</code> configured to be. the service file on my machine is at <code>/usr/lib/systemd/system/mariadb.service</code></p>\n    <h2>complete reboot</h2>\n    <p>stop mariadb service - <code>systemctl stop mariadb</code></p>\n    <p>delete contents of datadir -<code>rm -rf /var/lib/mysql/*</code></p>\n    <p>remake infrastructure files - <code>mysql_install_db --user=mysql --ldata=/var/lib/mysql</code></p>\n    <p>start mariadb service - <code>systemctl start mariadb</code></p>\n    <blockquote>\n      <p>\n        when we need such a thing?\n        for example; there are configurations that only apply on installation, such as <code>lower_case_table_names</code>\n      </p>\n    </blockquote>\n  </body>\n</html>\n"}},{"id":"posts/pacman","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/pacman.md","metadata":{"title":"Pacman","description":null,"permalink":null,"priority":0,"tags":["Notes","Archlinux"],"categories":[]},"content":{"raw":"\n# Pacman\n\nFocues on esoteric usages I sometimes do, instead of re-searching\n\n> Perhaps do a single packages for all (apk, pacman, apt)?\n\n__Purge Package__\n\n    pacman -Rns {package}\n\nThe most common use case is to just delete a package {package}, removing all it's configurations and dependencies.\n\n- R is the _Remove_ operation\n- n flag indicates to remove the package's configuration\n- s flag indicates to remove unnecessary dependencies\n\n\n__List Orphans__\n\n    pacman -Qdt\n\n- Q is the _Query_ action\n- d filters only depnedencies\n- t filters only those who are unrequired\n\n__Delete orphans__\n\n    pacman -Rns $(pacman -Qdtq)\n\nNotice that we added a _q_ option to the _List Orphans_ command, it prints less information. Specifically, it makes it so the _Query_ operation will only return the package name. That way, we can easily pass it as an argument to the _Remove_ operation\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Pacman</h1>\n    <p>Focues on esoteric usages I sometimes do, instead of re-searching</p>\n    <blockquote>\n      <p>Perhaps do a single packages for all (apk, pacman, apt)?</p>\n    </blockquote>\n    <p><strong>Purge Package</strong></p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">pacman</span> <span class=\"hljs-string\">-Rns {package}</span>\n</code></pre>\n    <p>The most common use case is to just delete a package {package}, removing all it's configurations and dependencies.</p>\n    <ul>\n      <li>R is the <em>Remove</em> operation</li>\n      <li>n flag indicates to remove the package's configuration</li>\n      <li>s flag indicates to remove unnecessary dependencies</li>\n    </ul>\n    <p><strong>List Orphans</strong></p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">pacman</span> <span class=\"hljs-string\">-Qdt</span>\n</code></pre>\n    <ul>\n      <li>Q is the <em>Query</em> action</li>\n      <li>d filters only depnedencies</li>\n      <li>t filters only those who are unrequired</li>\n    </ul>\n    <p><strong>Delete orphans</strong></p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">pacman</span> <span class=\"hljs-string\">-Rns $(pacman -Qdtq)</span>\n</code></pre>\n    <p>Notice that we added a <em>q</em> option to the <em>List Orphans</em> command, it prints less information. Specifically, it makes it so the <em>Query</em> operation will only return the package name. That way, we can easily pass it as an argument to the <em>Remove</em> operation</p>\n  </body>\n</html>\n"}},{"id":"posts/postgres-notes","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/postgres-notes.md","metadata":{"title":"Postgres Notes","description":null,"permalink":null,"priority":0,"tags":["PostgreSQL"],"categories":["Notes","Databases"]},"content":{"raw":"\nWithin the REPL, all buit-in commands are prefixed with ```\\```. For example;\n\n```\n\\?              Displays help page\n\\q              Quits the REPL\n\\l              Lists all databases\n\\c {database}   Connect to a different database\n```\n\n### Roles\n\nA Role is the single entity for authentication/authorization. According to how it is set up, it can act as a user, a group or both.\n\nCreate a role\n\n```sql\nCREATE ROLE \"somerole\"\n```\n\nGrant login to the role\n\n```sql\nALTER ROLE \"somerole\" WITH LOGIN;\n```\n\n### Serial (Auto Increment)\n\n```sql\nCREATE TABLE some_table (\n  id SERIAL PRIMARY KEY,\n  other varchar(20)\n)\n```\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>Within the REPL, all buit-in commands are prefixed with <code>\\</code>. For example;</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">\\?</span>              <span class=\"hljs-string\">Displays help page</span>\n<span class=\"hljs-attr\">\\q</span>              <span class=\"hljs-string\">Quits the REPL</span>\n<span class=\"hljs-attr\">\\l</span>              <span class=\"hljs-string\">Lists all databases</span>\n<span class=\"hljs-attr\">\\c</span> <span class=\"hljs-string\">{database}   Connect to a different database</span>\n</code></pre>\n    <h3>Roles</h3>\n    <p>A Role is the single entity for authentication/authorization. According to how it is set up, it can act as a user, a group or both.</p>\n    <p>Create a role</p>\n    <pre><code class=\"hljs language-sql\"><span class=\"hljs-keyword\">CREATE</span> ROLE \"somerole\"\n</code></pre>\n    <p>Grant login to the role</p>\n    <pre><code class=\"hljs language-sql\"><span class=\"hljs-keyword\">ALTER</span> ROLE \"somerole\" <span class=\"hljs-keyword\">WITH</span> LOGIN;\n</code></pre>\n    <h3>Serial (Auto Increment)</h3>\n    <pre><code class=\"hljs language-sql\"><span class=\"hljs-keyword\">CREATE</span> <span class=\"hljs-keyword\">TABLE</span> some_table (\n  id SERIAL <span class=\"hljs-keyword\">PRIMARY</span> KEY,\n  other <span class=\"hljs-type\">varchar</span>(<span class=\"hljs-number\">20</span>)\n)\n</code></pre>\n  </body>\n</html>\n"}},{"id":"posts/system","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/system.md","metadata":{"title":"Scattered stuff to bring together","description":null,"permalink":null,"priority":0,"tags":[],"categories":[]},"content":{"raw":"\n# Cache\n\n**read-through** strategy is when the server checks if X is in the cache, if it does it returns it, if it does not, invoke the appropriate database query, cache the result as X, and return back.\n\n# Framework\n\n## 1. Undestand the problem and establish a scope for the design\n\n- Take your time\n- Ask clarifications\n- Write down assumptions\n\n## 2. High level proposition\n\n## 3. Design deep dive\n\n## 4. Deep dive\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Cache</h1>\n    <p><strong>read-through</strong> strategy is when the server checks if X is in the cache, if it does it returns it, if it does not, invoke the appropriate database query, cache the result as X, and return back.</p>\n    <h1>Framework</h1>\n    <h2>1. Undestand the problem and establish a scope for the design</h2>\n    <ul>\n      <li>Take your time</li>\n      <li>Ask clarifications</li>\n      <li>Write down assumptions</li>\n    </ul>\n    <h2>2. High level proposition</h2>\n    <h2>3. Design deep dive</h2>\n    <h2>4. Deep dive</h2>\n  </body>\n</html>\n"}},{"id":"posts/timescale","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/timescale.md","metadata":{"title":"Timescale","description":null,"permalink":null,"priority":0,"tags":["Notes"],"categories":[]},"content":{"raw":"\nTimescale is a time series optimized system built on top of posgres.\n\nIt provides pg extensions\n\n- timescaledb\n- timescaledb_toolkit\n\nOne can perhaps even use the ```promscale``` extension\n\n# Hypertables\n\nHypertables are the core construct behind timescale.\n\nPractically, the Hypertable is an abstraction of multiple tables, called Chunks.\n\nA Hypertable replaces a standard Postgres table and partition it by time, and potentially by space.\n\n## Creating a hypertable\n\nA Hypertable imposes the criteria that the column we partition by will included in all UNIQUE or PRIMARY indexes.\n\nTake the following table\n\n```sql\nCREATE TABLE events (\n    id SERIAL,\n    name VARCHAR,\n    timestamp timestamptz,\n    domain VARCHAR\n);\n```\n\nTo create a Hypertable, partitioning by ```timestamp```, with chunk sizes of 1 week each, with a space partition using ```domain``` we use\n\n```sql\nselect create_hypertable(\n    'event', 'timestamp',\n    partitioning_column => 'domain',\n    number_partitions => 10);\n``` \n\nAdditional parameters and information can be found [In the docs](https://docs.timescale.com/api/latest/hypertable/create_hypertable/#create-hypertable)\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>Timescale is a time series optimized system built on top of posgres.</p>\n    <p>It provides pg extensions</p>\n    <ul>\n      <li>timescaledb</li>\n      <li>timescaledb_toolkit</li>\n    </ul>\n    <p>One can perhaps even use the <code>promscale</code> extension</p>\n    <h1>Hypertables</h1>\n    <p>Hypertables are the core construct behind timescale.</p>\n    <p>Practically, the Hypertable is an abstraction of multiple tables, called Chunks.</p>\n    <p>A Hypertable replaces a standard Postgres table and partition it by time, and potentially by space.</p>\n    <h2>Creating a hypertable</h2>\n    <p>A Hypertable imposes the criteria that the column we partition by will included in all UNIQUE or PRIMARY indexes.</p>\n    <p>Take the following table</p>\n    <pre><code class=\"hljs language-sql\"><span class=\"hljs-keyword\">CREATE</span> <span class=\"hljs-keyword\">TABLE</span> events (\n    id SERIAL,\n    name <span class=\"hljs-type\">VARCHAR</span>,\n    <span class=\"hljs-type\">timestamp</span> timestamptz,\n    domain <span class=\"hljs-type\">VARCHAR</span>\n);\n</code></pre>\n    <p>To create a Hypertable, partitioning by <code>timestamp</code>, with chunk sizes of 1 week each, with a space partition using <code>domain</code> we use</p>\n    <pre><code class=\"hljs language-sql\"><span class=\"hljs-keyword\">select</span> create_hypertable(\n    <span class=\"hljs-string\">'event'</span>, <span class=\"hljs-string\">'timestamp'</span>,\n    partitioning_column <span class=\"hljs-operator\">=</span><span class=\"hljs-operator\">></span> <span class=\"hljs-string\">'domain'</span>,\n    number_partitions <span class=\"hljs-operator\">=</span><span class=\"hljs-operator\">></span> <span class=\"hljs-number\">10</span>);\n</code></pre>\n    <p>Additional parameters and information can be found <a href=\"https://docs.timescale.com/api/latest/hypertable/create_hypertable/#create-hypertable\">In the docs</a></p>\n  </body>\n</html>\n"}},{"id":"posts/vagrant-over-libvirt-arch","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/vagrant-over-libvirt-arch.md","metadata":{"title":"Vagrant over libvirt on Archlinux","description":null,"permalink":null,"priority":0,"tags":["Linux","Archlinux","Vagrant"],"categories":[]},"content":{"raw":"\n# The tools\n\n[Vagrant](https://www.vagrantup.com/) is an open source software to virtualize development environments.\n\n[libvirt](https://libvit.org/) is an open source virtualization API. I think the [archwiki page](https://wiki.archlinux.org/title/Libvit) actually describes it better, as a collection of software that provides a way to manage virtualization functionality.\n\n[kvm](https://www.linux-kvm.org/page/Main_Page/) a short for **K**ernel-based **V**irtual **M**achine, is a virtualization infrastructure provided by the kernel.\n\n[QEMU](https://www.qemu.org/) is an open source machine emulator and virtualizer.\n\n# The stack\n\nVagrant will use the libvirt APIs which will be drived by QEMU utilizing kvm.\n\n```\n+-----------+\n|  Vagrant  |\n+-----------+\n|  libvirt  |\n+-----------+\n|  QEMU     |\n+-----------+\n|  KVM      |\n+-----------\n```\n\nTo install the stack we will need the following packages  \n- [vagrant](https://archlinux.org/packages/?name=vagrant)\n- [libvirt](https://archlinux.org/packages/?name=libvirt)\n- [iptables-nft](https://archlinux.org/packages/?name=iptables-nft)\n- [dnsmasq](https://archlinux.org/packages/?name=dnsmasq)\n- [qemu-headless](https://archlinux.org/packages/?name=qemu-headless)\n\nRun the command\n\n    pacman -Suy vagrant libvirt iptables-nft dnsmasq qemu-headless\n\n# Startup\n\nIn order to run the stack we need the following services running\n- libvirtd.service \n- virtlogd.service\n\nYou can either start them by running\n\n    systemctl start libvirtd virtlogd\n\nOr you can enable them by running\n\n    systemctl enable libvirtd virtlogd\n\nYou can check that everything is running by running\n\n    virsh -c qemu:///system\n\n> [virsh](https://linux.die.net/man/1/virsh) is a cli to interact with guest domains (virtual machines).\n\n# Starting out first Vagrant Box\n\nIn Vagrant's domain, a Box is a package format, a bit like an ISO or a docker image. We will start a ```debian/bullseye64``` Boxed OS.\n\nInside your working directory, there should be a configuration file that Vagrant can read and function by - It is the ```Vagrantfile```. The Vagrantfile contains configuration about what Box to run, how many resources to allocate and more.\n\nIn a new environment, we can either create a file manually or use Vagrants ```init``` command to do this for us. \n\n    vagrant init --minimal\n\nNow, lets edit the newly created Vagrantfile and set the parameter ```config.vm.box``` to \"debian/bullseye64\". Lets also add the following parameters  \n\nWe can always validate the Vagrantfile by running\n\n    vagrant validate\n\nAt this point, during validation, you might get an error like ```No usable default provider could be found for your system```. Thats fine, see next.\n\nVagrant uses a notion of Providers. A Provider is Vagrant's abstraction over the underlying hypervisor that vagrant will operate. In our case, as illustrated above, we use libvirt as the hypervisor so we will need to install the relevant Provider. To install the Provider we will use Vagrant's Plugins mechanism and run\n\n    vagrant plugin install vagrant-libvirt\n\nNow we are finally ready to run the Box by running the command\n\n    vagrant up --provider=libvirt\n\nSome errors you might encounter\n\n**Some error about polkit indicates permission issues**. Read about it for best scenario solution, as a quick and easy solution, add your user to the libvirt group\n\n**Some error about your machine not supporting NFS.** Just install nfs-utils by running\n\n    pacman -Syu nfs-utils\n\n**Forevr waiting on IP acquisition.** I still havn't completely figured this out. It looks somethong about DNS and DHCP. What I did find out that some Boxes do not get this issue, try changing.\n\nTo ssh into the OS run\n\n    vagrant ssh\n\nTo clean up run\n\n    vagrant destroy\n\n# Other tools\n\n__virt-manager__ is a graphical tool to list and manage the guest domains.\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>The tools</h1>\n    <p><a href=\"https://www.vagrantup.com/\">Vagrant</a> is an open source software to virtualize development environments.</p>\n    <p><a href=\"https://libvit.org/\">libvirt</a> is an open source virtualization API. I think the <a href=\"https://wiki.archlinux.org/title/Libvit\">archwiki page</a> actually describes it better, as a collection of software that provides a way to manage virtualization functionality.</p>\n    <p><a href=\"https://www.linux-kvm.org/page/Main_Page/\">kvm</a> a short for <strong>K</strong>ernel-based <strong>V</strong>irtual <strong>M</strong>achine, is a virtualization infrastructure provided by the kernel.</p>\n    <p><a href=\"https://www.qemu.org/\">QEMU</a> is an open source machine emulator and virtualizer.</p>\n    <h1>The stack</h1>\n    <p>Vagrant will use the libvirt APIs which will be drived by QEMU utilizing kvm.</p>\n    <pre><code class=\"hljs language-asciidoc\"><span class=\"hljs-code\">+-----------+</span>\n<span class=\"hljs-section\">|  Vagrant  |\n+-----------+</span>\n<span class=\"hljs-section\">|  libvirt  |\n+-----------+</span>\n<span class=\"hljs-section\">|  QEMU     |\n+-----------+</span>\n<span class=\"hljs-section\">|  KVM      |\n+-----------</span>\n</code></pre>\n    <p>To install the stack we will need the following packages</p>\n    <ul>\n      <li><a href=\"https://archlinux.org/packages/?name=vagrant\">vagrant</a></li>\n      <li><a href=\"https://archlinux.org/packages/?name=libvirt\">libvirt</a></li>\n      <li><a href=\"https://archlinux.org/packages/?name=iptables-nft\">iptables-nft</a></li>\n      <li><a href=\"https://archlinux.org/packages/?name=dnsmasq\">dnsmasq</a></li>\n      <li><a href=\"https://archlinux.org/packages/?name=qemu-headless\">qemu-headless</a></li>\n    </ul>\n    <p>Run the command</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">pacman</span> <span class=\"hljs-string\">-Suy vagrant libvirt iptables-nft dnsmasq qemu-headless</span>\n</code></pre>\n    <h1>Startup</h1>\n    <p>In order to run the stack we need the following services running</p>\n    <ul>\n      <li>libvirtd.service</li>\n      <li>virtlogd.service</li>\n    </ul>\n    <p>You can either start them by running</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">systemctl</span> <span class=\"hljs-string\">start libvirtd virtlogd</span>\n</code></pre>\n    <p>Or you can enable them by running</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">systemctl</span> <span class=\"hljs-string\">enable libvirtd virtlogd</span>\n</code></pre>\n    <p>You can check that everything is running by running</p>\n    <pre><code class=\"hljs language-perl\">virsh -c qemu:<span class=\"hljs-regexp\">//</span>/<span class=\"hljs-keyword\">system</span>\n</code></pre>\n    <blockquote>\n      <p><a href=\"https://linux.die.net/man/1/virsh\">virsh</a> is a cli to interact with guest domains (virtual machines).</p>\n    </blockquote>\n    <h1>Starting out first Vagrant Box</h1>\n    <p>In Vagrant's domain, a Box is a package format, a bit like an ISO or a docker image. We will start a <code>debian/bullseye64</code> Boxed OS.</p>\n    <p>Inside your working directory, there should be a configuration file that Vagrant can read and function by - It is the <code>Vagrantfile</code>. The Vagrantfile contains configuration about what Box to run, how many resources to allocate and more.</p>\n    <p>In a new environment, we can either create a file manually or use Vagrants <code>init</code> command to do this for us.</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">vagrant</span> <span class=\"hljs-string\">init --minimal</span>\n</code></pre>\n    <p>Now, lets edit the newly created Vagrantfile and set the parameter <code>config.vm.box</code> to \"debian/bullseye64\". Lets also add the following parameters</p>\n    <p>We can always validate the Vagrantfile by running</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">vagrant</span> <span class=\"hljs-string\">validate</span>\n</code></pre>\n    <p>At this point, during validation, you might get an error like <code>No usable default provider could be found for your system</code>. Thats fine, see next.</p>\n    <p>Vagrant uses a notion of Providers. A Provider is Vagrant's abstraction over the underlying hypervisor that vagrant will operate. In our case, as illustrated above, we use libvirt as the hypervisor so we will need to install the relevant Provider. To install the Provider we will use Vagrant's Plugins mechanism and run</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">vagrant</span> <span class=\"hljs-string\">plugin install vagrant-libvirt</span>\n</code></pre>\n    <p>Now we are finally ready to run the Box by running the command</p>\n    <pre><code class=\"hljs language-ini\">vagrant up <span class=\"hljs-attr\">--provider</span>=libvirt\n</code></pre>\n    <p>Some errors you might encounter</p>\n    <p><strong>Some error about polkit indicates permission issues</strong>. Read about it for best scenario solution, as a quick and easy solution, add your user to the libvirt group</p>\n    <p><strong>Some error about your machine not supporting NFS.</strong> Just install nfs-utils by running</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">pacman</span> <span class=\"hljs-string\">-Syu nfs-utils</span>\n</code></pre>\n    <p><strong>Forevr waiting on IP acquisition.</strong> I still havn't completely figured this out. It looks somethong about DNS and DHCP. What I did find out that some Boxes do not get this issue, try changing.</p>\n    <p>To ssh into the OS run</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">vagrant</span> <span class=\"hljs-string\">ssh</span>\n</code></pre>\n    <p>To clean up run</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">vagrant</span> <span class=\"hljs-string\">destroy</span>\n</code></pre>\n    <h1>Other tools</h1>\n    <p><strong>virt-manager</strong> is a graphical tool to list and manage the guest domains.</p>\n  </body>\n</html>\n"}},{"id":"posts/zsh-completions","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/posts/zsh-completions.md","metadata":{"title":"ZSH completions","description":null,"permalink":null,"priority":0,"tags":["Notes"],"categories":[]},"content":{"raw":"\nUsing `oh-my-zsh`.\n\nPut completions for `x` at\n\n    ~/.oh-my-zsh/completions/_x\n\nIn `~/.zshr`, Add if not exists\n\n    fpath=($fpath /.oh-my-zsh/completions)\n    autoload -U compinit\n    compinit\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>Using <code>oh-my-zsh</code>.</p>\n    <p>Put completions for <code>x</code> at</p>\n    <pre><code class=\"hljs language-arcade\">~<span class=\"hljs-regexp\">/.oh-my-zsh/</span>completions/_x\n</code></pre>\n    <p>In <code>~/.zshr</code>, Add if not exists</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">fpath</span>=<span class=\"hljs-string\">($fpath /.oh-my-zsh/completions)</span>\n<span class=\"hljs-attr\">autoload</span> <span class=\"hljs-string\">-U compinit</span>\n<span class=\"hljs-attr\">compinit</span>\n</code></pre>\n  </body>\n</html>\n"}}],"metadataAggregation":{"categories":{"Algorithms":{"count":4},"Probabalistic Datastructures":{"count":1},"AWS":{"count":5},"Domain Driven Design":{"count":4},"Elasticsearch":{"count":3},"Notes":{"count":3},"Kubernetes":{"count":7},"Guides":{"count":1},"ArgoCD":{"count":1},"Cheatsheet":{"count":1},"helm":{"count":1},"Databases":{"count":2}},"tags":{"Dynamic Programming":{"count":3},"Palindrom":{"count":1},"Cheatsheet":{"count":1},"Elasticsearch":{"count":2},"Elastissearch":{"count":1},"ILM":{"count":1},"Kubernetes":{"count":7},"Archlinux":{"count":3},"Linux":{"count":2},"ArgoCD":{"count":1},"Emacs":{"count":1},"helm":{"count":1},"kubernetes":{"count":1},"cheetsheet":{"count":1},"MariaDB":{"count":1},"Notes":{"count":3},"PostgreSQL":{"count":1},"Vagrant":{"count":1}}}}},"__N_SSG":true}