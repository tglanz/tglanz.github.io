{"pageProps":{"article":{"id":"intro-to-ai/bayesian-networks","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/next-legacy/content/intro-to-ai/bayesian-networks.md","metadata":{"title":"Bayesian Networks","description":null,"priority":0,"tags":["AI","Probability"],"categories":["Intro to AI"],"toc":true},"content":{"raw":"\n**NOTE**: Need to continue this.\n\n## Definition\n\nA **Bayesian Network (BN)** is a data structure that represents dependencies among different Random Variables. BNs represent the full joint distribution concisely which leads to more efficient query inferences.\n\nA Bayesian Network is a directed, acyclic graph whose nodes represent a random variable and the edges represent a parent-child relationship. For every node $X$ the network associates the conditioned probabilities of $X$ as an effect of it's parents, i.e. $P(X | Parents(X))$.\n\nEach node is attached with local probability information a.k.a **conditional probability table (CPT)**.\n\n## Example\n\nLet's consider the following scenario. A burglary alarm in Paul's home can be set off by small earthquakes. Paul has two neighbors: Nina and Lei - they promised Paul to call him when they hear the alarm. Nina is very alert but Lei is always busy and is more likely not to hear Paul's alarm. Given a call, what is the probability of a burglary?\n\nBelow is a BN describing the scenario:\n\n```plantuml\ndigraph G {\n    {Earthquake, Burglary} -> Alarm;\n    Alarm -> {LeiCalls, NinaCalls};\n}\n```\n\nAnd the CPT tables:\n\n$P(Burglary=true)$|\n----------|\n0.001|\n\n$P(Earthquake=true)$|\n----------|\n0.002|\n\n$Burglary$ | $Earthquake$ | $P(Alarm=true \\mid Burglary, Earthquake)$ |\n-----------|--------------|---------------|\ntrue|true|0.95\ntrue|false|0.94\nfalse|true|0.29\nfalse|false|0.001\n\n$Alarm$ | $P(NinaCalls=true \\mid Alarm)$ |\n--------|--------------------------------|\ntrue | 0.9\nfalse | 0.05\n\n$Alarm$ | $P(LeiCalls=true \\mid Alarm)$ |\n--------|--------------------------------|\ntrue | 0.7\nfalse | 0.01\n\n!> Notice we didn't need to write the complements in the CPTs since they are computable by \"1-...\"\n\n## Semantics\n\nWe defined the syntax of BNs above. The semantics we want to impose on BNs is that different variables are conditionall independent of each other **given their parents**\n\n$$\nP(x_1, x_2, ..., x_n) = \\Pi_{i=1}^{n}{P(x_i | Parents(x_i))}\n$$\n\nIn general, we can reduce the joint distribution by iteratively invoking the **product rule**: \n\n$$\n\\begin{align*}\nP(x_1, x_2, ..., x_n) &= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_1, x_2, ..., x_{n-1}) \\\\\\\\\n  &= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_{n-1} | x_1, x_2, ..., x_{n=2}) P(x_1, x_2, ..., x_{n-2}) \\\\\\\\\n  &= ... \\\\\\\\\n  &= \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})\n\\end{align*}\n$$\n\nThis is a very important formula and is known as the **chain rule**:\n\n$$\nP(x_1, x_2, ..., x_n) = \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})\n$$\n\nCombining the chain rule with the first formula we desire the following equality:\n\n$$\n\\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1}) = \\Pi_{i=1}^{n}{P(x_i | Parents(x_i))}\n$$\n\nOr in vector form:\n\n$$\nP(X_i | X_1, ..., X_{i-1}) = P(X_i | Parents(X_1, ..., X_{i-1}))\n$$\n\nWe get this by enforcing **topological ordering** and linking nodes to their parents in such a way that they are conditionally independent of any other node given their parents.  \n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <nav class=\"toc\">\n      <ol class=\"toc-level toc-level-1\">\n        <li class=\"toc-item toc-item-h2\"><a class=\"toc-link toc-link-h2\" href=\"#definition\">Definition</a></li>\n        <li class=\"toc-item toc-item-h2\"><a class=\"toc-link toc-link-h2\" href=\"#example\">Example</a></li>\n        <li class=\"toc-item toc-item-h2\"><a class=\"toc-link toc-link-h2\" href=\"#semantics\">Semantics</a></li>\n      </ol>\n    </nav>\n    <p><strong>NOTE</strong>: Need to continue this.</p>\n    <h2 id=\"definition\">Definition</h2>\n    <p>A <strong>Bayesian Network (BN)</strong> is a data structure that represents dependencies among different Random Variables. BNs represent the full joint distribution concisely which leads to more efficient query inferences.</p>\n    <p>A Bayesian Network is a directed, acyclic graph whose nodes represent a random variable and the edges represent a parent-child relationship. For every node $X$ the network associates the conditioned probabilities of $X$ as an effect of it's parents, i.e. $P(X | Parents(X))$.</p>\n    <p>Each node is attached with local probability information a.k.a <strong>conditional probability table (CPT)</strong>.</p>\n    <h2 id=\"example\">Example</h2>\n    <p>Let's consider the following scenario. A burglary alarm in Paul's home can be set off by small earthquakes. Paul has two neighbors: Nina and Lei - they promised Paul to call him when they hear the alarm. Nina is very alert but Lei is always busy and is more likely not to hear Paul's alarm. Given a call, what is the probability of a burglary?</p>\n    <p>Below is a BN describing the scenario:</p>\n    <img src=\"https://www.plantuml.com/plantuml/png/IybCBqeio51mLwZcKW22QjV4efACmjB4x5GT1QVIelISnABAMWLTEmL782lN6gm8p0I9LVkaPZedvkGKwoZuPUObWfcrrbor0000\">\n    <p>And the CPT tables:</p>\n    <div class=\"table-container\">\n      <table>\n        <thead>\n          <tr>\n            <th>$P(Burglary=true)$</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td>0.001</td>\n          </tr>\n        </tbody>\n      </table>\n    </div>\n    <div class=\"table-container\">\n      <table>\n        <thead>\n          <tr>\n            <th>$P(Earthquake=true)$</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td>0.002</td>\n          </tr>\n        </tbody>\n      </table>\n    </div>\n    <div class=\"table-container\">\n      <table>\n        <thead>\n          <tr>\n            <th>$Burglary$</th>\n            <th>$Earthquake$</th>\n            <th>$P(Alarm=true \\mid Burglary, Earthquake)$</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td>true</td>\n            <td>true</td>\n            <td>0.95</td>\n          </tr>\n          <tr>\n            <td>true</td>\n            <td>false</td>\n            <td>0.94</td>\n          </tr>\n          <tr>\n            <td>false</td>\n            <td>true</td>\n            <td>0.29</td>\n          </tr>\n          <tr>\n            <td>false</td>\n            <td>false</td>\n            <td>0.001</td>\n          </tr>\n        </tbody>\n      </table>\n    </div>\n    <div class=\"table-container\">\n      <table>\n        <thead>\n          <tr>\n            <th>$Alarm$</th>\n            <th>$P(NinaCalls=true \\mid Alarm)$</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td>true</td>\n            <td>0.9</td>\n          </tr>\n          <tr>\n            <td>false</td>\n            <td>0.05</td>\n          </tr>\n        </tbody>\n      </table>\n    </div>\n    <div class=\"table-container\">\n      <table>\n        <thead>\n          <tr>\n            <th>$Alarm$</th>\n            <th>$P(LeiCalls=true \\mid Alarm)$</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td>true</td>\n            <td>0.7</td>\n          </tr>\n          <tr>\n            <td>false</td>\n            <td>0.01</td>\n          </tr>\n        </tbody>\n      </table>\n    </div>\n    <p class=\"hint tip\">Notice we didn't need to write the complements in the CPTs since they are computable by \"1-...\"</p>\n    <h2 id=\"semantics\">Semantics</h2>\n    <p>We defined the syntax of BNs above. The semantics we want to impose on BNs is that different variables are conditionall independent of each other <strong>given their parents</strong></p>\n    <p>\n      $$\n      P(x_1, x_2, ..., x_n) = \\Pi_{i=1}^{n}{P(x_i | Parents(x_i))}\n      $$\n    </p>\n    <p>In general, we can reduce the joint distribution by iteratively invoking the <strong>product rule</strong>:</p>\n    <p>\n      $$\n      \\begin{align*}\n      P(x_1, x_2, ..., x_n) &#x26;= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_1, x_2, ..., x_{n-1}) \\\\\n      &#x26;= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_{n-1} | x_1, x_2, ..., x_{n=2}) P(x_1, x_2, ..., x_{n-2}) \\\\\n      &#x26;= ... \\\\\n      &#x26;= \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})\n      \\end{align*}\n      $$\n    </p>\n    <p>This is a very important formula and is known as the <strong>chain rule</strong>:</p>\n    <p>\n      $$\n      P(x_1, x_2, ..., x_n) = \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})\n      $$\n    </p>\n    <p>Combining the chain rule with the first formula we desire the following equality:</p>\n    <p>\n      $$\n      \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1}) = \\Pi_{i=1}^{n}{P(x_i | Parents(x_i))}\n      $$\n    </p>\n    <p>Or in vector form:</p>\n    <p>\n      $$\n      P(X_i | X_1, ..., X_{i-1}) = P(X_i | Parents(X_1, ..., X_{i-1}))\n      $$\n    </p>\n    <p>We get this by enforcing <strong>topological ordering</strong> and linking nodes to their parents in such a way that they are conditionally independent of any other node given their parents.</p>\n  </body>\n</html>\n"}}},"__N_SSG":true}