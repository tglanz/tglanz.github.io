{"pageProps":{"category":"Kubernetes","articles":[{"id":"kubernetes/deployments","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/deployments.md","metadata":{"title":"Kubernetes Deployments","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Deployments\n\nA _Deployment_ manages _ReplicaSets_ and _ReplicaSets_ manage _Pods_.\n\n_ReplicaSet_ manage _Pods_ and bring self-healing and scaling capabilities while _Deployments_ manage _ReplicaSets_ and add rollout and rollback capabilities.\n\n### Self-healing and scalability\n\nIf _Pods_ managed by a _Deployment_ fail, they will be replaced - this is known as _self healing_.\n\nIf _Pods_ managed by a _Deployment_ see increased/decreased load, they will be _scaled_.\n\nIn Kubernetes there are 3 related concepts\n\n- _desired state_\n- _observerd state_\n- _reconciliation_\n\n_ReplicaSets_ are implemented as a controller running background process comparing the _desired state_ vs the _observed state_. If they are different it contacts the cluster to perform _reconciliation_.\n\n### Rolling updates\n\nZero downtime, rolling updates (a.k.a rollouts) can be supported when a service has backward and forward compatibility. One by one, the _ReplicaSet_ bring a replica down and introduces a new one with the designated version until all of the _Pods_ are updated with the desired version.\n\nIt is crucial that the services be stateless and backward/forward compatible for this to work.\n\n### Rollbacks\n\n### Commands\n\nTo scale a _Deployment_\n\n    kubectl scale deployment {deployment-name} --replicas {number-of-replicas}\n\nAfter changing image versions, initiate rollouts simply by reaplying a manifest\n\n    kubectl apply -f {manifest-path}\n\nWe can monitor the rollout progress by\n\n    kubectl rollout status deployment {deployment-name}\n\nTo pause a rollout\n\n    kubectl rollout pause deployment {deployment-name}\n\nTo resume a rollout\n\n    kubectl rollout resume deployment {deployment-name}\n\nIn the manifests we can specify ```revisionHistoryLimit``` for containers. \n\nTo show rollout history\n\n    kubectl rollout history deployment {deployment-name}\n\nTo rollback to a revision\n\n    kubectl rollout undo deployment {deployment-name} --to-revision={revision-number}\n\n\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Deployments</h1>\n    <p>A <em>Deployment</em> manages <em>ReplicaSets</em> and <em>ReplicaSets</em> manage <em>Pods</em>.</p>\n    <p><em>ReplicaSet</em> manage <em>Pods</em> and bring self-healing and scaling capabilities while <em>Deployments</em> manage <em>ReplicaSets</em> and add rollout and rollback capabilities.</p>\n    <h3>Self-healing and scalability</h3>\n    <p>If <em>Pods</em> managed by a <em>Deployment</em> fail, they will be replaced - this is known as <em>self healing</em>.</p>\n    <p>If <em>Pods</em> managed by a <em>Deployment</em> see increased/decreased load, they will be <em>scaled</em>.</p>\n    <p>In Kubernetes there are 3 related concepts</p>\n    <ul>\n      <li><em>desired state</em></li>\n      <li><em>observerd state</em></li>\n      <li><em>reconciliation</em></li>\n    </ul>\n    <p><em>ReplicaSets</em> are implemented as a controller running background process comparing the <em>desired state</em> vs the <em>observed state</em>. If they are different it contacts the cluster to perform <em>reconciliation</em>.</p>\n    <h3>Rolling updates</h3>\n    <p>Zero downtime, rolling updates (a.k.a rollouts) can be supported when a service has backward and forward compatibility. One by one, the <em>ReplicaSet</em> bring a replica down and introduces a new one with the designated version until all of the <em>Pods</em> are updated with the desired version.</p>\n    <p>It is crucial that the services be stateless and backward/forward compatible for this to work.</p>\n    <h3>Rollbacks</h3>\n    <h3>Commands</h3>\n    <p>To scale a <em>Deployment</em></p>\n    <pre><code class=\"hljs language-fortran\">kubectl <span class=\"hljs-built_in\">scale</span> deployment {deployment-<span class=\"hljs-keyword\">name</span>} --replicas {<span class=\"hljs-keyword\">number</span>-of-replicas}\n</code></pre>\n    <p>After changing image versions, initiate rollouts simply by reaplying a manifest</p>\n    <pre><code class=\"hljs language-puppet\">kubectl apply -<span class=\"hljs-keyword\">f</span> {<span class=\"hljs-literal\">manifest</span>-<span class=\"hljs-built_in\">path</span>}\n</code></pre>\n    <p>We can monitor the rollout progress by</p>\n    <pre><code class=\"hljs language-fortran\">kubectl rollout <span class=\"hljs-keyword\">status</span> deployment {deployment-<span class=\"hljs-keyword\">name</span>}\n</code></pre>\n    <p>To pause a rollout</p>\n    <pre><code class=\"hljs language-fortran\">kubectl rollout <span class=\"hljs-keyword\">pause</span> deployment {deployment-<span class=\"hljs-keyword\">name</span>}\n</code></pre>\n    <p>To resume a rollout</p>\n    <pre><code class=\"hljs language-basic\">kubectl rollout <span class=\"hljs-keyword\">resume</span> deployment {deployment-<span class=\"hljs-keyword\">name</span>}\n</code></pre>\n    <p>In the manifests we can specify <code>revisionHistoryLimit</code> for containers.</p>\n    <p>To show rollout history</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">kubectl</span> <span class=\"hljs-string\">rollout history deployment {deployment-name}</span>\n</code></pre>\n    <p>To rollback to a revision</p>\n    <pre><code class=\"hljs language-vim\">kubectl rollout <span class=\"hljs-keyword\">undo</span> deployment {deployment-name} --<span class=\"hljs-keyword\">to</span>-revision={revision-<span class=\"hljs-keyword\">number</span>}\n</code></pre>\n  </body>\n</html>\n"}},{"id":"kubernetes/service-discovery","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/service-discovery.md","metadata":{"title":"Service Discovery","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Service Discovery\n\nService discovery is a mean for applications to find one another in the cluster.\n\nThere are two major components to service discovery\n\n- Registration\n- Discovery\n\nService registration is when an application registers itself in a _service registry_.\n\nKubernetes uses its internal DNS as a _service registry_, and as we know, _Services_ are automatically registered with DNS.\n\nFor discovery to work, Kubernetes provides a well-known internal DNS services that are called the __cluster DNS__, in the namespace __kube-system__. Every _Pod_ in the cluster is automatically configured to where this service is. The relevant _Pods_ are managed by a _Deployment_ called __coredns__ and frontend by a _Service_ called __kube-dns__. \n\nFor illustration\n\n```\nkubectl get pods --namespace kube-system --selector k8s-app=kube-dns\n\nNAME                       READY   STATUS    RESTARTS   AGE\ncoredns-6d4b75cb6d-4lpv9   1/1     Running   0          139m\ncoredns-6d4b75cb6d-vmkfz   1/1     Running   0          139m\n\n```\n\nWe specify a _Service_ DNS using it's name (in the metadata)\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Service Discovery</h1>\n    <p>Service discovery is a mean for applications to find one another in the cluster.</p>\n    <p>There are two major components to service discovery</p>\n    <ul>\n      <li>Registration</li>\n      <li>Discovery</li>\n    </ul>\n    <p>Service registration is when an application registers itself in a <em>service registry</em>.</p>\n    <p>Kubernetes uses its internal DNS as a <em>service registry</em>, and as we know, <em>Services</em> are automatically registered with DNS.</p>\n    <p>For discovery to work, Kubernetes provides a well-known internal DNS services that are called the <strong>cluster DNS</strong>, in the namespace <strong>kube-system</strong>. Every <em>Pod</em> in the cluster is automatically configured to where this service is. The relevant <em>Pods</em> are managed by a <em>Deployment</em> called <strong>coredns</strong> and frontend by a <em>Service</em> called <strong>kube-dns</strong>.</p>\n    <p>For illustration</p>\n    <pre><code class=\"hljs language-angelscript\">kubectl <span class=\"hljs-keyword\">get</span> pods --<span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-symbol\">kube</span>-<span class=\"hljs-symbol\">system</span> --<span class=\"hljs-symbol\">selector</span> <span class=\"hljs-symbol\">k8s</span>-<span class=\"hljs-symbol\">app</span>=<span class=\"hljs-symbol\">kube</span>-<span class=\"hljs-symbol\">dns</span>\n\n<span class=\"hljs-symbol\">NAME</span>                       <span class=\"hljs-symbol\">READY</span>   <span class=\"hljs-symbol\">STATUS</span>    <span class=\"hljs-symbol\">RESTARTS</span>   <span class=\"hljs-symbol\">AGE</span>\n<span class=\"hljs-symbol\">coredns</span>-<span class=\"hljs-symbol\">6d4b75cb6d</span>-<span class=\"hljs-symbol\">4lpv9</span>   <span class=\"hljs-symbol\">1</span>/<span class=\"hljs-symbol\">1</span>     <span class=\"hljs-symbol\">Running</span>   <span class=\"hljs-symbol\">0</span>          <span class=\"hljs-symbol\">139m</span>\n<span class=\"hljs-symbol\">coredns</span>-<span class=\"hljs-symbol\">6d4b75cb6d</span>-<span class=\"hljs-symbol\">vmkfz</span>   <span class=\"hljs-symbol\">1</span>/<span class=\"hljs-symbol\">1</span>     <span class=\"hljs-symbol\">Running</span>   <span class=\"hljs-symbol\">0</span>          <span class=\"hljs-symbol\">139m</span>\n\n</code></pre>\n    <p>We specify a <em>Service</em> DNS using it's name (in the metadata)</p>\n  </body>\n</html>\n"}},{"id":"kubernetes/services","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/services.md","metadata":{"title":"Kubernetes Services","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Services \n\n_Service_ provides reliable access to _Pods_.\n\nMain _Service_ concepts\n\n- _Services_ are REST objects in the API that we define in a manifest file or post to the API server.\n- Every service gets it's own __stable IP address__, it's own __stable DNS name__ and it's own __stable port__.\n- _Services_ use __labels__ and __selectors__ to dynamically select the _Pods_ they send traffic to.\n\n_Services_ get a list of healthy pods that match the relevant selctors using a Kubernetes object called an _Endpoint_. Kubernetes is continuously monitoring the state of the _Pods_ and updates the relevant _Endpoints'_ lists.\n\n```bash\n              +----------------+     +------------+     +--------------------------+\n{request} --> | DNS resolution | --> | Service IP | --> | Pod in the Endpoint List |\n              +----------------+     +------------+     +--------------------------+\n```\n\nKubernetes native applications can query the API and directly find the _Service_ IP, bypassing DNS resolution.\n\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Services</h1>\n    <p><em>Service</em> provides reliable access to <em>Pods</em>.</p>\n    <p>Main <em>Service</em> concepts</p>\n    <ul>\n      <li><em>Services</em> are REST objects in the API that we define in a manifest file or post to the API server.</li>\n      <li>Every service gets it's own <strong>stable IP address</strong>, it's own <strong>stable DNS name</strong> and it's own <strong>stable port</strong>.</li>\n      <li><em>Services</em> use <strong>labels</strong> and <strong>selectors</strong> to dynamically select the <em>Pods</em> they send traffic to.</li>\n    </ul>\n    <p><em>Services</em> get a list of healthy pods that match the relevant selctors using a Kubernetes object called an <em>Endpoint</em>. Kubernetes is continuously monitoring the state of the <em>Pods</em> and updates the relevant <em>Endpoints'</em> lists.</p>\n    <pre><code class=\"hljs language-bash\">              +----------------+     +------------+     +--------------------------+\n{request} --> | DNS resolution | --> | Service IP | --> | Pod <span class=\"hljs-keyword\">in</span> the Endpoint List |\n              +----------------+     +------------+     +--------------------------+\n</code></pre>\n    <p>Kubernetes native applications can query the API and directly find the <em>Service</em> IP, bypassing DNS resolution.</p>\n  </body>\n</html>\n"}},{"id":"kubernetes/simple-on-prem-cluster","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/simple-on-prem-cluster.md","metadata":{"title":"Simple on-prem Kuberenetes cluster","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Kubes\n\nDeploy a kubernetes cluster.\n\nWe will setup a simple kubernetes cluster will describe the concepts and process.\n\nThe OS on all nodes is debian bullseye - I specifically executing this using vagrant's box ```debian/bullseye64```.\n\nTo document the steps we will provide bash script snippets for now. But, the goal is to provide configuration files content for something like ansible or chef.\n\n## Container runtime\n\nKubernetes is an orchestration infrastructure and does not provide any containerization - It relies on a different containarization platform, a.k.a the [Container Runtime](https://kubernetes.io/docs/setup/production-environment/container-runtimes/).\n\nWe will use [docker](https://www.docker.com/). Let's install it by following the documentation [Here](https://docs.docker.com/engine/install/debian/).\n\n```\nsudo apt-get remove docker docker-engine docker.io containerd runc\n\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg lsb-release\n\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io\n```\n\nAnother thing to do is docker to utilize systemd for cgroup management (You can read more about it in the container runtimes documentation). To apply this setting we need to edit docker's configuration. There are multiple to do so, for example - edit systemd's service that initiates docker. Another approach is to edit docker's global configuration file which is at ```/etc/docker/daemon.json```. Hence, edit (create if missing) the mentioned file and add\n\n```json\n{\n    ... other configurations\n    \"exec-opts\": [\"native.cgroupdriver=systemd\", ... more exec opts if exists]\n}\n```\n\nOnce done, reboot docker by running ```sudo systemctl restart docker```\n\n## Kube Components\n\nWe will not rely on the package manager to install the components.\n\nDefine the relevant variables\n\n> Note that the cni directory does not include the version! Later we will install a network plugin, it'll be in the same directory\n\n```\nARCH=\"amd64\"\nCNI_VERSION=\"v0.8.2\"\nCNI_DIR=\"/opt/cni/bin\"\nCRICTL_VERSION=\"v1.23.0\"\nCRICTL_DIR=\"/opt/cri/$CRICTL_VERSION/bin\"\nKUBERNETES_VERSION=\"v1.23.3\"\nKUBERNETES_DIR=\"/opt/kubernetes/$KUBERNETES_VERSION\"\n\n# Install [CNI](https://www.cni.dev/)\n\nsudo mkdir -p $CNI_DIR\ncurl -L \"https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz\" | sudo tar -C $CNI_DIR -xz\n\n# Install [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)\n\nsudo mkdir -p $CRICTL_DIR\ncurl -L \"https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz\" | sudo tar -C $CRICTL_DIR -xz\n\n# Install Kube components\n\nsudo mkdir -p $KUBERNETES_DIR\ncd $KUBERNETES_DIR\nfor component in kubeadm kubectl kubelet; do\n  sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/$KUBERNETES_VERSION/bin/linux/$ARCH/$component\n  sudo chmod +x $component\ndone\n\n# and services\n\nRELEASE_VERSION=\"v0.4.0\"\ncurl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\" | sed \"s:/usr/bin:${KUBERNETES_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service\nsudo mkdir -p /etc/systemd/system/kubelet.service.d\ncurl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\" | sed \"s:/usr/bin:${KUBERNETES_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n```\n\nenable, and start kubelet\n\n```\nsudo systemctl enable --now kubelet\n```\n\n## Initialization\n\nInstall prerequesites for kubeadm\n\n```\nsudo apt-get update \nsudo apt install ethtool socat conntrack\n```\n\nCreate an update alternative\n\n```\nsudo update-alternatives --install /usr/bin/kubeadm kubeadm $KUBERNETES_DIR/kubeadm 100\nsudo update-alternatives --install /usr/bin/kubelet kubelet $KUBERNETES_DIR/kubelet 100\nsudo update-alternatives --install /usr/bin/kubectl kubectl $KUBERNETES_DIR/kubectl 100\n```\n\nRun @controlplane\n\n> TODO: load balancer, hostnames\n\nInitialize configuration such that the network is 10.10.0.0/16\n\n```\nsudo kubeadm init --pod-network-cidr 10.10.0.0/16 --apiserver-advertise-address {ip}\n```\n\nFor documentation, you should see something like\n\n```\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.121.210:6443 --token clns4a.b29f6anjipygy0e2 \\\n\t--discovery-token-ca-cert-hash sha256:833f599cc9ab27eb5010c499e9c77e8e3263fb991d8e9e78ef187ba97e1efb59\n```\n\nDo as it says, run\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\nWe will use [Weave Net](https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/) as a network plugin\n\n```\nkubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"\n```\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h1>Kubes</h1>\n    <p>Deploy a kubernetes cluster.</p>\n    <p>We will setup a simple kubernetes cluster will describe the concepts and process.</p>\n    <p>The OS on all nodes is debian bullseye - I specifically executing this using vagrant's box <code>debian/bullseye64</code>.</p>\n    <p>To document the steps we will provide bash script snippets for now. But, the goal is to provide configuration files content for something like ansible or chef.</p>\n    <h2>Container runtime</h2>\n    <p>Kubernetes is an orchestration infrastructure and does not provide any containerization - It relies on a different containarization platform, a.k.a the <a href=\"https://kubernetes.io/docs/setup/production-environment/container-runtimes/\">Container Runtime</a>.</p>\n    <p>We will use <a href=\"https://www.docker.com/\">docker</a>. Let's install it by following the documentation <a href=\"https://docs.docker.com/engine/install/debian/\">Here</a>.</p>\n    <pre><code class=\"hljs language-basic\">sudo apt-<span class=\"hljs-keyword\">get</span> <span class=\"hljs-comment\">remove docker docker-engine docker.io containerd runc</span>\n\nsudo apt-<span class=\"hljs-keyword\">get</span> update\nsudo apt-<span class=\"hljs-keyword\">get</span> install ca-certificates curl gnupg lsb-release\n\ncurl -fsSL https://download.docker.<span class=\"hljs-keyword\">com</span>/linux/debian/gpg | sudo gpg --dearmor -o /<span class=\"hljs-keyword\">usr</span>/share/keyrings/docker-archive-keyring.gpg\n\necho \\\n  <span class=\"hljs-string\">\"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\"</span> | sudo tee /etc/apt/sources.<span class=\"hljs-keyword\">list</span>.d/docker.<span class=\"hljs-keyword\">list</span> > /dev/null\n\nsudo apt-<span class=\"hljs-keyword\">get</span> update\nsudo apt-<span class=\"hljs-keyword\">get</span> install docker-ce docker-ce-cli containerd.io\n</code></pre>\n    <p>Another thing to do is docker to utilize systemd for cgroup management (You can read more about it in the container runtimes documentation). To apply this setting we need to edit docker's configuration. There are multiple to do so, for example - edit systemd's service that initiates docker. Another approach is to edit docker's global configuration file which is at <code>/etc/docker/daemon.json</code>. Hence, edit (create if missing) the mentioned file and add</p>\n    <pre><code class=\"hljs language-json\"><span class=\"hljs-punctuation\">{</span>\n    ... other configurations\n    <span class=\"hljs-attr\">\"exec-opts\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"native.cgroupdriver=systemd\"</span><span class=\"hljs-punctuation\">,</span> ... more exec opts if exists<span class=\"hljs-punctuation\">]</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre>\n    <p>Once done, reboot docker by running <code>sudo systemctl restart docker</code></p>\n    <h2>Kube Components</h2>\n    <p>We will not rely on the package manager to install the components.</p>\n    <p>Define the relevant variables</p>\n    <blockquote>\n      <p>Note that the cni directory does not include the version! Later we will install a network plugin, it'll be in the same directory</p>\n    </blockquote>\n    <pre><code class=\"hljs language-bash\">ARCH=<span class=\"hljs-string\">\"amd64\"</span>\nCNI_VERSION=<span class=\"hljs-string\">\"v0.8.2\"</span>\nCNI_DIR=<span class=\"hljs-string\">\"/opt/cni/bin\"</span>\nCRICTL_VERSION=<span class=\"hljs-string\">\"v1.23.0\"</span>\nCRICTL_DIR=<span class=\"hljs-string\">\"/opt/cri/<span class=\"hljs-variable\">$CRICTL_VERSION</span>/bin\"</span>\nKUBERNETES_VERSION=<span class=\"hljs-string\">\"v1.23.3\"</span>\nKUBERNETES_DIR=<span class=\"hljs-string\">\"/opt/kubernetes/<span class=\"hljs-variable\">$KUBERNETES_VERSION</span>\"</span>\n\n<span class=\"hljs-comment\"># Install [CNI](https://www.cni.dev/)</span>\n\nsudo <span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$CNI_DIR</span>\ncurl -L <span class=\"hljs-string\">\"https://github.com/containernetworking/plugins/releases/download/<span class=\"hljs-variable\">${CNI_VERSION}</span>/cni-plugins-linux-<span class=\"hljs-variable\">${ARCH}</span>-<span class=\"hljs-variable\">${CNI_VERSION}</span>.tgz\"</span> | sudo tar -C <span class=\"hljs-variable\">$CNI_DIR</span> -xz\n\n<span class=\"hljs-comment\"># Install [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)</span>\n\nsudo <span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$CRICTL_DIR</span>\ncurl -L <span class=\"hljs-string\">\"https://github.com/kubernetes-sigs/cri-tools/releases/download/<span class=\"hljs-variable\">${CRICTL_VERSION}</span>/crictl-<span class=\"hljs-variable\">${CRICTL_VERSION}</span>-linux-<span class=\"hljs-variable\">${ARCH}</span>.tar.gz\"</span> | sudo tar -C <span class=\"hljs-variable\">$CRICTL_DIR</span> -xz\n\n<span class=\"hljs-comment\"># Install Kube components</span>\n\nsudo <span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$KUBERNETES_DIR</span>\n<span class=\"hljs-built_in\">cd</span> <span class=\"hljs-variable\">$KUBERNETES_DIR</span>\n<span class=\"hljs-keyword\">for</span> component <span class=\"hljs-keyword\">in</span> kubeadm kubectl kubelet; <span class=\"hljs-keyword\">do</span>\n  sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/<span class=\"hljs-variable\">$KUBERNETES_VERSION</span>/bin/linux/<span class=\"hljs-variable\">$ARCH</span>/<span class=\"hljs-variable\">$component</span>\n  sudo <span class=\"hljs-built_in\">chmod</span> +x <span class=\"hljs-variable\">$component</span>\n<span class=\"hljs-keyword\">done</span>\n\n<span class=\"hljs-comment\"># and services</span>\n\nRELEASE_VERSION=<span class=\"hljs-string\">\"v0.4.0\"</span>\ncurl -sSL <span class=\"hljs-string\">\"https://raw.githubusercontent.com/kubernetes/release/<span class=\"hljs-variable\">${RELEASE_VERSION}</span>/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\"</span> | sed <span class=\"hljs-string\">\"s:/usr/bin:<span class=\"hljs-variable\">${KUBERNETES_DIR}</span>:g\"</span> | sudo <span class=\"hljs-built_in\">tee</span> /etc/systemd/system/kubelet.service\nsudo <span class=\"hljs-built_in\">mkdir</span> -p /etc/systemd/system/kubelet.service.d\ncurl -sSL <span class=\"hljs-string\">\"https://raw.githubusercontent.com/kubernetes/release/<span class=\"hljs-variable\">${RELEASE_VERSION}</span>/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\"</span> | sed <span class=\"hljs-string\">\"s:/usr/bin:<span class=\"hljs-variable\">${KUBERNETES_DIR}</span>:g\"</span> | sudo <span class=\"hljs-built_in\">tee</span> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n</code></pre>\n    <p>enable, and start kubelet</p>\n    <pre><code class=\"hljs language-pgsql\">sudo systemctl <span class=\"hljs-keyword\">enable</span> <span class=\"hljs-comment\">--now kubelet</span>\n</code></pre>\n    <h2>Initialization</h2>\n    <p>Install prerequesites for kubeadm</p>\n    <pre><code class=\"hljs language-properties\"><span class=\"hljs-attr\">sudo</span> <span class=\"hljs-string\">apt-get update </span>\n<span class=\"hljs-attr\">sudo</span> <span class=\"hljs-string\">apt install ethtool socat conntrack</span>\n</code></pre>\n    <p>Create an update alternative</p>\n    <pre><code class=\"hljs language-awk\">sudo update-alternatives --install <span class=\"hljs-regexp\">/usr/</span>bin<span class=\"hljs-regexp\">/kubeadm kubeadm $KUBERNETES_DIR/</span>kubeadm <span class=\"hljs-number\">100</span>\nsudo update-alternatives --install <span class=\"hljs-regexp\">/usr/</span>bin<span class=\"hljs-regexp\">/kubelet kubelet $KUBERNETES_DIR/</span>kubelet <span class=\"hljs-number\">100</span>\nsudo update-alternatives --install <span class=\"hljs-regexp\">/usr/</span>bin<span class=\"hljs-regexp\">/kubectl kubectl $KUBERNETES_DIR/</span>kubectl <span class=\"hljs-number\">100</span>\n</code></pre>\n    <p>Run @controlplane</p>\n    <blockquote>\n      <p>TODO: load balancer, hostnames</p>\n    </blockquote>\n    <p>Initialize configuration such that the network is 10.10.0.0/16</p>\n    <pre><code class=\"hljs language-apache\"><span class=\"hljs-attribute\">sudo</span> kubeadm init --pod-network-cidr <span class=\"hljs-number\">10.10.0.0</span>/<span class=\"hljs-number\">16</span> --apiserver-advertise-address {ip}\n</code></pre>\n    <p>For documentation, you should see something like</p>\n    <pre><code class=\"hljs language-pgsql\">Your Kubernetes control-plane has initialized successfully!\n\n<span class=\"hljs-keyword\">To</span> <span class=\"hljs-keyword\">start</span> <span class=\"hljs-keyword\">using</span> your <span class=\"hljs-keyword\">cluster</span>, you need <span class=\"hljs-keyword\">to</span> run the <span class=\"hljs-keyword\">following</span> <span class=\"hljs-keyword\">as</span> a regular <span class=\"hljs-keyword\">user</span>:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/<span class=\"hljs-keyword\">admin</span>.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, <span class=\"hljs-keyword\">if</span> you are the root <span class=\"hljs-keyword\">user</span>, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/<span class=\"hljs-keyword\">admin</span>.conf\n\nYou should now deploy a pod network <span class=\"hljs-keyword\">to</span> the <span class=\"hljs-keyword\">cluster</span>.\nRun \"kubectl apply -f [podnetwork].yaml\" <span class=\"hljs-keyword\">with</span> one <span class=\"hljs-keyword\">of</span> the <span class=\"hljs-keyword\">options</span> listed at:\n  https://kubernetes.io/docs/concepts/<span class=\"hljs-keyword\">cluster</span>-administration/addons/\n\n<span class=\"hljs-keyword\">Then</span> you can <span class=\"hljs-keyword\">join</span> <span class=\"hljs-keyword\">any</span> number <span class=\"hljs-keyword\">of</span> worker nodes <span class=\"hljs-keyword\">by</span> running the <span class=\"hljs-keyword\">following</span> <span class=\"hljs-keyword\">on</span> <span class=\"hljs-keyword\">each</span> <span class=\"hljs-keyword\">as</span> root:\n\nkubeadm <span class=\"hljs-keyword\">join</span> <span class=\"hljs-number\">192.168</span><span class=\"hljs-number\">.121</span><span class=\"hljs-number\">.210</span>:<span class=\"hljs-number\">6443</span> <span class=\"hljs-comment\">--token clns4a.b29f6anjipygy0e2 \\</span>\n\t<span class=\"hljs-comment\">--discovery-token-ca-cert-hash sha256:833f599cc9ab27eb5010c499e9c77e8e3263fb991d8e9e78ef187ba97e1efb59</span>\n</code></pre>\n    <p>Do as it says, run</p>\n    <pre><code class=\"hljs language-bash\"><span class=\"hljs-built_in\">mkdir</span> -p <span class=\"hljs-variable\">$HOME</span>/.kube\nsudo <span class=\"hljs-built_in\">cp</span> -i /etc/kubernetes/admin.conf <span class=\"hljs-variable\">$HOME</span>/.kube/config\nsudo <span class=\"hljs-built_in\">chown</span> $(<span class=\"hljs-built_in\">id</span> -u):$(<span class=\"hljs-built_in\">id</span> -g) <span class=\"hljs-variable\">$HOME</span>/.kube/config\n</code></pre>\n    <p>We will use <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/\">Weave Net</a> as a network plugin</p>\n    <pre><code class=\"hljs language-powershell\">kubectl apply <span class=\"hljs-operator\">-f</span> <span class=\"hljs-string\">\"https://cloud.weave.works/k8s/net?k8s-version=<span class=\"hljs-variable\">$</span>(kubectl version | base64 | tr -d '\\n')\"</span>\n</code></pre>\n  </body>\n</html>\n"}},{"id":"kubernetes/storage","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/storage.md","metadata":{"title":"Storage","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\nKubernetes abstracts the storage through a __plugin layer__. The plugin layer is the interface that connects external storage with Kubernetes. The layer can mediate between any kind of storage, be it file based, bloc of object based, on-prem or cloud.\n\nMost plugins are based on the __Container Storage Interface (CSI)__ which is an open standard.\n\n> TBD\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <p>Kubernetes abstracts the storage through a <strong>plugin layer</strong>. The plugin layer is the interface that connects external storage with Kubernetes. The layer can mediate between any kind of storage, be it file based, bloc of object based, on-prem or cloud.</p>\n    <p>Most plugins are based on the <strong>Container Storage Interface (CSI)</strong> which is an open standard.</p>\n    <blockquote>\n      <p>TBD</p>\n    </blockquote>\n  </body>\n</html>\n"}},{"id":"kubernetes/technical-overview","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/technical-overview.md","metadata":{"title":"Kubernetes technical overview","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n## Application packaging\n\nAn application should be\n\n1. Packaged as a container\n1. Wrapped in a _Pod_\n1. Deployed via a declerative manifest file\n\n## The declerative model \n\nAccording to the _declerative model_, we only declare about how we want the application to look like. It is Kubernetes' jpb to make sure the cluster behaves as intended.\n\n_Manifests_ simple YAML files and they tell Kubernetes how the application should look like - the _desired state_.\n\n_Controllers_ are constantly running and monitor the application's state, reconciling and difference betweeen the _observerd state_ and the _desired state_.\n\n## Pods\n\nIn Kubernetes, _Pods_ are the atomic unit of scheduling. Kubernetes demands that every container runs inside a pod.\n\nA simple model is to run a sigle container in every pod. \n\nEffectively, a _Pod_ is a construct for running one or more containers.\n\nPods are the most basic unit of scaling. We scale applications by adding or removing pods (not containers).\n\nPods are deployed atomiclly. A pod is ready only when all containers are up and running. A single pod executes on a single Node.\n\nWhen a pod dies, a new one takes it's place. The new pod is a different instance with the same semantics, it has different id, ip etc..\n\nPods are immutable. If we want to change a pod's configuration, we must create a new pod to take it's place.\n\n### Pod theory\n\nThere are 3 main reasons for Pods to exist\n\n1. Pods augment containers 1. Pods assist in scheduling\n1. Pods enable resource sharing\n\nThe augmentation is done in the following ways\n\n- Labels / annotations\n- Restart policies\n- Probes (startup, readiness, liveness etc...)\n- Affinity / anti-affinity rules (Affinities are related to specifying how specific pods behave with other pods)\n- Termination control\n- Security policies\n- Resource requests and limits (min/max values on CPU, memory and I/O)\n\nPods have __Labels__ which lets us group Pods and associate them with other objects. \n\nRegarding resource sharing, Pods provide _shared execution environment_ for one or more containers. It includes\n\n- Filesystem\n- Network stack (IP address, routing, ports)\n- Memory\n- Volumes\n\nPods can be deployed either directly via a Pod manifest or indirectly via a controller. Pods deployed directly are called _static pods_.\n\n## Deployments\n\nA _Deployment_ is a higher-level controller. Usually we will deploy pods indirectly via a deployment.\n\nThe deployment controller monitors the state of a wrapped pod providing extra features such as self-healing, scaling, zero-downtime rollouts and versioned rollbacks.\n\n## Services\n\nA _Service_ is a Kubernetes contstruct which provides reliable networking for a set of pods.\n\nAs we know, pods are immutable and modifications due to auto scaling, rollbacks etc... result in replacements of pods - and the effective IPs.\n\n_Services_ provide reliable names and IPs and provide load balancing capabilities over a set of pods.\n\n## Examples of controllers\n\n- Deployments\n- DaemonSets\n- StatefulSets\n\n## Generall usefull commands\n\nList all possible Pod attributes\n\n    kubectl explain pods --recursive\n\n## Multi container patterns\n\nKubernetes offers several well-defined multi-container Pod patterns\n\n### Sidecar pattern\n\nThis pattern has a _main_ application container and a _sidecar_ container. The _sidecar's_ job is to augment and perform secondary tasks for the _main_ application container.\n\n### Adapter pattern\n\nThis pattern is a specific variation of the _sidecar pattern_ where the _sidecar_ container takes non-standardized output from the _main_ container and standardize it as required by an external system.\n\n### Ambassador pattern\n\nThis is another variation of the _sidecar pattern_ where the _sidecar_ brokers connectivity to an external system.\n\n### Init pattern\n\nThis pattern has an _init_ container that's gauranteed to start and complete before your _main_ application container. It is also gauranteed to run exactly once!\n","html":"<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <h2>Application packaging</h2>\n    <p>An application should be</p>\n    <ol>\n      <li>Packaged as a container</li>\n      <li>Wrapped in a <em>Pod</em></li>\n      <li>Deployed via a declerative manifest file</li>\n    </ol>\n    <h2>The declerative model</h2>\n    <p>According to the <em>declerative model</em>, we only declare about how we want the application to look like. It is Kubernetes' jpb to make sure the cluster behaves as intended.</p>\n    <p><em>Manifests</em> simple YAML files and they tell Kubernetes how the application should look like - the <em>desired state</em>.</p>\n    <p><em>Controllers</em> are constantly running and monitor the application's state, reconciling and difference betweeen the <em>observerd state</em> and the <em>desired state</em>.</p>\n    <h2>Pods</h2>\n    <p>In Kubernetes, <em>Pods</em> are the atomic unit of scheduling. Kubernetes demands that every container runs inside a pod.</p>\n    <p>A simple model is to run a sigle container in every pod.</p>\n    <p>Effectively, a <em>Pod</em> is a construct for running one or more containers.</p>\n    <p>Pods are the most basic unit of scaling. We scale applications by adding or removing pods (not containers).</p>\n    <p>Pods are deployed atomiclly. A pod is ready only when all containers are up and running. A single pod executes on a single Node.</p>\n    <p>When a pod dies, a new one takes it's place. The new pod is a different instance with the same semantics, it has different id, ip etc..</p>\n    <p>Pods are immutable. If we want to change a pod's configuration, we must create a new pod to take it's place.</p>\n    <h3>Pod theory</h3>\n    <p>There are 3 main reasons for Pods to exist</p>\n    <ol>\n      <li>Pods augment containers 1. Pods assist in scheduling</li>\n      <li>Pods enable resource sharing</li>\n    </ol>\n    <p>The augmentation is done in the following ways</p>\n    <ul>\n      <li>Labels / annotations</li>\n      <li>Restart policies</li>\n      <li>Probes (startup, readiness, liveness etc...)</li>\n      <li>Affinity / anti-affinity rules (Affinities are related to specifying how specific pods behave with other pods)</li>\n      <li>Termination control</li>\n      <li>Security policies</li>\n      <li>Resource requests and limits (min/max values on CPU, memory and I/O)</li>\n    </ul>\n    <p>Pods have <strong>Labels</strong> which lets us group Pods and associate them with other objects.</p>\n    <p>Regarding resource sharing, Pods provide <em>shared execution environment</em> for one or more containers. It includes</p>\n    <ul>\n      <li>Filesystem</li>\n      <li>Network stack (IP address, routing, ports)</li>\n      <li>Memory</li>\n      <li>Volumes</li>\n    </ul>\n    <p>Pods can be deployed either directly via a Pod manifest or indirectly via a controller. Pods deployed directly are called <em>static pods</em>.</p>\n    <h2>Deployments</h2>\n    <p>A <em>Deployment</em> is a higher-level controller. Usually we will deploy pods indirectly via a deployment.</p>\n    <p>The deployment controller monitors the state of a wrapped pod providing extra features such as self-healing, scaling, zero-downtime rollouts and versioned rollbacks.</p>\n    <h2>Services</h2>\n    <p>A <em>Service</em> is a Kubernetes contstruct which provides reliable networking for a set of pods.</p>\n    <p>As we know, pods are immutable and modifications due to auto scaling, rollbacks etc... result in replacements of pods - and the effective IPs.</p>\n    <p><em>Services</em> provide reliable names and IPs and provide load balancing capabilities over a set of pods.</p>\n    <h2>Examples of controllers</h2>\n    <ul>\n      <li>Deployments</li>\n      <li>DaemonSets</li>\n      <li>StatefulSets</li>\n    </ul>\n    <h2>Generall usefull commands</h2>\n    <p>List all possible Pod attributes</p>\n    <pre><code class=\"hljs language-pgsql\">kubectl <span class=\"hljs-keyword\">explain</span> pods <span class=\"hljs-comment\">--recursive</span>\n</code></pre>\n    <h2>Multi container patterns</h2>\n    <p>Kubernetes offers several well-defined multi-container Pod patterns</p>\n    <h3>Sidecar pattern</h3>\n    <p>This pattern has a <em>main</em> application container and a <em>sidecar</em> container. The <em>sidecar's</em> job is to augment and perform secondary tasks for the <em>main</em> application container.</p>\n    <h3>Adapter pattern</h3>\n    <p>This pattern is a specific variation of the <em>sidecar pattern</em> where the <em>sidecar</em> container takes non-standardized output from the <em>main</em> container and standardize it as required by an external system.</p>\n    <h3>Ambassador pattern</h3>\n    <p>This is another variation of the <em>sidecar pattern</em> where the <em>sidecar</em> brokers connectivity to an external system.</p>\n    <h3>Init pattern</h3>\n    <p>This pattern has an <em>init</em> container that's gauranteed to start and complete before your <em>main</em> application container. It is also gauranteed to run exactly once!</p>\n  </body>\n</html>\n"}}]},"__N_SSG":true}