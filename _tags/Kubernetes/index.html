<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/b24dfbaff566f11b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b24dfbaff566f11b.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-20cc5a3cc3d233fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-97927b8cd08b2c1f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6522ec515b61e54e.js" defer=""></script><script src="/_next/static/chunks/pages/_tags/%5Btag%5D-78797b533043948c.js" defer=""></script><script src="/_next/static/wQSJSBKb1V3HQur7R1QQA/_buildManifest.js" defer=""></script><script src="/_next/static/wQSJSBKb1V3HQur7R1QQA/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_container__K9hpm"><nav class="p-6 border border-r-2"><div class="flex flex-col items-center"><img src="/logo.png" width="100" height="100"/><span class="text-3xl font-semibold">Tal Glanzman</span><span class="text-lg">Software Engineer</span></div><div class="mt-6"><ul><li><a href="/">Home</a></li><details><summary>Advanced CS</summary><ul class="ml-4"><li><a href="/_articles/advanced-cs/linear-programming/">Linear Programming</a></li><li><a href="/_articles/advanced-cs/expanders/">Expanders</a></li></ul></details><li><a href="/_articles/about/">About</a></li></ul></div></nav><header><div class=" p-2 flex flex-col items-center"><span class="text-4xl font-semibold">Kubernetes</span><span class="text-lg">Tag</span></div></header><main><div class="my-8"><div><a class="text-2xl font-bold" href="/_articles/kubernetes/deployments/">Kubernetes Deployments</a><div class="mb-2"></div><div class="text-sm"><span>Categories<!-- -->: </span><span><span class="inline-block"><a href="/_categories/Kubernetes/">Kubernetes</a></span></span></div><div class="text-sm"><span>Tags<!-- -->: </span><span><span class="inline-block"><a href="/_tags/Kubernetes/">Kubernetes</a></span></span></div></div></div><div class="my-8"><div><a class="text-2xl font-bold" href="/_articles/kubernetes/service-discovery/">Service Discovery</a><div class="mb-2"></div><div class="text-sm"><span>Categories<!-- -->: </span><span><span class="inline-block"><a href="/_categories/Kubernetes/">Kubernetes</a></span></span></div><div class="text-sm"><span>Tags<!-- -->: </span><span><span class="inline-block"><a href="/_tags/Kubernetes/">Kubernetes</a></span></span></div></div></div><div class="my-8"><div><a class="text-2xl font-bold" href="/_articles/kubernetes/services/">Kubernetes Services</a><div class="mb-2"></div><div class="text-sm"><span>Categories<!-- -->: </span><span><span class="inline-block"><a href="/_categories/Kubernetes/">Kubernetes</a></span></span></div><div class="text-sm"><span>Tags<!-- -->: </span><span><span class="inline-block"><a href="/_tags/Kubernetes/">Kubernetes</a></span></span></div></div></div><div class="my-8"><div><a class="text-2xl font-bold" href="/_articles/kubernetes/simple-on-prem-cluster/">Simple on-prem Kuberenetes cluster</a><div class="mb-2"></div><div class="text-sm"><span>Categories<!-- -->: </span><span><span class="inline-block"><a href="/_categories/Kubernetes/">Kubernetes</a></span></span></div><div class="text-sm"><span>Tags<!-- -->: </span><span><span class="inline-block"><a href="/_tags/Kubernetes/">Kubernetes</a></span></span></div></div></div><div class="my-8"><div><a class="text-2xl font-bold" href="/_articles/kubernetes/storage/">Storage</a><div class="mb-2"></div><div class="text-sm"><span>Categories<!-- -->: </span><span><span class="inline-block"><a href="/_categories/Kubernetes/">Kubernetes</a></span></span></div><div class="text-sm"><span>Tags<!-- -->: </span><span><span class="inline-block"><a href="/_tags/Kubernetes/">Kubernetes</a></span></span></div></div></div><div class="my-8"><div><a class="text-2xl font-bold" href="/_articles/kubernetes/technical-overview/">Kubernetes technical overview</a><div class="mb-2"></div><div class="text-sm"><span>Categories<!-- -->: </span><span><span class="inline-block"><a href="/_categories/Kubernetes/">Kubernetes</a></span></span></div><div class="text-sm"><span>Tags<!-- -->: </span><span><span class="inline-block"><a href="/_tags/Kubernetes/">Kubernetes</a></span></span></div></div></div></main><footer><div class=" border-t-2 p-4 flex flex-row justify-center items-center space-x-4"><a href="https://github.com/tglanz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://il.linkedin.com/in/tal-glanzman"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"tag":"Kubernetes","articles":[{"id":"kubernetes/deployments","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/deployments.md","metadata":{"title":"Kubernetes Deployments","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Deployments\n\nA _Deployment_ manages _ReplicaSets_ and _ReplicaSets_ manage _Pods_.\n\n_ReplicaSet_ manage _Pods_ and bring self-healing and scaling capabilities while _Deployments_ manage _ReplicaSets_ and add rollout and rollback capabilities.\n\n### Self-healing and scalability\n\nIf _Pods_ managed by a _Deployment_ fail, they will be replaced - this is known as _self healing_.\n\nIf _Pods_ managed by a _Deployment_ see increased/decreased load, they will be _scaled_.\n\nIn Kubernetes there are 3 related concepts\n\n- _desired state_\n- _observerd state_\n- _reconciliation_\n\n_ReplicaSets_ are implemented as a controller running background process comparing the _desired state_ vs the _observed state_. If they are different it contacts the cluster to perform _reconciliation_.\n\n### Rolling updates\n\nZero downtime, rolling updates (a.k.a rollouts) can be supported when a service has backward and forward compatibility. One by one, the _ReplicaSet_ bring a replica down and introduces a new one with the designated version until all of the _Pods_ are updated with the desired version.\n\nIt is crucial that the services be stateless and backward/forward compatible for this to work.\n\n### Rollbacks\n\n### Commands\n\nTo scale a _Deployment_\n\n    kubectl scale deployment {deployment-name} --replicas {number-of-replicas}\n\nAfter changing image versions, initiate rollouts simply by reaplying a manifest\n\n    kubectl apply -f {manifest-path}\n\nWe can monitor the rollout progress by\n\n    kubectl rollout status deployment {deployment-name}\n\nTo pause a rollout\n\n    kubectl rollout pause deployment {deployment-name}\n\nTo resume a rollout\n\n    kubectl rollout resume deployment {deployment-name}\n\nIn the manifests we can specify ```revisionHistoryLimit``` for containers. \n\nTo show rollout history\n\n    kubectl rollout history deployment {deployment-name}\n\nTo rollback to a revision\n\n    kubectl rollout undo deployment {deployment-name} --to-revision={revision-number}\n\n\n","html":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003ch1\u003eDeployments\u003c/h1\u003e\n    \u003cp\u003eA \u003cem\u003eDeployment\u003c/em\u003e manages \u003cem\u003eReplicaSets\u003c/em\u003e and \u003cem\u003eReplicaSets\u003c/em\u003e manage \u003cem\u003ePods\u003c/em\u003e.\u003c/p\u003e\n    \u003cp\u003e\u003cem\u003eReplicaSet\u003c/em\u003e manage \u003cem\u003ePods\u003c/em\u003e and bring self-healing and scaling capabilities while \u003cem\u003eDeployments\u003c/em\u003e manage \u003cem\u003eReplicaSets\u003c/em\u003e and add rollout and rollback capabilities.\u003c/p\u003e\n    \u003ch3\u003eSelf-healing and scalability\u003c/h3\u003e\n    \u003cp\u003eIf \u003cem\u003ePods\u003c/em\u003e managed by a \u003cem\u003eDeployment\u003c/em\u003e fail, they will be replaced - this is known as \u003cem\u003eself healing\u003c/em\u003e.\u003c/p\u003e\n    \u003cp\u003eIf \u003cem\u003ePods\u003c/em\u003e managed by a \u003cem\u003eDeployment\u003c/em\u003e see increased/decreased load, they will be \u003cem\u003escaled\u003c/em\u003e.\u003c/p\u003e\n    \u003cp\u003eIn Kubernetes there are 3 related concepts\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003e\u003cem\u003edesired state\u003c/em\u003e\u003c/li\u003e\n      \u003cli\u003e\u003cem\u003eobserverd state\u003c/em\u003e\u003c/li\u003e\n      \u003cli\u003e\u003cem\u003ereconciliation\u003c/em\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003cp\u003e\u003cem\u003eReplicaSets\u003c/em\u003e are implemented as a controller running background process comparing the \u003cem\u003edesired state\u003c/em\u003e vs the \u003cem\u003eobserved state\u003c/em\u003e. If they are different it contacts the cluster to perform \u003cem\u003ereconciliation\u003c/em\u003e.\u003c/p\u003e\n    \u003ch3\u003eRolling updates\u003c/h3\u003e\n    \u003cp\u003eZero downtime, rolling updates (a.k.a rollouts) can be supported when a service has backward and forward compatibility. One by one, the \u003cem\u003eReplicaSet\u003c/em\u003e bring a replica down and introduces a new one with the designated version until all of the \u003cem\u003ePods\u003c/em\u003e are updated with the desired version.\u003c/p\u003e\n    \u003cp\u003eIt is crucial that the services be stateless and backward/forward compatible for this to work.\u003c/p\u003e\n    \u003ch3\u003eRollbacks\u003c/h3\u003e\n    \u003ch3\u003eCommands\u003c/h3\u003e\n    \u003cp\u003eTo scale a \u003cem\u003eDeployment\u003c/em\u003e\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-fortran\"\u003ekubectl \u003cspan class=\"hljs-built_in\"\u003escale\u003c/span\u003e deployment {deployment-\u003cspan class=\"hljs-keyword\"\u003ename\u003c/span\u003e} --replicas {\u003cspan class=\"hljs-keyword\"\u003enumber\u003c/span\u003e-of-replicas}\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eAfter changing image versions, initiate rollouts simply by reaplying a manifest\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-puppet\"\u003ekubectl apply -\u003cspan class=\"hljs-keyword\"\u003ef\u003c/span\u003e {\u003cspan class=\"hljs-literal\"\u003emanifest\u003c/span\u003e-\u003cspan class=\"hljs-built_in\"\u003epath\u003c/span\u003e}\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eWe can monitor the rollout progress by\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-fortran\"\u003ekubectl rollout \u003cspan class=\"hljs-keyword\"\u003estatus\u003c/span\u003e deployment {deployment-\u003cspan class=\"hljs-keyword\"\u003ename\u003c/span\u003e}\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eTo pause a rollout\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-fortran\"\u003ekubectl rollout \u003cspan class=\"hljs-keyword\"\u003epause\u003c/span\u003e deployment {deployment-\u003cspan class=\"hljs-keyword\"\u003ename\u003c/span\u003e}\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eTo resume a rollout\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-basic\"\u003ekubectl rollout \u003cspan class=\"hljs-keyword\"\u003eresume\u003c/span\u003e deployment {deployment-\u003cspan class=\"hljs-keyword\"\u003ename\u003c/span\u003e}\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eIn the manifests we can specify \u003ccode\u003erevisionHistoryLimit\u003c/code\u003e for containers.\u003c/p\u003e\n    \u003cp\u003eTo show rollout history\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-properties\"\u003e\u003cspan class=\"hljs-attr\"\u003ekubectl\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003erollout history deployment {deployment-name}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eTo rollback to a revision\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-vim\"\u003ekubectl rollout \u003cspan class=\"hljs-keyword\"\u003eundo\u003c/span\u003e deployment {deployment-name} --\u003cspan class=\"hljs-keyword\"\u003eto\u003c/span\u003e-revision={revision-\u003cspan class=\"hljs-keyword\"\u003enumber\u003c/span\u003e}\n\u003c/code\u003e\u003c/pre\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"}},{"id":"kubernetes/service-discovery","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/service-discovery.md","metadata":{"title":"Service Discovery","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Service Discovery\n\nService discovery is a mean for applications to find one another in the cluster.\n\nThere are two major components to service discovery\n\n- Registration\n- Discovery\n\nService registration is when an application registers itself in a _service registry_.\n\nKubernetes uses its internal DNS as a _service registry_, and as we know, _Services_ are automatically registered with DNS.\n\nFor discovery to work, Kubernetes provides a well-known internal DNS services that are called the __cluster DNS__, in the namespace __kube-system__. Every _Pod_ in the cluster is automatically configured to where this service is. The relevant _Pods_ are managed by a _Deployment_ called __coredns__ and frontend by a _Service_ called __kube-dns__. \n\nFor illustration\n\n```\nkubectl get pods --namespace kube-system --selector k8s-app=kube-dns\n\nNAME                       READY   STATUS    RESTARTS   AGE\ncoredns-6d4b75cb6d-4lpv9   1/1     Running   0          139m\ncoredns-6d4b75cb6d-vmkfz   1/1     Running   0          139m\n\n```\n\nWe specify a _Service_ DNS using it's name (in the metadata)\n","html":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003ch1\u003eService Discovery\u003c/h1\u003e\n    \u003cp\u003eService discovery is a mean for applications to find one another in the cluster.\u003c/p\u003e\n    \u003cp\u003eThere are two major components to service discovery\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eRegistration\u003c/li\u003e\n      \u003cli\u003eDiscovery\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003cp\u003eService registration is when an application registers itself in a \u003cem\u003eservice registry\u003c/em\u003e.\u003c/p\u003e\n    \u003cp\u003eKubernetes uses its internal DNS as a \u003cem\u003eservice registry\u003c/em\u003e, and as we know, \u003cem\u003eServices\u003c/em\u003e are automatically registered with DNS.\u003c/p\u003e\n    \u003cp\u003eFor discovery to work, Kubernetes provides a well-known internal DNS services that are called the \u003cstrong\u003ecluster DNS\u003c/strong\u003e, in the namespace \u003cstrong\u003ekube-system\u003c/strong\u003e. Every \u003cem\u003ePod\u003c/em\u003e in the cluster is automatically configured to where this service is. The relevant \u003cem\u003ePods\u003c/em\u003e are managed by a \u003cem\u003eDeployment\u003c/em\u003e called \u003cstrong\u003ecoredns\u003c/strong\u003e and frontend by a \u003cem\u003eService\u003c/em\u003e called \u003cstrong\u003ekube-dns\u003c/strong\u003e.\u003c/p\u003e\n    \u003cp\u003eFor illustration\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-angelscript\"\u003ekubectl \u003cspan class=\"hljs-keyword\"\u003eget\u003c/span\u003e pods --\u003cspan class=\"hljs-keyword\"\u003enamespace\u003c/span\u003e \u003cspan class=\"hljs-symbol\"\u003ekube\u003c/span\u003e-\u003cspan class=\"hljs-symbol\"\u003esystem\u003c/span\u003e --\u003cspan class=\"hljs-symbol\"\u003eselector\u003c/span\u003e \u003cspan class=\"hljs-symbol\"\u003ek8s\u003c/span\u003e-\u003cspan class=\"hljs-symbol\"\u003eapp\u003c/span\u003e=\u003cspan class=\"hljs-symbol\"\u003ekube\u003c/span\u003e-\u003cspan class=\"hljs-symbol\"\u003edns\u003c/span\u003e\n\n\u003cspan class=\"hljs-symbol\"\u003eNAME\u003c/span\u003e                       \u003cspan class=\"hljs-symbol\"\u003eREADY\u003c/span\u003e   \u003cspan class=\"hljs-symbol\"\u003eSTATUS\u003c/span\u003e    \u003cspan class=\"hljs-symbol\"\u003eRESTARTS\u003c/span\u003e   \u003cspan class=\"hljs-symbol\"\u003eAGE\u003c/span\u003e\n\u003cspan class=\"hljs-symbol\"\u003ecoredns\u003c/span\u003e-\u003cspan class=\"hljs-symbol\"\u003e6d4b75cb6d\u003c/span\u003e-\u003cspan class=\"hljs-symbol\"\u003e4lpv9\u003c/span\u003e   \u003cspan class=\"hljs-symbol\"\u003e1\u003c/span\u003e/\u003cspan class=\"hljs-symbol\"\u003e1\u003c/span\u003e     \u003cspan class=\"hljs-symbol\"\u003eRunning\u003c/span\u003e   \u003cspan class=\"hljs-symbol\"\u003e0\u003c/span\u003e          \u003cspan class=\"hljs-symbol\"\u003e139m\u003c/span\u003e\n\u003cspan class=\"hljs-symbol\"\u003ecoredns\u003c/span\u003e-\u003cspan class=\"hljs-symbol\"\u003e6d4b75cb6d\u003c/span\u003e-\u003cspan class=\"hljs-symbol\"\u003evmkfz\u003c/span\u003e   \u003cspan class=\"hljs-symbol\"\u003e1\u003c/span\u003e/\u003cspan class=\"hljs-symbol\"\u003e1\u003c/span\u003e     \u003cspan class=\"hljs-symbol\"\u003eRunning\u003c/span\u003e   \u003cspan class=\"hljs-symbol\"\u003e0\u003c/span\u003e          \u003cspan class=\"hljs-symbol\"\u003e139m\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eWe specify a \u003cem\u003eService\u003c/em\u003e DNS using it's name (in the metadata)\u003c/p\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"}},{"id":"kubernetes/services","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/services.md","metadata":{"title":"Kubernetes Services","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Services \n\n_Service_ provides reliable access to _Pods_.\n\nMain _Service_ concepts\n\n- _Services_ are REST objects in the API that we define in a manifest file or post to the API server.\n- Every service gets it's own __stable IP address__, it's own __stable DNS name__ and it's own __stable port__.\n- _Services_ use __labels__ and __selectors__ to dynamically select the _Pods_ they send traffic to.\n\n_Services_ get a list of healthy pods that match the relevant selctors using a Kubernetes object called an _Endpoint_. Kubernetes is continuously monitoring the state of the _Pods_ and updates the relevant _Endpoints'_ lists.\n\n```bash\n              +----------------+     +------------+     +--------------------------+\n{request} --\u003e | DNS resolution | --\u003e | Service IP | --\u003e | Pod in the Endpoint List |\n              +----------------+     +------------+     +--------------------------+\n```\n\nKubernetes native applications can query the API and directly find the _Service_ IP, bypassing DNS resolution.\n\n","html":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003ch1\u003eServices\u003c/h1\u003e\n    \u003cp\u003e\u003cem\u003eService\u003c/em\u003e provides reliable access to \u003cem\u003ePods\u003c/em\u003e.\u003c/p\u003e\n    \u003cp\u003eMain \u003cem\u003eService\u003c/em\u003e concepts\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003e\u003cem\u003eServices\u003c/em\u003e are REST objects in the API that we define in a manifest file or post to the API server.\u003c/li\u003e\n      \u003cli\u003eEvery service gets it's own \u003cstrong\u003estable IP address\u003c/strong\u003e, it's own \u003cstrong\u003estable DNS name\u003c/strong\u003e and it's own \u003cstrong\u003estable port\u003c/strong\u003e.\u003c/li\u003e\n      \u003cli\u003e\u003cem\u003eServices\u003c/em\u003e use \u003cstrong\u003elabels\u003c/strong\u003e and \u003cstrong\u003eselectors\u003c/strong\u003e to dynamically select the \u003cem\u003ePods\u003c/em\u003e they send traffic to.\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003cp\u003e\u003cem\u003eServices\u003c/em\u003e get a list of healthy pods that match the relevant selctors using a Kubernetes object called an \u003cem\u003eEndpoint\u003c/em\u003e. Kubernetes is continuously monitoring the state of the \u003cem\u003ePods\u003c/em\u003e and updates the relevant \u003cem\u003eEndpoints'\u003c/em\u003e lists.\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e              +----------------+     +------------+     +--------------------------+\n{request} --\u003e | DNS resolution | --\u003e | Service IP | --\u003e | Pod \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e the Endpoint List |\n              +----------------+     +------------+     +--------------------------+\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eKubernetes native applications can query the API and directly find the \u003cem\u003eService\u003c/em\u003e IP, bypassing DNS resolution.\u003c/p\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"}},{"id":"kubernetes/simple-on-prem-cluster","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/simple-on-prem-cluster.md","metadata":{"title":"Simple on-prem Kuberenetes cluster","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n# Kubes\n\nDeploy a kubernetes cluster.\n\nWe will setup a simple kubernetes cluster will describe the concepts and process.\n\nThe OS on all nodes is debian bullseye - I specifically executing this using vagrant's box ```debian/bullseye64```.\n\nTo document the steps we will provide bash script snippets for now. But, the goal is to provide configuration files content for something like ansible or chef.\n\n## Container runtime\n\nKubernetes is an orchestration infrastructure and does not provide any containerization - It relies on a different containarization platform, a.k.a the [Container Runtime](https://kubernetes.io/docs/setup/production-environment/container-runtimes/).\n\nWe will use [docker](https://www.docker.com/). Let's install it by following the documentation [Here](https://docs.docker.com/engine/install/debian/).\n\n```\nsudo apt-get remove docker docker-engine docker.io containerd runc\n\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg lsb-release\n\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io\n```\n\nAnother thing to do is docker to utilize systemd for cgroup management (You can read more about it in the container runtimes documentation). To apply this setting we need to edit docker's configuration. There are multiple to do so, for example - edit systemd's service that initiates docker. Another approach is to edit docker's global configuration file which is at ```/etc/docker/daemon.json```. Hence, edit (create if missing) the mentioned file and add\n\n```json\n{\n    ... other configurations\n    \"exec-opts\": [\"native.cgroupdriver=systemd\", ... more exec opts if exists]\n}\n```\n\nOnce done, reboot docker by running ```sudo systemctl restart docker```\n\n## Kube Components\n\nWe will not rely on the package manager to install the components.\n\nDefine the relevant variables\n\n\u003e Note that the cni directory does not include the version! Later we will install a network plugin, it'll be in the same directory\n\n```\nARCH=\"amd64\"\nCNI_VERSION=\"v0.8.2\"\nCNI_DIR=\"/opt/cni/bin\"\nCRICTL_VERSION=\"v1.23.0\"\nCRICTL_DIR=\"/opt/cri/$CRICTL_VERSION/bin\"\nKUBERNETES_VERSION=\"v1.23.3\"\nKUBERNETES_DIR=\"/opt/kubernetes/$KUBERNETES_VERSION\"\n\n# Install [CNI](https://www.cni.dev/)\n\nsudo mkdir -p $CNI_DIR\ncurl -L \"https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz\" | sudo tar -C $CNI_DIR -xz\n\n# Install [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)\n\nsudo mkdir -p $CRICTL_DIR\ncurl -L \"https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz\" | sudo tar -C $CRICTL_DIR -xz\n\n# Install Kube components\n\nsudo mkdir -p $KUBERNETES_DIR\ncd $KUBERNETES_DIR\nfor component in kubeadm kubectl kubelet; do\n  sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/$KUBERNETES_VERSION/bin/linux/$ARCH/$component\n  sudo chmod +x $component\ndone\n\n# and services\n\nRELEASE_VERSION=\"v0.4.0\"\ncurl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\" | sed \"s:/usr/bin:${KUBERNETES_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service\nsudo mkdir -p /etc/systemd/system/kubelet.service.d\ncurl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\" | sed \"s:/usr/bin:${KUBERNETES_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n```\n\nenable, and start kubelet\n\n```\nsudo systemctl enable --now kubelet\n```\n\n## Initialization\n\nInstall prerequesites for kubeadm\n\n```\nsudo apt-get update \nsudo apt install ethtool socat conntrack\n```\n\nCreate an update alternative\n\n```\nsudo update-alternatives --install /usr/bin/kubeadm kubeadm $KUBERNETES_DIR/kubeadm 100\nsudo update-alternatives --install /usr/bin/kubelet kubelet $KUBERNETES_DIR/kubelet 100\nsudo update-alternatives --install /usr/bin/kubectl kubectl $KUBERNETES_DIR/kubectl 100\n```\n\nRun @controlplane\n\n\u003e TODO: load balancer, hostnames\n\nInitialize configuration such that the network is 10.10.0.0/16\n\n```\nsudo kubeadm init --pod-network-cidr 10.10.0.0/16 --apiserver-advertise-address {ip}\n```\n\nFor documentation, you should see something like\n\n```\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.121.210:6443 --token clns4a.b29f6anjipygy0e2 \\\n\t--discovery-token-ca-cert-hash sha256:833f599cc9ab27eb5010c499e9c77e8e3263fb991d8e9e78ef187ba97e1efb59\n```\n\nDo as it says, run\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\nWe will use [Weave Net](https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/) as a network plugin\n\n```\nkubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"\n```\n","html":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003ch1\u003eKubes\u003c/h1\u003e\n    \u003cp\u003eDeploy a kubernetes cluster.\u003c/p\u003e\n    \u003cp\u003eWe will setup a simple kubernetes cluster will describe the concepts and process.\u003c/p\u003e\n    \u003cp\u003eThe OS on all nodes is debian bullseye - I specifically executing this using vagrant's box \u003ccode\u003edebian/bullseye64\u003c/code\u003e.\u003c/p\u003e\n    \u003cp\u003eTo document the steps we will provide bash script snippets for now. But, the goal is to provide configuration files content for something like ansible or chef.\u003c/p\u003e\n    \u003ch2\u003eContainer runtime\u003c/h2\u003e\n    \u003cp\u003eKubernetes is an orchestration infrastructure and does not provide any containerization - It relies on a different containarization platform, a.k.a the \u003ca href=\"https://kubernetes.io/docs/setup/production-environment/container-runtimes/\"\u003eContainer Runtime\u003c/a\u003e.\u003c/p\u003e\n    \u003cp\u003eWe will use \u003ca href=\"https://www.docker.com/\"\u003edocker\u003c/a\u003e. Let's install it by following the documentation \u003ca href=\"https://docs.docker.com/engine/install/debian/\"\u003eHere\u003c/a\u003e.\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-basic\"\u003esudo apt-\u003cspan class=\"hljs-keyword\"\u003eget\u003c/span\u003e \u003cspan class=\"hljs-comment\"\u003eremove docker docker-engine docker.io containerd runc\u003c/span\u003e\n\nsudo apt-\u003cspan class=\"hljs-keyword\"\u003eget\u003c/span\u003e update\nsudo apt-\u003cspan class=\"hljs-keyword\"\u003eget\u003c/span\u003e install ca-certificates curl gnupg lsb-release\n\ncurl -fsSL https://download.docker.\u003cspan class=\"hljs-keyword\"\u003ecom\u003c/span\u003e/linux/debian/gpg | sudo gpg --dearmor -o /\u003cspan class=\"hljs-keyword\"\u003eusr\u003c/span\u003e/share/keyrings/docker-archive-keyring.gpg\n\necho \\\n  \u003cspan class=\"hljs-string\"\u003e\"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\"\u003c/span\u003e | sudo tee /etc/apt/sources.\u003cspan class=\"hljs-keyword\"\u003elist\u003c/span\u003e.d/docker.\u003cspan class=\"hljs-keyword\"\u003elist\u003c/span\u003e \u003e /dev/null\n\nsudo apt-\u003cspan class=\"hljs-keyword\"\u003eget\u003c/span\u003e update\nsudo apt-\u003cspan class=\"hljs-keyword\"\u003eget\u003c/span\u003e install docker-ce docker-ce-cli containerd.io\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eAnother thing to do is docker to utilize systemd for cgroup management (You can read more about it in the container runtimes documentation). To apply this setting we need to edit docker's configuration. There are multiple to do so, for example - edit systemd's service that initiates docker. Another approach is to edit docker's global configuration file which is at \u003ccode\u003e/etc/docker/daemon.json\u003c/code\u003e. Hence, edit (create if missing) the mentioned file and add\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-json\"\u003e\u003cspan class=\"hljs-punctuation\"\u003e{\u003c/span\u003e\n    ... other configurations\n    \u003cspan class=\"hljs-attr\"\u003e\"exec-opts\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"hljs-punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"hljs-string\"\u003e\"native.cgroupdriver=systemd\"\u003c/span\u003e\u003cspan class=\"hljs-punctuation\"\u003e,\u003c/span\u003e ... more exec opts if exists\u003cspan class=\"hljs-punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"hljs-punctuation\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eOnce done, reboot docker by running \u003ccode\u003esudo systemctl restart docker\u003c/code\u003e\u003c/p\u003e\n    \u003ch2\u003eKube Components\u003c/h2\u003e\n    \u003cp\u003eWe will not rely on the package manager to install the components.\u003c/p\u003e\n    \u003cp\u003eDefine the relevant variables\u003c/p\u003e\n    \u003cblockquote\u003e\n      \u003cp\u003eNote that the cni directory does not include the version! Later we will install a network plugin, it'll be in the same directory\u003c/p\u003e\n    \u003c/blockquote\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003eARCH=\u003cspan class=\"hljs-string\"\u003e\"amd64\"\u003c/span\u003e\nCNI_VERSION=\u003cspan class=\"hljs-string\"\u003e\"v0.8.2\"\u003c/span\u003e\nCNI_DIR=\u003cspan class=\"hljs-string\"\u003e\"/opt/cni/bin\"\u003c/span\u003e\nCRICTL_VERSION=\u003cspan class=\"hljs-string\"\u003e\"v1.23.0\"\u003c/span\u003e\nCRICTL_DIR=\u003cspan class=\"hljs-string\"\u003e\"/opt/cri/\u003cspan class=\"hljs-variable\"\u003e$CRICTL_VERSION\u003c/span\u003e/bin\"\u003c/span\u003e\nKUBERNETES_VERSION=\u003cspan class=\"hljs-string\"\u003e\"v1.23.3\"\u003c/span\u003e\nKUBERNETES_DIR=\u003cspan class=\"hljs-string\"\u003e\"/opt/kubernetes/\u003cspan class=\"hljs-variable\"\u003e$KUBERNETES_VERSION\u003c/span\u003e\"\u003c/span\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e# Install [CNI](https://www.cni.dev/)\u003c/span\u003e\n\nsudo \u003cspan class=\"hljs-built_in\"\u003emkdir\u003c/span\u003e -p \u003cspan class=\"hljs-variable\"\u003e$CNI_DIR\u003c/span\u003e\ncurl -L \u003cspan class=\"hljs-string\"\u003e\"https://github.com/containernetworking/plugins/releases/download/\u003cspan class=\"hljs-variable\"\u003e${CNI_VERSION}\u003c/span\u003e/cni-plugins-linux-\u003cspan class=\"hljs-variable\"\u003e${ARCH}\u003c/span\u003e-\u003cspan class=\"hljs-variable\"\u003e${CNI_VERSION}\u003c/span\u003e.tgz\"\u003c/span\u003e | sudo tar -C \u003cspan class=\"hljs-variable\"\u003e$CNI_DIR\u003c/span\u003e -xz\n\n\u003cspan class=\"hljs-comment\"\u003e# Install [CRI](https://kubernetes.io/docs/concepts/architecture/cri/)\u003c/span\u003e\n\nsudo \u003cspan class=\"hljs-built_in\"\u003emkdir\u003c/span\u003e -p \u003cspan class=\"hljs-variable\"\u003e$CRICTL_DIR\u003c/span\u003e\ncurl -L \u003cspan class=\"hljs-string\"\u003e\"https://github.com/kubernetes-sigs/cri-tools/releases/download/\u003cspan class=\"hljs-variable\"\u003e${CRICTL_VERSION}\u003c/span\u003e/crictl-\u003cspan class=\"hljs-variable\"\u003e${CRICTL_VERSION}\u003c/span\u003e-linux-\u003cspan class=\"hljs-variable\"\u003e${ARCH}\u003c/span\u003e.tar.gz\"\u003c/span\u003e | sudo tar -C \u003cspan class=\"hljs-variable\"\u003e$CRICTL_DIR\u003c/span\u003e -xz\n\n\u003cspan class=\"hljs-comment\"\u003e# Install Kube components\u003c/span\u003e\n\nsudo \u003cspan class=\"hljs-built_in\"\u003emkdir\u003c/span\u003e -p \u003cspan class=\"hljs-variable\"\u003e$KUBERNETES_DIR\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003ecd\u003c/span\u003e \u003cspan class=\"hljs-variable\"\u003e$KUBERNETES_DIR\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e component \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e kubeadm kubectl kubelet; \u003cspan class=\"hljs-keyword\"\u003edo\u003c/span\u003e\n  sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/\u003cspan class=\"hljs-variable\"\u003e$KUBERNETES_VERSION\u003c/span\u003e/bin/linux/\u003cspan class=\"hljs-variable\"\u003e$ARCH\u003c/span\u003e/\u003cspan class=\"hljs-variable\"\u003e$component\u003c/span\u003e\n  sudo \u003cspan class=\"hljs-built_in\"\u003echmod\u003c/span\u003e +x \u003cspan class=\"hljs-variable\"\u003e$component\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edone\u003c/span\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e# and services\u003c/span\u003e\n\nRELEASE_VERSION=\u003cspan class=\"hljs-string\"\u003e\"v0.4.0\"\u003c/span\u003e\ncurl -sSL \u003cspan class=\"hljs-string\"\u003e\"https://raw.githubusercontent.com/kubernetes/release/\u003cspan class=\"hljs-variable\"\u003e${RELEASE_VERSION}\u003c/span\u003e/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\"\u003c/span\u003e | sed \u003cspan class=\"hljs-string\"\u003e\"s:/usr/bin:\u003cspan class=\"hljs-variable\"\u003e${KUBERNETES_DIR}\u003c/span\u003e:g\"\u003c/span\u003e | sudo \u003cspan class=\"hljs-built_in\"\u003etee\u003c/span\u003e /etc/systemd/system/kubelet.service\nsudo \u003cspan class=\"hljs-built_in\"\u003emkdir\u003c/span\u003e -p /etc/systemd/system/kubelet.service.d\ncurl -sSL \u003cspan class=\"hljs-string\"\u003e\"https://raw.githubusercontent.com/kubernetes/release/\u003cspan class=\"hljs-variable\"\u003e${RELEASE_VERSION}\u003c/span\u003e/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\"\u003c/span\u003e | sed \u003cspan class=\"hljs-string\"\u003e\"s:/usr/bin:\u003cspan class=\"hljs-variable\"\u003e${KUBERNETES_DIR}\u003c/span\u003e:g\"\u003c/span\u003e | sudo \u003cspan class=\"hljs-built_in\"\u003etee\u003c/span\u003e /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eenable, and start kubelet\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-pgsql\"\u003esudo systemctl \u003cspan class=\"hljs-keyword\"\u003eenable\u003c/span\u003e \u003cspan class=\"hljs-comment\"\u003e--now kubelet\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n    \u003ch2\u003eInitialization\u003c/h2\u003e\n    \u003cp\u003eInstall prerequesites for kubeadm\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-properties\"\u003e\u003cspan class=\"hljs-attr\"\u003esudo\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eapt-get update \u003c/span\u003e\n\u003cspan class=\"hljs-attr\"\u003esudo\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003eapt install ethtool socat conntrack\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eCreate an update alternative\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-awk\"\u003esudo update-alternatives --install \u003cspan class=\"hljs-regexp\"\u003e/usr/\u003c/span\u003ebin\u003cspan class=\"hljs-regexp\"\u003e/kubeadm kubeadm $KUBERNETES_DIR/\u003c/span\u003ekubeadm \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e\nsudo update-alternatives --install \u003cspan class=\"hljs-regexp\"\u003e/usr/\u003c/span\u003ebin\u003cspan class=\"hljs-regexp\"\u003e/kubelet kubelet $KUBERNETES_DIR/\u003c/span\u003ekubelet \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e\nsudo update-alternatives --install \u003cspan class=\"hljs-regexp\"\u003e/usr/\u003c/span\u003ebin\u003cspan class=\"hljs-regexp\"\u003e/kubectl kubectl $KUBERNETES_DIR/\u003c/span\u003ekubectl \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eRun @controlplane\u003c/p\u003e\n    \u003cblockquote\u003e\n      \u003cp\u003eTODO: load balancer, hostnames\u003c/p\u003e\n    \u003c/blockquote\u003e\n    \u003cp\u003eInitialize configuration such that the network is 10.10.0.0/16\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-apache\"\u003e\u003cspan class=\"hljs-attribute\"\u003esudo\u003c/span\u003e kubeadm init --pod-network-cidr \u003cspan class=\"hljs-number\"\u003e10.10.0.0\u003c/span\u003e/\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e --apiserver-advertise-address {ip}\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eFor documentation, you should see something like\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-pgsql\"\u003eYour Kubernetes control-plane has initialized successfully!\n\n\u003cspan class=\"hljs-keyword\"\u003eTo\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003estart\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eusing\u003c/span\u003e your \u003cspan class=\"hljs-keyword\"\u003ecluster\u003c/span\u003e, you need \u003cspan class=\"hljs-keyword\"\u003eto\u003c/span\u003e run the \u003cspan class=\"hljs-keyword\"\u003efollowing\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e a regular \u003cspan class=\"hljs-keyword\"\u003euser\u003c/span\u003e:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/\u003cspan class=\"hljs-keyword\"\u003eadmin\u003c/span\u003e.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e you are the root \u003cspan class=\"hljs-keyword\"\u003euser\u003c/span\u003e, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/\u003cspan class=\"hljs-keyword\"\u003eadmin\u003c/span\u003e.conf\n\nYou should now deploy a pod network \u003cspan class=\"hljs-keyword\"\u003eto\u003c/span\u003e the \u003cspan class=\"hljs-keyword\"\u003ecluster\u003c/span\u003e.\nRun \"kubectl apply -f [podnetwork].yaml\" \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e one \u003cspan class=\"hljs-keyword\"\u003eof\u003c/span\u003e the \u003cspan class=\"hljs-keyword\"\u003eoptions\u003c/span\u003e listed at:\n  https://kubernetes.io/docs/concepts/\u003cspan class=\"hljs-keyword\"\u003ecluster\u003c/span\u003e-administration/addons/\n\n\u003cspan class=\"hljs-keyword\"\u003eThen\u003c/span\u003e you can \u003cspan class=\"hljs-keyword\"\u003ejoin\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eany\u003c/span\u003e number \u003cspan class=\"hljs-keyword\"\u003eof\u003c/span\u003e worker nodes \u003cspan class=\"hljs-keyword\"\u003eby\u003c/span\u003e running the \u003cspan class=\"hljs-keyword\"\u003efollowing\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eon\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eeach\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e root:\n\nkubeadm \u003cspan class=\"hljs-keyword\"\u003ejoin\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e192.168\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.121\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.210\u003c/span\u003e:\u003cspan class=\"hljs-number\"\u003e6443\u003c/span\u003e \u003cspan class=\"hljs-comment\"\u003e--token clns4a.b29f6anjipygy0e2 \\\u003c/span\u003e\n\t\u003cspan class=\"hljs-comment\"\u003e--discovery-token-ca-cert-hash sha256:833f599cc9ab27eb5010c499e9c77e8e3263fb991d8e9e78ef187ba97e1efb59\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eDo as it says, run\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e\u003cspan class=\"hljs-built_in\"\u003emkdir\u003c/span\u003e -p \u003cspan class=\"hljs-variable\"\u003e$HOME\u003c/span\u003e/.kube\nsudo \u003cspan class=\"hljs-built_in\"\u003ecp\u003c/span\u003e -i /etc/kubernetes/admin.conf \u003cspan class=\"hljs-variable\"\u003e$HOME\u003c/span\u003e/.kube/config\nsudo \u003cspan class=\"hljs-built_in\"\u003echown\u003c/span\u003e $(\u003cspan class=\"hljs-built_in\"\u003eid\u003c/span\u003e -u):$(\u003cspan class=\"hljs-built_in\"\u003eid\u003c/span\u003e -g) \u003cspan class=\"hljs-variable\"\u003e$HOME\u003c/span\u003e/.kube/config\n\u003c/code\u003e\u003c/pre\u003e\n    \u003cp\u003eWe will use \u003ca href=\"https://kubernetes.io/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/\"\u003eWeave Net\u003c/a\u003e as a network plugin\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-powershell\"\u003ekubectl apply \u003cspan class=\"hljs-operator\"\u003e-f\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"https://cloud.weave.works/k8s/net?k8s-version=\u003cspan class=\"hljs-variable\"\u003e$\u003c/span\u003e(kubectl version | base64 | tr -d '\\n')\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"}},{"id":"kubernetes/storage","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/storage.md","metadata":{"title":"Storage","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\nKubernetes abstracts the storage through a __plugin layer__. The plugin layer is the interface that connects external storage with Kubernetes. The layer can mediate between any kind of storage, be it file based, bloc of object based, on-prem or cloud.\n\nMost plugins are based on the __Container Storage Interface (CSI)__ which is an open standard.\n\n\u003e TBD\n","html":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003cp\u003eKubernetes abstracts the storage through a \u003cstrong\u003eplugin layer\u003c/strong\u003e. The plugin layer is the interface that connects external storage with Kubernetes. The layer can mediate between any kind of storage, be it file based, bloc of object based, on-prem or cloud.\u003c/p\u003e\n    \u003cp\u003eMost plugins are based on the \u003cstrong\u003eContainer Storage Interface (CSI)\u003c/strong\u003e which is an open standard.\u003c/p\u003e\n    \u003cblockquote\u003e\n      \u003cp\u003eTBD\u003c/p\u003e\n    \u003c/blockquote\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"}},{"id":"kubernetes/technical-overview","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/kubernetes/technical-overview.md","metadata":{"title":"Kubernetes technical overview","description":null,"permalink":null,"priority":0,"tags":["Kubernetes"],"categories":["Kubernetes"]},"content":{"raw":"\n## Application packaging\n\nAn application should be\n\n1. Packaged as a container\n1. Wrapped in a _Pod_\n1. Deployed via a declerative manifest file\n\n## The declerative model \n\nAccording to the _declerative model_, we only declare about how we want the application to look like. It is Kubernetes' jpb to make sure the cluster behaves as intended.\n\n_Manifests_ simple YAML files and they tell Kubernetes how the application should look like - the _desired state_.\n\n_Controllers_ are constantly running and monitor the application's state, reconciling and difference betweeen the _observerd state_ and the _desired state_.\n\n## Pods\n\nIn Kubernetes, _Pods_ are the atomic unit of scheduling. Kubernetes demands that every container runs inside a pod.\n\nA simple model is to run a sigle container in every pod. \n\nEffectively, a _Pod_ is a construct for running one or more containers.\n\nPods are the most basic unit of scaling. We scale applications by adding or removing pods (not containers).\n\nPods are deployed atomiclly. A pod is ready only when all containers are up and running. A single pod executes on a single Node.\n\nWhen a pod dies, a new one takes it's place. The new pod is a different instance with the same semantics, it has different id, ip etc..\n\nPods are immutable. If we want to change a pod's configuration, we must create a new pod to take it's place.\n\n### Pod theory\n\nThere are 3 main reasons for Pods to exist\n\n1. Pods augment containers 1. Pods assist in scheduling\n1. Pods enable resource sharing\n\nThe augmentation is done in the following ways\n\n- Labels / annotations\n- Restart policies\n- Probes (startup, readiness, liveness etc...)\n- Affinity / anti-affinity rules (Affinities are related to specifying how specific pods behave with other pods)\n- Termination control\n- Security policies\n- Resource requests and limits (min/max values on CPU, memory and I/O)\n\nPods have __Labels__ which lets us group Pods and associate them with other objects. \n\nRegarding resource sharing, Pods provide _shared execution environment_ for one or more containers. It includes\n\n- Filesystem\n- Network stack (IP address, routing, ports)\n- Memory\n- Volumes\n\nPods can be deployed either directly via a Pod manifest or indirectly via a controller. Pods deployed directly are called _static pods_.\n\n## Deployments\n\nA _Deployment_ is a higher-level controller. Usually we will deploy pods indirectly via a deployment.\n\nThe deployment controller monitors the state of a wrapped pod providing extra features such as self-healing, scaling, zero-downtime rollouts and versioned rollbacks.\n\n## Services\n\nA _Service_ is a Kubernetes contstruct which provides reliable networking for a set of pods.\n\nAs we know, pods are immutable and modifications due to auto scaling, rollbacks etc... result in replacements of pods - and the effective IPs.\n\n_Services_ provide reliable names and IPs and provide load balancing capabilities over a set of pods.\n\n## Examples of controllers\n\n- Deployments\n- DaemonSets\n- StatefulSets\n\n## Generall usefull commands\n\nList all possible Pod attributes\n\n    kubectl explain pods --recursive\n\n## Multi container patterns\n\nKubernetes offers several well-defined multi-container Pod patterns\n\n### Sidecar pattern\n\nThis pattern has a _main_ application container and a _sidecar_ container. The _sidecar's_ job is to augment and perform secondary tasks for the _main_ application container.\n\n### Adapter pattern\n\nThis pattern is a specific variation of the _sidecar pattern_ where the _sidecar_ container takes non-standardized output from the _main_ container and standardize it as required by an external system.\n\n### Ambassador pattern\n\nThis is another variation of the _sidecar pattern_ where the _sidecar_ brokers connectivity to an external system.\n\n### Init pattern\n\nThis pattern has an _init_ container that's gauranteed to start and complete before your _main_ application container. It is also gauranteed to run exactly once!\n","html":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003ch2\u003eApplication packaging\u003c/h2\u003e\n    \u003cp\u003eAn application should be\u003c/p\u003e\n    \u003col\u003e\n      \u003cli\u003ePackaged as a container\u003c/li\u003e\n      \u003cli\u003eWrapped in a \u003cem\u003ePod\u003c/em\u003e\u003c/li\u003e\n      \u003cli\u003eDeployed via a declerative manifest file\u003c/li\u003e\n    \u003c/ol\u003e\n    \u003ch2\u003eThe declerative model\u003c/h2\u003e\n    \u003cp\u003eAccording to the \u003cem\u003edeclerative model\u003c/em\u003e, we only declare about how we want the application to look like. It is Kubernetes' jpb to make sure the cluster behaves as intended.\u003c/p\u003e\n    \u003cp\u003e\u003cem\u003eManifests\u003c/em\u003e simple YAML files and they tell Kubernetes how the application should look like - the \u003cem\u003edesired state\u003c/em\u003e.\u003c/p\u003e\n    \u003cp\u003e\u003cem\u003eControllers\u003c/em\u003e are constantly running and monitor the application's state, reconciling and difference betweeen the \u003cem\u003eobserverd state\u003c/em\u003e and the \u003cem\u003edesired state\u003c/em\u003e.\u003c/p\u003e\n    \u003ch2\u003ePods\u003c/h2\u003e\n    \u003cp\u003eIn Kubernetes, \u003cem\u003ePods\u003c/em\u003e are the atomic unit of scheduling. Kubernetes demands that every container runs inside a pod.\u003c/p\u003e\n    \u003cp\u003eA simple model is to run a sigle container in every pod.\u003c/p\u003e\n    \u003cp\u003eEffectively, a \u003cem\u003ePod\u003c/em\u003e is a construct for running one or more containers.\u003c/p\u003e\n    \u003cp\u003ePods are the most basic unit of scaling. We scale applications by adding or removing pods (not containers).\u003c/p\u003e\n    \u003cp\u003ePods are deployed atomiclly. A pod is ready only when all containers are up and running. A single pod executes on a single Node.\u003c/p\u003e\n    \u003cp\u003eWhen a pod dies, a new one takes it's place. The new pod is a different instance with the same semantics, it has different id, ip etc..\u003c/p\u003e\n    \u003cp\u003ePods are immutable. If we want to change a pod's configuration, we must create a new pod to take it's place.\u003c/p\u003e\n    \u003ch3\u003ePod theory\u003c/h3\u003e\n    \u003cp\u003eThere are 3 main reasons for Pods to exist\u003c/p\u003e\n    \u003col\u003e\n      \u003cli\u003ePods augment containers 1. Pods assist in scheduling\u003c/li\u003e\n      \u003cli\u003ePods enable resource sharing\u003c/li\u003e\n    \u003c/ol\u003e\n    \u003cp\u003eThe augmentation is done in the following ways\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eLabels / annotations\u003c/li\u003e\n      \u003cli\u003eRestart policies\u003c/li\u003e\n      \u003cli\u003eProbes (startup, readiness, liveness etc...)\u003c/li\u003e\n      \u003cli\u003eAffinity / anti-affinity rules (Affinities are related to specifying how specific pods behave with other pods)\u003c/li\u003e\n      \u003cli\u003eTermination control\u003c/li\u003e\n      \u003cli\u003eSecurity policies\u003c/li\u003e\n      \u003cli\u003eResource requests and limits (min/max values on CPU, memory and I/O)\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003cp\u003ePods have \u003cstrong\u003eLabels\u003c/strong\u003e which lets us group Pods and associate them with other objects.\u003c/p\u003e\n    \u003cp\u003eRegarding resource sharing, Pods provide \u003cem\u003eshared execution environment\u003c/em\u003e for one or more containers. It includes\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eFilesystem\u003c/li\u003e\n      \u003cli\u003eNetwork stack (IP address, routing, ports)\u003c/li\u003e\n      \u003cli\u003eMemory\u003c/li\u003e\n      \u003cli\u003eVolumes\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003cp\u003ePods can be deployed either directly via a Pod manifest or indirectly via a controller. Pods deployed directly are called \u003cem\u003estatic pods\u003c/em\u003e.\u003c/p\u003e\n    \u003ch2\u003eDeployments\u003c/h2\u003e\n    \u003cp\u003eA \u003cem\u003eDeployment\u003c/em\u003e is a higher-level controller. Usually we will deploy pods indirectly via a deployment.\u003c/p\u003e\n    \u003cp\u003eThe deployment controller monitors the state of a wrapped pod providing extra features such as self-healing, scaling, zero-downtime rollouts and versioned rollbacks.\u003c/p\u003e\n    \u003ch2\u003eServices\u003c/h2\u003e\n    \u003cp\u003eA \u003cem\u003eService\u003c/em\u003e is a Kubernetes contstruct which provides reliable networking for a set of pods.\u003c/p\u003e\n    \u003cp\u003eAs we know, pods are immutable and modifications due to auto scaling, rollbacks etc... result in replacements of pods - and the effective IPs.\u003c/p\u003e\n    \u003cp\u003e\u003cem\u003eServices\u003c/em\u003e provide reliable names and IPs and provide load balancing capabilities over a set of pods.\u003c/p\u003e\n    \u003ch2\u003eExamples of controllers\u003c/h2\u003e\n    \u003cul\u003e\n      \u003cli\u003eDeployments\u003c/li\u003e\n      \u003cli\u003eDaemonSets\u003c/li\u003e\n      \u003cli\u003eStatefulSets\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003ch2\u003eGenerall usefull commands\u003c/h2\u003e\n    \u003cp\u003eList all possible Pod attributes\u003c/p\u003e\n    \u003cpre\u003e\u003ccode class=\"hljs language-pgsql\"\u003ekubectl \u003cspan class=\"hljs-keyword\"\u003eexplain\u003c/span\u003e pods \u003cspan class=\"hljs-comment\"\u003e--recursive\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n    \u003ch2\u003eMulti container patterns\u003c/h2\u003e\n    \u003cp\u003eKubernetes offers several well-defined multi-container Pod patterns\u003c/p\u003e\n    \u003ch3\u003eSidecar pattern\u003c/h3\u003e\n    \u003cp\u003eThis pattern has a \u003cem\u003emain\u003c/em\u003e application container and a \u003cem\u003esidecar\u003c/em\u003e container. The \u003cem\u003esidecar's\u003c/em\u003e job is to augment and perform secondary tasks for the \u003cem\u003emain\u003c/em\u003e application container.\u003c/p\u003e\n    \u003ch3\u003eAdapter pattern\u003c/h3\u003e\n    \u003cp\u003eThis pattern is a specific variation of the \u003cem\u003esidecar pattern\u003c/em\u003e where the \u003cem\u003esidecar\u003c/em\u003e container takes non-standardized output from the \u003cem\u003emain\u003c/em\u003e container and standardize it as required by an external system.\u003c/p\u003e\n    \u003ch3\u003eAmbassador pattern\u003c/h3\u003e\n    \u003cp\u003eThis is another variation of the \u003cem\u003esidecar pattern\u003c/em\u003e where the \u003cem\u003esidecar\u003c/em\u003e brokers connectivity to an external system.\u003c/p\u003e\n    \u003ch3\u003eInit pattern\u003c/h3\u003e\n    \u003cp\u003eThis pattern has an \u003cem\u003einit\u003c/em\u003e container that's gauranteed to start and complete before your \u003cem\u003emain\u003c/em\u003e application container. It is also gauranteed to run exactly once!\u003c/p\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"}}]},"__N_SSG":true},"page":"/_tags/[tag]","query":{"tag":"Kubernetes"},"buildId":"wQSJSBKb1V3HQur7R1QQA","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>