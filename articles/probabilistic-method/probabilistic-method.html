<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/4b7777cd1894a606.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1cb3813e458884a4.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-785779ca76fcde28.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-672a444f700a8e5a.js" async="" crossorigin=""></script><script src="/_next/static/chunks/472-7e5eafffd19dca44.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-d355f2bc91b5bf25.js" async="" crossorigin=""></script><script src="/_next/static/chunks/326-dcee1ff54fa4f70c.js" async=""></script><script src="/_next/static/chunks/app/layout-4997615273b5e9f0.js" async=""></script><script src="/_next/static/chunks/d3ac728e-1e5d8b71e3d43fec.js" async=""></script><script src="/_next/static/chunks/app/articles/%5B...slug%5D/page-d876e1e9a9f10cb2.js" async=""></script><title>Article</title><meta name="description" content="Personal site"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="256x256"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body class="__className_e66fe9 Layout_body__oXsmr"><header class="Layout_header__XC_Gv"><div class="NavBar_container__pKdC7"><a class="link" href="/">Home</a><a class="link" href="/categories">Categories</a><a class="link" href="/articles">All</a><a class="link" href="/articles/about">About</a></div></header><main class="Layout_main__luTTh"><div class="article-page_container__5yaZl"><h1>The Probabilistic Method</h1><div class="Taxonomy_container__C2Vdb"><div class="Taxonomy_values__yvK16"><a href="/tags/Probabilistic Method"><div class="Chip_container__q1AW2">Probabilistic Method</div></a><a href="/tags/Probability"><div class="Chip_container__q1AW2">Probability</div></a><a href="/tags/Algorithms"><div class="Chip_container__q1AW2">Algorithms</div></a></div></div><div class="ArticleContent_md__SxPPI"><!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
    <nav class="toc">
      <ol class="toc-level toc-level-1">
        <li class="toc-item toc-item-h1"><a class="toc-link toc-link-h1" href="#introduction">Introduction</a></li>
        <li class="toc-item toc-item-h1"><a class="toc-link toc-link-h1" href="#basic-definitions-and-results">Basic definitions and results</a>
          <ol class="toc-level toc-level-2">
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#union-bound">Union Bound</a></li>
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#conditional-probability">Conditional Probability</a></li>
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#bayes-rule">Bayes rule</a></li>
          </ol>
        </li>
        <li class="toc-item toc-item-h1"><a class="toc-link toc-link-h1" href="#probabilistic-method---union-bound-and-intersection-of-independent-events">Probabilistic method - Union bound and Intersection of independent events</a>
          <ol class="toc-level toc-level-2">
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#examples">Examples</a></li>
          </ol>
        </li>
        <li class="toc-item toc-item-h1"><a class="toc-link toc-link-h1" href="#random-variables">Random Variables</a>
          <ol class="toc-level toc-level-2">
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#expectancy">Expectancy</a></li>
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#variance">Variance</a></li>
            <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#common-distributions">Common Distributions</a></li>
          </ol>
        </li>
      </ol>
    </nav>
    <h1 id="introduction">Introduction</h1>
    <p>In this page we will discuss the probabilistic method which is a powerful tool to prove the existence of a combinatorial object. For a long time we have used conventional approaches for this purpose - Either we provided a proof by contruction or we provided a non-constructive proof. The probabilistic method is a non-constructive method first introduced by <a href="https://en.wikipedia.org/wiki/Paul_Erd%C5%91s">Paul Erdos</a> while he was working on the development of the <a href="https://en.wikipedia.org/wiki/Ramsey_theory">Ramsey Theory</a>.</p>
    <p>In essence, the method shows that the probability that some object with the desired property exist is greater than 0 and therefore one such instance surely exist, otherwise the probability was strictly 0.</p>
    <p>We will use many practical examples and uses of this method which we will link to throughout this page.</p>
    <h1 id="basic-definitions-and-results">Basic definitions and results</h1>
    <p>Before we continue we need to review the definition of probability spaces.</p>
    <p>A <strong>probability space</strong> is a triplet $(\Omega, \Sigma, Pr)$ where</p>
    <ol>
      <li>
        <p>$\Omega$ is a non-empty set known as the <strong>sample space</strong>. It represents all possible outcomes of some experiment.</p>
        <ul>
          <li>We will limit ourselves to a finite sample space.</li>
        </ul>
      </li>
      <li>
        <p>$\Sigma$ is the collection of subsets of $\Omega$ which is closed under the <strong>complement ($x'$)</strong>, <strong>union ($x \cup y$)</strong> and <strong>intersection ($x \cap y$)</strong> operations.</p>
        <ul>
          <li>An element $A \in \Sigma$ is called an <strong>event</strong>.</li>
        </ul>
      </li>
      <li>
        <p>$Pr : \Sigma \rightarrow [0, 1]$ is a function with the following properties:</p>
        <ul>
          <li>$Pr(\Omega) = 1$</li>
          <li>$\forall A, B \in \Sigma ; A \cap B = \phi \implies Pr(A) + Pr(B) = Pr(A \cup B)$</li>
          <li>$\forall \omega \in \Omega ; $ we will denote $Pr(\omega) = Pr(\{\omega\})$</li>
        </ul>
      </li>
    </ol>
    <blockquote>
      <p>Methematically, a probability space is a measure space with the measure function over $\Omega$ where $\Sigma$ is the $\sigma$-algebra over $\Omega$ and $Pr$ is the measure of the space such that $Pr(\Omega) = 1$.</p>
    </blockquote>
    <h2 id="union-bound">Union Bound</h2>
    <p>The measue function is sub-additive with respect to the union operation. Meaning, every two events $A, B$ satisfies $Pr(A \cup B) \leq Pr(A) + Pr(B)$.</p>
    <p>It makes sense, if the two events are not disjointed, the intersection part must be calculated once, not twice as is calculated in $Pr(A) + $Pr(B)$.</p>
    <p>More generally, the <strong>Union Bound</strong> theorem states that for any set of events $\{ A_i \}$ it holds that:</p>
    <p>
      $$
      Pr(\bigcup_i A_i) \leq \sum_i Pr(A_i)
      $$
    </p>
    <h2 id="conditional-probability">Conditional Probability</h2>
    <p>The probability of some event $A$, given that we know that the event $B$ happened is called the <strong>conditional probability of $A$ given $B$</strong> and is notated and given by</p>
    <p>
      $$
      Pr(A | B) = \frac{Pr(A \cap B)}{Pr(B)}
      $$
    </p>
    <p>This definition is intuitive. The probability $A$ happens given $B$ happens is firstly at the intersection between them. Then, we scale this probability of the intersection to limit ourselves to the "world" of $B$ only.</p>
    <p>Another variant of this definition is known as the <strong>product rule</strong>:</p>
    <p>
      $$
      Pr(A \cap B) = Pr(A | B) Pr(B)
      $$
    </p>
    <p>Let's see an example - Consider the experiment of rolling a six-sided die and let $A$ be the event that the number $2$ was thrown and $B$ the event that an even number was thrown. Formally, $A = \{ 2 \}, B = \{2, 4, 6 \}$. It is obvious that $Pr(A) = \frac{1}{6}$ and $Pr(B) = \frac{3}{6} = \frac{1}{2}$. Intuitively, the probability that $A$ given $B$ is $\frac{1}{3}$ since if we know an even number was rolled it means that one of three numbers 2, 4 and 6 were rolled - from those, the probability that 2 was rolled is $\frac{1}{3}$. We can verify the intuition using the formula: $Pr(A | B) = \frac{Pr(A \cap B)}{Pr(B)} = \frac{\frac{1}{6}}{\frac{1}{2}} = \frac{1}{3}$.</p>
    <p>Now, what happens when what we know about $B$ doesn't affect $A$? For example, consider $A$ to be the result of a die roll and $B$ the event that it is Sunday - the result of the roll is not affected by the day of week at all. Such events are called <strong>independent</strong>, let's define it:</p>
    <p>Two events $A$ and $B$ such that $Pr(A | B) = Pr(A)$ are said to be <strong>independent</strong>.</p>
    <p>For two independent events $A$ and $B$ we can see that:</p>
    <p>
      $$
      Pr(A) = Pr(A | B) = \frac{Pr(A \cap B)}{Pr(B)} \implies Pr(A)Pr(B) = Pr(A \cap B)
      $$
    </p>
    <p>We can generalize this and get the important claim.</p>
    <p>For every set of pair-wise independent events $\{ A_i \}$ it holds true that:</p>
    <p>
      $$
      Pr(\bigcap_i A_i) = \prod_i Pr(A_i)
      $$
    </p>
    <h2 id="bayes-rule">Bayes rule</h2>
    <p>Although we won't use it much here, it is important to show a straight-forward result which stems from the definitions of conditional probability.</p>
    <p>Using a bit of algebra, we can get the <strong>very</strong> important rule, <strong>Bayes Rule</strong> which states that we can always invert the conditional causality:</p>
    <p>
      $$
      Pr(A | B) = \frac{Pr(B | A) Pr(A)}{Pr(B)}
      $$
    </p>
    <h1 id="probabilistic-method---union-bound-and-intersection-of-independent-events">Probabilistic method - Union bound and Intersection of independent events</h1>
    <p>Up until now we saw only basic results which we are all familiar with. Although basic, they provide provide the basic and most common tools for the probabilistic method. Usually the way we will use them is as follows.</p>
    <p>Assume we want to bound the probability of some event $A$ which we cannot calculate the probability of directly because it is somewhat complex.</p>
    <p>Represent the $A$ as smaller, usually simpler events $A_i$ such that $A = \bigcup_i A_i$. From the union bound we know that $Pr(A) \leq \sum_ Pr(A_i)$.</p>
    <p>Usually we will now be able to calculate $A_i$ directly. We will break such events even further such that $A_i = \bigcup B_{ij}$ where $\{ B_{ij} \}$ is a set of pair-wise independent events. It is immediately follows by the intersection of independent event rule that $Pr(A_i) = \prod_j Pr(B_{ij})$.</p>
    <p>Finally we can conclude that $Pr(A) \leq \sum_i \prod_j Pr(B_{ij})$.</p>
    <p>Usually, we will see that the probabilities of the smaller events are similar to each other.</p>
    <h2 id="examples">Examples</h2>
    <ul>
      <li><a href="../hypergraph-2coloring">Hypergraph 2 Coloring</a></li>
      <li><a href="../coupons-collector-v1">Coupons Collector 1</a></li>
    </ul>
    <h1 id="random-variables">Random Variables</h1>
    <p>Another basic object in probability theory is the <strong>Random Variable</strong>. A random variable $X$ is a function that assigns a real number for each element in the sample space, $X : \Omega \rightarrow \mathbb{R}$.</p>
    <p>All of the possible inputs and outputs of a random variable is known as it's distribution: ${ (\omega, X(\omega)) | \omega \in \Omega }$.</p>
    <p>Let's think of the experiment of rolling a fair dice. The sample space is $\Omega = { 1, 2, 3, 4, 5, 6 }$.</p>
    <p>Let's define the random variable $X(\omega) = 1 <del>if</del> \omega \leq 2 <del>and</del> 0 <del>otherwise</del>$. Meaning, $X$ is 1 if the outcome is $1$ or $2$, otherwise it's zero. $X$'s distribution is $A = { (1, 1), (2, 1), (3, 0), (4, 0), (5, 0), (6, 0) }$. What is the probability for the event that $X = 1$? Combinatorically, we calculate that $Pr(X = 1) = \frac{|{\omega | X(\omega) = 1 }|}{|A|} = \frac{2}{6} = \frac{1}{3}$. This is rather intuitive, we know that a third of the outcomes are less than or equal to 2.</p>
    <p>Let's define another random variable $Y(\omega) = \omega \cdot 2$. The range of $Y$ is $D = { 2, 4, 6, 8, 10, 12 }$. What is the probability that $Y$ gets the value $4$? Again, combinatorically we see that $Pr(Y=4) = \frac{|{\omega | Y(\omega) = 2}|}{|D|}=\frac{1}{6}$. In fact, that is true for all $d \in D$ that $Pr(Y = d) = \frac{1}{6}$!</p>
    <p>The random variables $X$ and $Y$ exhibit different, yet common distribution patterns. $X$ behaves like a predicate - it get's the value 1 if some condition holds or 0 if it doesn't. Therefore, the probability of ${ X = 1 }$ is the probability of the condition to be true. $Y$ is simple, the probability for it to achieve any value is the same probability - specifically, it is exactly $\frac{1}{|Range(Y)|}$.</p>
    <p>$X$'s distribution is known as the <strong>Bernoulli</strong> distribution with probability $p = \frac{1}{3}$. Usually, the Bernoulli distribution with probability $p$ is notated by $B(p)$. We notate the fact that $X$'s distribution is $B(\frac{1}{3})$ by $X \sim B(\frac{1}{3})$.</p>
    <p>$Y$'s distribution is known as the <strong>Uniform</strong> distribution with $n = 6$. Simlirarly, we notate $Y \sim Uniform(6)$.</p>
    <h2 id="expectancy">Expectancy</h2>
    <p>The <strong>Expectency</strong> of a random variable is the value we would expect the random variable to achieve. For any random variable $V$ we define its expectency by:</p>
    <p>
      $$
      \mathbb{E}(V) := \sum_{v \in Range(V)} vPr(V=v) = \sum_{\omega \in \Omega}Pr(\omega)V(\omega)
      $$
    </p>
    <p>Let's calculate the expectencies of $X$ and $Y$ from the previous section:</p>
    <ul>
      <li>
        $\mathbb{E}(X) = Pr(1)X(1) + Pr(2)X(2) + Pr(3)X(3) + ... + Pr(6)X(6) = \frac{1}{6} \cdot 1+\frac{1}{6} \cdot 1 + \frac{1}{6} \cdot 0 + ... + \frac{1}{6} \cdot 0 =
        \frac{2}{6} = \frac{1}{3}$
        <ul>
          <li>Not coincidently, the expectancy is exactly the probability $p = \frac{1}{3}$</li>
        </ul>
      </li>
      <li>$\mathbb{E}(Y) = \sum_{\omega \in {1, 2, 3, 4, 5, 6}} Pr(\omega)Y(\omega) = \sum_{\omega \in {1, 2, 3, 4, 5, 6}} \frac{1}{6} (\omega \cdot 2) = \frac{\sum_{\omega \in {1, 2, 3, 4, 5, 6}} \omega \cdot 2}{6} = 8$
        <ul>
          <li>Not coincidently, the expectancy is exactly the average of the possible values</li>
        </ul>
      </li>
    </ul>
    <p>The expectancy has an important characteristic, known as the <strong>Linearity of expectation</strong>: For any two random variables $V, U$ and two real numbers $\alpha, \beta$:</p>
    <p>
      $$
      \mathbb{\mathbb{E}(\alpha U + \beta V)} = \alpha \mathbb{E}(U) + \beta \mathbb{E}(V)
      $$
    </p>
    <p>This doesn't seems much but it is. As we know from theoretical math, the less constraints a theorem has the more powerful and robust it is. This is the case for the linearity of expectation - It holds for <strong>any</strong> two random variables, now small print, that's it.</p>
    <h2 id="variance">Variance</h2>
    <p>Observe the two uniform distributions ${ 0, 100 }$ and ${ 49, 51 }$. Both of their expectancies are 50 but they are inherently different with respect to the distance of the values from it. A measurement for how far the values spread within the distribution is known as the <strong>Variance</strong>.</p>
    <p>How will we define the variance then?</p>
    <ul>
      <li>The first idea is to subtract the random variable from it's expectency and take the expectancy of that. i.e., for the random variable $U$ it's variance could have been defined by (but it isn't): $\mathbb{E}(U - \mathbb{E}(U))$. The problem with this definition is that it is analytically hard to work with. When is it negative vs. positive?</li>
      <li>The second idea is to improve upon the previous one by taking the absolute value and measure the distance of the random variable from it's expectancy. i.e. for the random variable $U$ it's variance could be defined by (but it isn't): $\mathbb{E}(|U - \mathbb{E}(U)|)$. The main reason which because it isn't a good definition is because the function of the absolute value is not differentiable at $0$. You may ask how differentiation has anything to do with random variables? Well, recall that random variables are just functions from the probability space. The probability space can also be continuous (we don't use it here though).</li>
    </ul>
    <blockquote>
      <p>As pointed out, we can define probability spaces as continuous spaces. In our case, we say that the random variables are <strong>Discrete</strong> rather than <strong>Continuous</strong>. Roughly the extention to the continous case is straight forward and all we need to do is use integration instead of summation for the respective definitions (which makes the computations harder but the theory itself is not much more complex).</p>
    </blockquote>
    <p>We define the variance of a random variable $U$ to be the expectancy of the squared distance from it's expectancy:</p>
    <p>
      $$
      Var(U) := \mathbb{E}((U - \mathbb{E}(U))^2)
      $$
    </p>
    <p>Let's try to expand upon it a bit:</p>
    <p>
      $$
      Var(U) = \mathbb{E}((U - \mathbb{E}(U))^2) = \mathbb{E}(U^2 -2U\mathbb{E}(U) + \mathbb{E}(U)^2)
      $$
    </p>
    <p>
      By linearity of expectation we get that:
      $$
      Var(U) = \mathbb{E}(U^2) - 2\mathbb{E}(U)\mathbb{E}(\mathbb{E}(U))+\mathbb{E}(U)^2
      $$
    </p>
    <p>
      The expectancy itself is a real number, so the expectancy of an expectancy is itself:
      $$
      Var(U) = \mathbb{E}(U^2) - 2\mathbb{E}(U)^2 + \mathbb{E}(U)^2
      $$
    </p>
    <p>
      And we will get a useful formula for calculating the variance:
      $$
      Var(U) = \mathbb{E}(U^2) - \mathbb{E}(U)^2
      $$
    </p>
    <p>The variance is <strong>not linear</strong>. But we can say something about the variance of sums.</p>
    <p>For <strong>mutually independent</strong> random variables ${ U_i }$ the variance of the sum is the sum of the variances: $Var(\sum U_i) = \sum Var(U_i)$.</p>
    <p>So what about variables that are not necessarily mutually independent? The variance of the sum can be expressed as:</p>
    <p>
      $$
      Var(\sum U_i) = \sum Var(U_i) + \sum_{i \neq j}Cov(U_i, U_j)
      $$
    </p>
    <p>Where $Cov(U, V)$ is the <strong>Covariance</strong> of $U$ and $V$ and it is defined by:</p>
    <p>
      $$
      Cov(U, V) := \mathbb{E}((U - \mathbb{E}(U))(V - \mathbb{E}(V)))
      $$
    </p>
    <blockquote>
      <p>Formula of the variance of the sums can be easily reached by straight forward computations according to the expectancy definition</p>
    </blockquote>
    <p>A formula for calculating the covariance is given by:</p>
    <p>
      $$
      Cov(U, V) = \mathbb{E}(UV) - \mathbb{E}(U)\mathbb{E}(V)
      $$
    </p>
    <blockquote>
      <p>We reach this formula just by expanding the definition</p>
    </blockquote>
    <h2 id="common-distributions">Common Distributions</h2>
    <p>We previously saw 2 different common distributions. Let's cover them more generally.</p>
    <h3 id="bernoulli-distribution">Bernoulli Distribution</h3>
    <p>The <strong>Bernoulli</strong> distribution is notated by $B(p)$. It models a single trial that can either <strong>succeed</strong> with probability $p$ in which case the value of the random variable is 1 or <strong>fail</strong> with probability $1 - p$ in which case the value of the random variable is 0.</p>
    <p>A random variable $X \sim B(p)$ is also called an <strong>Indicator</strong>.</p>
    <h4 id="expectancy-1">Expectancy</h4>
    <p>The expectancy is given by $\mathbb{E}(X) = p$.</p>
    <p><em>Proof</em></p>
    <p>
      $$
      \mathbb{E}(X \sim B(p)) = 1 \cdot Pr(X=1) + 0 \cdot Pr(X=0) = Pr(X = 1) = p
      $$
    </p>
    <h4 id="variance-1">Variance</h4>
    <p>The variance is given by $Var(X) = p(1 - p)$.</p>
    <p><em>Proof</em></p>
    <p>
      $$
      Var(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2 = p - p^2 = p(1 - p)
      $$
    </p>
  </body>
</html>
</div></div></main><footer><div class="Footer_container__Z8cUU"><a href="https://il.linkedin.com/in/tal-glanzman"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="25" width="25" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a><a href="https://github.com/tglanz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="25" width="25" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div></footer><script src="/_next/static/chunks/webpack-785779ca76fcde28.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/4b7777cd1894a606.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L3\"\n"])</script><script>self.__next_f.push([1,"4:HL[\"/_next/static/css/1cb3813e458884a4.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"5:I[3728,[],\"\"]\n7:I[9928,[],\"\"]\n8:I[5420,[\"326\",\"static/chunks/326-dcee1ff54fa4f70c.js\",\"185\",\"static/chunks/app/layout-4997615273b5e9f0.js\"],\"\"]\n9:I[6954,[],\"\"]\na:I[7264,[],\"\"]\nd:I[8326,[\"954\",\"static/chunks/d3ac728e-1e5d8b71e3d43fec.js\",\"326\",\"static/chunks/326-dcee1ff54fa4f70c.js\",\"496\",\"static/chunks/app/articles/%5B...slug%5D/page-d876e1e9a9f10cb2.js\"],\"\"]\ne:T518,"])</script><script>self.__next_f.push([1,"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"])</script><script>self.__next_f.push([1,"3:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/4b7777cd1894a606.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L5\",null,{\"buildId\":\"0DR5VRT5ukJIfOBO2_wNw\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/articles/probabilistic-method/probabilistic-method\",\"initialTree\":[\"\",{\"children\":[\"articles\",{\"children\":[[\"slug\",\"probabilistic-method/probabilistic-method\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"probabilistic-method\\\",\\\"probabilistic-method\\\"]}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialHead\":[false,\"$L6\"],\"globalErrorComponent\":\"$7\",\"children\":[null,[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_e66fe9 Layout_body__oXsmr\",\"children\":[[\"$\",\"header\",null,{\"className\":\"Layout_header__XC_Gv\",\"children\":[\"$\",\"$L8\",null,{}]}],[\"$\",\"main\",null,{\"className\":\"Layout_main__luTTh\",\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"initialChildNode\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"articles\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"initialChildNode\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"articles\",\"children\",[\"slug\",\"probabilistic-method/probabilistic-method\",\"c\"],\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"initialChildNode\":[\"$Lb\",\"$Lc\",null],\"childPropSegment\":\"__PAGE__?{\\\"slug\\\":[\\\"probabilistic-method\\\",\\\"probabilistic-method\\\"]}\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1cb3813e458884a4.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}],\"childPropSegment\":[\"slug\",\"probabilistic-method/probabilistic-method\",\"c\"],\"styles\":null}],\"childPropSegment\":\"articles\",\"styles\":null}]}],[\"$\",\"footer\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"Footer_container__Z8cUU\",\"children\":[[\"$\",\"$Ld\",null,{\"href\":\"https://il.linkedin.com/in/tal-glanzman\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 448 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z\",\"children\":\"$undefined\"}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":25,\"width\":25,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"$Ld\",null,{\"href\":\"https://github.com/tglanz\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 496 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"$e\",\"children\":\"$undefined\"}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":25,\"width\":25,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]]}]}]]}]}],null]}]]\n"])</script><script>self.__next_f.push([1,"f:I[6222,[\"954\",\"static/chunks/d3ac728e-1e5d8b71e3d43fec.js\",\"326\",\"static/chunks/326-dcee1ff54fa4f70c.js\",\"496\",\"static/chunks/app/articles/%5B...slug%5D/page-d876e1e9a9f10cb2.js\"],\"ArticleContent\"]\n10:T3515,"])</script><script>self.__next_f.push([1,"\n# Introduction\n\nIn this page we will discuss the probabilistic method which is a powerful tool to prove the existence of a combinatorial object. For a long time we have used conventional approaches for this purpose - Either we provided a proof by contruction or we provided a non-constructive proof. The probabilistic method is a non-constructive method first introduced by [Paul Erdos](https://en.wikipedia.org/wiki/Paul_Erd%C5%91s) while he was working on the development of the [Ramsey Theory](https://en.wikipedia.org/wiki/Ramsey_theory).\n\nIn essence, the method shows that the probability that some object with the desired property exist is greater than 0 and therefore one such instance surely exist, otherwise the probability was strictly 0. \n\nWe will use many practical examples and uses of this method which we will link to throughout this page.\n\n# Basic definitions and results\n\nBefore we continue we need to review the definition of probability spaces.\n\nA **probability space** is a triplet $(\\Omega, \\Sigma, Pr)$ where\n\n1. $\\Omega$ is a non-empty set known as the **sample space**. It represents all possible outcomes of some experiment.\n    - We will limit ourselves to a finite sample space.\n\n2. $\\Sigma$ is the collection of subsets of $\\Omega$ which is closed under the **complement ($x'$)**, **union ($x \\cup y$)** and **intersection ($x \\cap y$)** operations.\n    - An element $A \\in \\Sigma$ is called an **event**.\n\n3. $Pr : \\Sigma \\rightarrow [0, 1]$ is a function with the following properties:\n    - $Pr(\\Omega) = 1$\n    - $\\forall A, B \\in \\Sigma ; A \\cap B = \\phi \\implies Pr(A) + Pr(B) = Pr(A \\cup B)$\n    - $\\forall \\omega \\in \\Omega ; $  we will denote $Pr(\\omega) = Pr(\\\\{\\omega\\\\})$\n\n\u003e Methematically, a probability space is a measure space with the measure function over $\\Omega$ where $\\Sigma$ is the $\\sigma$-algebra over $\\Omega$ and $Pr$ is the measure of the space such that $Pr(\\Omega) = 1$.\n\n## Union Bound\n\nThe measue function is sub-additive with respect to the union operation. Meaning, every two events $A, B$ satisfies $Pr(A \\cup B) \\leq Pr(A) + Pr(B)$.\n\nIt makes sense, if the two events are not disjointed, the intersection part must be calculated once, not twice as is calculated in $Pr(A) + $Pr(B)$.\n\nMore generally, the **Union Bound** theorem states that for any set of events $\\\\{ A_i \\\\}$ it holds that:\n\n$$\n  Pr(\\bigcup_i A_i) \\leq \\sum_i Pr(A_i)\n$$\n\n## Conditional Probability\n\nThe probability of some event $A$, given that we know that the event $B$ happened is called the **conditional probability of $A$ given $B$** and is notated and given by\n\n$$\n  Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)}\n$$\n\nThis definition is intuitive. The probability $A$ happens given $B$ happens is firstly at the intersection between them. Then, we scale this probability of the intersection to limit ourselves to the \"world\" of $B$ only.\n\nAnother variant of this definition is known as the **product rule**:\n\n$$\n  Pr(A \\cap B) = Pr(A | B) Pr(B)\n$$\n\nLet's see an example - Consider the experiment of rolling a six-sided die and let $A$ be the event that the number $2$ was thrown and $B$ the event that an even number was thrown. Formally, $A = \\\\{ 2 \\\\}, B = \\\\{2, 4, 6 \\\\}$. It is obvious that $Pr(A) = \\frac{1}{6}$ and $Pr(B) = \\frac{3}{6} = \\frac{1}{2}$. Intuitively, the probability that $A$ given $B$ is $\\frac{1}{3}$ since if we know an even number was rolled it means that one of three numbers 2, 4 and 6 were rolled - from those, the probability that 2 was rolled is $\\frac{1}{3}$. We can verify the intuition using the formula: $Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)} = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}$.\n\nNow, what happens when what we know about $B$ doesn't affect $A$? For example, consider $A$ to be the result of a die roll and $B$ the event that it is Sunday - the result of the roll is not affected by the day of week at all. Such events are called **independent**, let's define it:\n\nTwo events $A$ and $B$ such that $Pr(A | B) = Pr(A)$ are said to be **independent**.\n\nFor two independent events $A$ and $B$ we can see that:\n\n$$\n    Pr(A) = Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)} \\implies Pr(A)Pr(B) = Pr(A \\cap B)\n$$\n\nWe can generalize this and get the important claim.\n\nFor every set of pair-wise independent events $\\\\{ A_i \\\\}$ it holds true that:\n\n$$\n   Pr(\\bigcap_i A_i) = \\prod_i Pr(A_i)\n$$\n\n## Bayes rule\n\nAlthough we won't use it much here, it is important to show a straight-forward result which stems from the definitions of conditional probability.\n\nUsing a bit of algebra, we can get the **very** important rule, **Bayes Rule** which states that we can always invert the conditional causality:\n\n$$\n    Pr(A | B) = \\frac{Pr(B | A) Pr(A)}{Pr(B)}\n$$\n\n# Probabilistic method - Union bound and Intersection of independent events\n\nUp until now we saw only basic results which we are all familiar with. Although basic, they provide provide the basic and most common tools for the probabilistic method. Usually the way we will use them is as follows.\n\nAssume we want to bound the probability of some event $A$ which we cannot calculate the probability of directly because it is somewhat complex.\n\nRepresent the $A$ as smaller, usually simpler events $A_i$ such that $A = \\bigcup_i A_i$. From the union bound we know that $Pr(A) \\leq \\sum_ Pr(A_i)$.\n\nUsually we will now be able to calculate $A_i$ directly. We will break such events even further such that $A_i = \\bigcup B_{ij}$ where $\\\\{ B_{ij} \\\\}$ is a set of pair-wise independent events. It is immediately follows by the intersection of independent event rule that $Pr(A_i) = \\prod_j Pr(B_{ij})$.\n\nFinally we can conclude that $Pr(A) \\leq \\sum_i \\prod_j Pr(B_{ij})$.\n\nUsually, we will see that the probabilities of the smaller events are similar to each other.\n\n## Examples\n\n- [Hypergraph 2 Coloring](../hypergraph-2coloring)\n- [Coupons Collector 1](../coupons-collector-v1)\n\n# Random Variables\n\nAnother basic object in probability theory is the **Random Variable**. A random variable $X$ is a function that assigns a real number for each element in the sample space, $X : \\Omega \\rightarrow \\mathbb{R}$.\n\nAll of the possible inputs and outputs of a random variable is known as it's distribution: $\\{ (\\omega, X(\\omega)) | \\omega \\in \\Omega \\}$.\n\nLet's think of the experiment of rolling a fair dice. The sample space is $\\Omega = \\{ 1, 2, 3, 4, 5, 6 \\}$.\n\nLet's define the random variable $X(\\omega) = 1 ~if~ \\omega \\leq 2 ~and~ 0 ~otherwise~$. Meaning, $X$ is 1 if the outcome is $1$ or $2$, otherwise it's zero. $X$'s distribution is $A = \\{ (1, 1), (2, 1), (3, 0), (4, 0), (5, 0), (6, 0) \\}$. What is the probability for the event that $X = 1$? Combinatorically, we calculate that $Pr(X = 1) = \\frac{|\\{\\omega | X(\\omega) = 1 \\}|}{|A|} = \\frac{2}{6} = \\frac{1}{3}$. This is rather intuitive, we know that a third of the outcomes are less than or equal to 2.\n\nLet's define another random variable $Y(\\omega) = \\omega \\cdot 2$. The range of $Y$ is $D = \\{ 2, 4, 6, 8, 10, 12 \\}$. What is the probability that $Y$ gets the value $4$? Again, combinatorically we see that $Pr(Y=4) = \\frac{|\\{\\omega | Y(\\omega) = 2\\}|}{|D|}=\\frac{1}{6}$. In fact, that is true for all $d \\in D$ that $Pr(Y = d) = \\frac{1}{6}$!\n\nThe random variables $X$ and $Y$ exhibit different, yet common distribution patterns. $X$ behaves like a predicate - it get's the value 1 if some condition holds or 0 if it doesn't. Therefore, the probability of $\\{ X = 1 \\}$ is the probability of the condition to be true. $Y$ is simple, the probability for it to achieve any value is the same probability - specifically, it is exactly $\\frac{1}{|Range(Y)|}$.\n\n$X$'s distribution is known as the **Bernoulli** distribution with probability $p = \\frac{1}{3}$. Usually, the Bernoulli distribution with probability $p$ is notated by $B(p)$. We notate the fact that $X$'s distribution is $B(\\frac{1}{3})$ by $X \\sim B(\\frac{1}{3})$.\n\n$Y$'s distribution is known as the **Uniform** distribution with $n = 6$. Simlirarly, we notate $Y \\sim Uniform(6)$.\n\n## Expectancy\n\nThe **Expectency** of a random variable is the value we would expect the random variable to achieve. For any random variable $V$ we define its expectency by:\n\n$$\n  \\mathbb{E}(V) := \\sum_{v \\in Range(V)} vPr(V=v) = \\sum_{\\omega \\in \\Omega}Pr(\\omega)V(\\omega)\n$$\n\nLet's calculate the expectencies of $X$ and $Y$ from the previous section:\n- $\\mathbb{E}(X) = Pr(1)X(1) + Pr(2)X(2) + Pr(3)X(3) + ... + Pr(6)X(6) = \\frac{1}{6} \\cdot 1+\\frac{1}{6} \\cdot 1 + \\frac{1}{6} \\cdot 0 + ... + \\frac{1}{6} \\cdot 0 = \n\\frac{2}{6} = \\frac{1}{3}$\n  - Not coincidently, the expectancy is exactly the probability $p = \\frac{1}{3}$\n- $\\mathbb{E}(Y) = \\sum_{\\omega \\in \\{1, 2, 3, 4, 5, 6\\}} Pr(\\omega)Y(\\omega) = \\sum_{\\omega \\in \\{1, 2, 3, 4, 5, 6\\}} \\frac{1}{6} (\\omega \\cdot 2) = \\frac{\\sum_{\\omega \\in \\{1, 2, 3, 4, 5, 6\\}} \\omega \\cdot 2}{6} = 8$\n  - Not coincidently, the expectancy is exactly the average of the possible values\n\nThe expectancy has an important characteristic, known as the **Linearity of expectation**: For any two random variables $V, U$ and two real numbers $\\alpha, \\beta$:\n\n$$\n  \\mathbb{\\mathbb{E}(\\alpha U + \\beta V)} = \\alpha \\mathbb{E}(U) + \\beta \\mathbb{E}(V)\n$$\n\nThis doesn't seems much but it is. As we know from theoretical math, the less constraints a theorem has the more powerful and robust it is. This is the case for the linearity of expectation - It holds for **any** two random variables, now small print, that's it.\n\n## Variance\n\nObserve the two uniform distributions $\\{ 0, 100 \\}$ and $\\{ 49, 51 \\}$. Both of their expectancies are 50 but they are inherently different with respect to the distance of the values from it. A measurement for how far the values spread within the distribution is known as the **Variance**.\n\nHow will we define the variance then?\n\n- The first idea is to subtract the random variable from it's expectency and take the expectancy of that. i.e., for the random variable $U$ it's variance could have been defined by (but it isn't): $\\mathbb{E}(U - \\mathbb{E}(U))$. The problem with this definition is that it is analytically hard to work with. When is it negative vs. positive?\n- The second idea is to improve upon the previous one by taking the absolute value and measure the distance of the random variable from it's expectancy. i.e. for the random variable $U$ it's variance could be defined by (but it isn't): $\\mathbb{E}(|U - \\mathbb{E}(U)|)$. The main reason which because it isn't a good definition is because the function of the absolute value is not differentiable at $0$. You may ask how differentiation has anything to do with random variables? Well, recall that random variables are just functions from the probability space. The probability space can also be continuous (we don't use it here though).\n\n\u003e As pointed out, we can define probability spaces as continuous spaces. In our case, we say that the random variables are **Discrete** rather than **Continuous**. Roughly the extention to the continous case is straight forward and all we need to do is use integration instead of summation for the respective definitions (which makes the computations harder but the theory itself is not much more complex).\n\nWe define the variance of a random variable $U$ to be the expectancy of the squared distance from it's expectancy:\n\n$$\n  Var(U) := \\mathbb{E}((U - \\mathbb{E}(U))^2)\n$$\n\nLet's try to expand upon it a bit:\n\n$$\n  Var(U) = \\mathbb{E}((U - \\mathbb{E}(U))^2) = \\mathbb{E}(U^2 -2U\\mathbb{E}(U) + \\mathbb{E}(U)^2)\n$$\n\nBy linearity of expectation we get that:\n$$\n  Var(U) = \\mathbb{E}(U^2) - 2\\mathbb{E}(U)\\mathbb{E}(\\mathbb{E}(U))+\\mathbb{E}(U)^2\n$$\n\nThe expectancy itself is a real number, so the expectancy of an expectancy is itself:\n$$\n  Var(U) = \\mathbb{E}(U^2) - 2\\mathbb{E}(U)^2 + \\mathbb{E}(U)^2\n$$\n\nAnd we will get a useful formula for calculating the variance:\n$$\n  Var(U) = \\mathbb{E}(U^2) - \\mathbb{E}(U)^2\n$$\n\nThe variance is **not linear**. But we can say something about the variance of sums.\n\nFor **mutually independent** random variables $\\{ U_i \\}$ the variance of the sum is the sum of the variances: $Var(\\sum U_i) = \\sum Var(U_i)$.\n\nSo what about variables that are not necessarily mutually independent? The variance of the sum can be expressed as:\n\n$$\n  Var(\\sum U_i) = \\sum Var(U_i) + \\sum_{i \\neq j}Cov(U_i, U_j)\n$$\n\nWhere $Cov(U, V)$ is the **Covariance** of $U$ and $V$ and it is defined by:\n\n$$\n  Cov(U, V) := \\mathbb{E}((U - \\mathbb{E}(U))(V - \\mathbb{E}(V)))\n$$\n\n\u003e Formula of the variance of the sums can be easily reached by straight forward computations according to the expectancy definition\n\nA formula for calculating the covariance is given by:\n\n$$\n  Cov(U, V) = \\mathbb{E}(UV) - \\mathbb{E}(U)\\mathbb{E}(V)\n$$\n\n\u003e We reach this formula just by expanding the definition\n\n## Common Distributions\n\nWe previously saw 2 different common distributions. Let's cover them more generally.\n\n### Bernoulli Distribution\n\nThe **Bernoulli** distribution is notated by $B(p)$. It models a single trial that can either **succeed** with probability $p$ in which case the value of the random variable is 1 or **fail** with probability $1 - p$ in which case the value of the random variable is 0.\n\nA random variable $X \\sim B(p)$ is also called an **Indicator**.\n\n#### Expectancy\n\nThe expectancy is given by $\\mathbb{E}(X) = p$.\n\n*Proof*\n\n$$\n  \\mathbb{E}(X \\sim B(p)) = 1 \\cdot Pr(X=1) + 0 \\cdot Pr(X=0) = Pr(X = 1) = p\n$$\n\n#### Variance\n\nThe variance is given by $Var(X) = p(1 - p)$.\n\n*Proof*\n\n$$\n  Var(X) = \\mathbb{E}(X^2) - \\mathbb{E}(X)^2 = p - p^2 = p(1 - p)\n$$"])</script><script>self.__next_f.push([1,"11:T474d,"])</script><script>self.__next_f.push([1,"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003cnav class=\"toc\"\u003e\n      \u003col class=\"toc-level toc-level-1\"\u003e\n        \u003cli class=\"toc-item toc-item-h1\"\u003e\u003ca class=\"toc-link toc-link-h1\" href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n        \u003cli class=\"toc-item toc-item-h1\"\u003e\u003ca class=\"toc-link toc-link-h1\" href=\"#basic-definitions-and-results\"\u003eBasic definitions and results\u003c/a\u003e\n          \u003col class=\"toc-level toc-level-2\"\u003e\n            \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#union-bound\"\u003eUnion Bound\u003c/a\u003e\u003c/li\u003e\n            \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#conditional-probability\"\u003eConditional Probability\u003c/a\u003e\u003c/li\u003e\n            \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#bayes-rule\"\u003eBayes rule\u003c/a\u003e\u003c/li\u003e\n          \u003c/ol\u003e\n        \u003c/li\u003e\n        \u003cli class=\"toc-item toc-item-h1\"\u003e\u003ca class=\"toc-link toc-link-h1\" href=\"#probabilistic-method---union-bound-and-intersection-of-independent-events\"\u003eProbabilistic method - Union bound and Intersection of independent events\u003c/a\u003e\n          \u003col class=\"toc-level toc-level-2\"\u003e\n            \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#examples\"\u003eExamples\u003c/a\u003e\u003c/li\u003e\n          \u003c/ol\u003e\n        \u003c/li\u003e\n        \u003cli class=\"toc-item toc-item-h1\"\u003e\u003ca class=\"toc-link toc-link-h1\" href=\"#random-variables\"\u003eRandom Variables\u003c/a\u003e\n          \u003col class=\"toc-level toc-level-2\"\u003e\n            \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#expectancy\"\u003eExpectancy\u003c/a\u003e\u003c/li\u003e\n            \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#variance\"\u003eVariance\u003c/a\u003e\u003c/li\u003e\n            \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#common-distributions\"\u003eCommon Distributions\u003c/a\u003e\u003c/li\u003e\n          \u003c/ol\u003e\n        \u003c/li\u003e\n      \u003c/ol\u003e\n    \u003c/nav\u003e\n    \u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n    \u003cp\u003eIn this page we will discuss the probabilistic method which is a powerful tool to prove the existence of a combinatorial object. For a long time we have used conventional approaches for this purpose - Either we provided a proof by contruction or we provided a non-constructive proof. The probabilistic method is a non-constructive method first introduced by \u003ca href=\"https://en.wikipedia.org/wiki/Paul_Erd%C5%91s\"\u003ePaul Erdos\u003c/a\u003e while he was working on the development of the \u003ca href=\"https://en.wikipedia.org/wiki/Ramsey_theory\"\u003eRamsey Theory\u003c/a\u003e.\u003c/p\u003e\n    \u003cp\u003eIn essence, the method shows that the probability that some object with the desired property exist is greater than 0 and therefore one such instance surely exist, otherwise the probability was strictly 0.\u003c/p\u003e\n    \u003cp\u003eWe will use many practical examples and uses of this method which we will link to throughout this page.\u003c/p\u003e\n    \u003ch1 id=\"basic-definitions-and-results\"\u003eBasic definitions and results\u003c/h1\u003e\n    \u003cp\u003eBefore we continue we need to review the definition of probability spaces.\u003c/p\u003e\n    \u003cp\u003eA \u003cstrong\u003eprobability space\u003c/strong\u003e is a triplet $(\\Omega, \\Sigma, Pr)$ where\u003c/p\u003e\n    \u003col\u003e\n      \u003cli\u003e\n        \u003cp\u003e$\\Omega$ is a non-empty set known as the \u003cstrong\u003esample space\u003c/strong\u003e. It represents all possible outcomes of some experiment.\u003c/p\u003e\n        \u003cul\u003e\n          \u003cli\u003eWe will limit ourselves to a finite sample space.\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\n        \u003cp\u003e$\\Sigma$ is the collection of subsets of $\\Omega$ which is closed under the \u003cstrong\u003ecomplement ($x'$)\u003c/strong\u003e, \u003cstrong\u003eunion ($x \\cup y$)\u003c/strong\u003e and \u003cstrong\u003eintersection ($x \\cap y$)\u003c/strong\u003e operations.\u003c/p\u003e\n        \u003cul\u003e\n          \u003cli\u003eAn element $A \\in \\Sigma$ is called an \u003cstrong\u003eevent\u003c/strong\u003e.\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e\n        \u003cp\u003e$Pr : \\Sigma \\rightarrow [0, 1]$ is a function with the following properties:\u003c/p\u003e\n        \u003cul\u003e\n          \u003cli\u003e$Pr(\\Omega) = 1$\u003c/li\u003e\n          \u003cli\u003e$\\forall A, B \\in \\Sigma ; A \\cap B = \\phi \\implies Pr(A) + Pr(B) = Pr(A \\cup B)$\u003c/li\u003e\n          \u003cli\u003e$\\forall \\omega \\in \\Omega ; $ we will denote $Pr(\\omega) = Pr(\\{\\omega\\})$\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ol\u003e\n    \u003cblockquote\u003e\n      \u003cp\u003eMethematically, a probability space is a measure space with the measure function over $\\Omega$ where $\\Sigma$ is the $\\sigma$-algebra over $\\Omega$ and $Pr$ is the measure of the space such that $Pr(\\Omega) = 1$.\u003c/p\u003e\n    \u003c/blockquote\u003e\n    \u003ch2 id=\"union-bound\"\u003eUnion Bound\u003c/h2\u003e\n    \u003cp\u003eThe measue function is sub-additive with respect to the union operation. Meaning, every two events $A, B$ satisfies $Pr(A \\cup B) \\leq Pr(A) + Pr(B)$.\u003c/p\u003e\n    \u003cp\u003eIt makes sense, if the two events are not disjointed, the intersection part must be calculated once, not twice as is calculated in $Pr(A) + $Pr(B)$.\u003c/p\u003e\n    \u003cp\u003eMore generally, the \u003cstrong\u003eUnion Bound\u003c/strong\u003e theorem states that for any set of events $\\{ A_i \\}$ it holds that:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(\\bigcup_i A_i) \\leq \\sum_i Pr(A_i)\n      $$\n    \u003c/p\u003e\n    \u003ch2 id=\"conditional-probability\"\u003eConditional Probability\u003c/h2\u003e\n    \u003cp\u003eThe probability of some event $A$, given that we know that the event $B$ happened is called the \u003cstrong\u003econditional probability of $A$ given $B$\u003c/strong\u003e and is notated and given by\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)}\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eThis definition is intuitive. The probability $A$ happens given $B$ happens is firstly at the intersection between them. Then, we scale this probability of the intersection to limit ourselves to the \"world\" of $B$ only.\u003c/p\u003e\n    \u003cp\u003eAnother variant of this definition is known as the \u003cstrong\u003eproduct rule\u003c/strong\u003e:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(A \\cap B) = Pr(A | B) Pr(B)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eLet's see an example - Consider the experiment of rolling a six-sided die and let $A$ be the event that the number $2$ was thrown and $B$ the event that an even number was thrown. Formally, $A = \\{ 2 \\}, B = \\{2, 4, 6 \\}$. It is obvious that $Pr(A) = \\frac{1}{6}$ and $Pr(B) = \\frac{3}{6} = \\frac{1}{2}$. Intuitively, the probability that $A$ given $B$ is $\\frac{1}{3}$ since if we know an even number was rolled it means that one of three numbers 2, 4 and 6 were rolled - from those, the probability that 2 was rolled is $\\frac{1}{3}$. We can verify the intuition using the formula: $Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)} = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}$.\u003c/p\u003e\n    \u003cp\u003eNow, what happens when what we know about $B$ doesn't affect $A$? For example, consider $A$ to be the result of a die roll and $B$ the event that it is Sunday - the result of the roll is not affected by the day of week at all. Such events are called \u003cstrong\u003eindependent\u003c/strong\u003e, let's define it:\u003c/p\u003e\n    \u003cp\u003eTwo events $A$ and $B$ such that $Pr(A | B) = Pr(A)$ are said to be \u003cstrong\u003eindependent\u003c/strong\u003e.\u003c/p\u003e\n    \u003cp\u003eFor two independent events $A$ and $B$ we can see that:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(A) = Pr(A | B) = \\frac{Pr(A \\cap B)}{Pr(B)} \\implies Pr(A)Pr(B) = Pr(A \\cap B)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eWe can generalize this and get the important claim.\u003c/p\u003e\n    \u003cp\u003eFor every set of pair-wise independent events $\\{ A_i \\}$ it holds true that:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(\\bigcap_i A_i) = \\prod_i Pr(A_i)\n      $$\n    \u003c/p\u003e\n    \u003ch2 id=\"bayes-rule\"\u003eBayes rule\u003c/h2\u003e\n    \u003cp\u003eAlthough we won't use it much here, it is important to show a straight-forward result which stems from the definitions of conditional probability.\u003c/p\u003e\n    \u003cp\u003eUsing a bit of algebra, we can get the \u003cstrong\u003every\u003c/strong\u003e important rule, \u003cstrong\u003eBayes Rule\u003c/strong\u003e which states that we can always invert the conditional causality:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(A | B) = \\frac{Pr(B | A) Pr(A)}{Pr(B)}\n      $$\n    \u003c/p\u003e\n    \u003ch1 id=\"probabilistic-method---union-bound-and-intersection-of-independent-events\"\u003eProbabilistic method - Union bound and Intersection of independent events\u003c/h1\u003e\n    \u003cp\u003eUp until now we saw only basic results which we are all familiar with. Although basic, they provide provide the basic and most common tools for the probabilistic method. Usually the way we will use them is as follows.\u003c/p\u003e\n    \u003cp\u003eAssume we want to bound the probability of some event $A$ which we cannot calculate the probability of directly because it is somewhat complex.\u003c/p\u003e\n    \u003cp\u003eRepresent the $A$ as smaller, usually simpler events $A_i$ such that $A = \\bigcup_i A_i$. From the union bound we know that $Pr(A) \\leq \\sum_ Pr(A_i)$.\u003c/p\u003e\n    \u003cp\u003eUsually we will now be able to calculate $A_i$ directly. We will break such events even further such that $A_i = \\bigcup B_{ij}$ where $\\{ B_{ij} \\}$ is a set of pair-wise independent events. It is immediately follows by the intersection of independent event rule that $Pr(A_i) = \\prod_j Pr(B_{ij})$.\u003c/p\u003e\n    \u003cp\u003eFinally we can conclude that $Pr(A) \\leq \\sum_i \\prod_j Pr(B_{ij})$.\u003c/p\u003e\n    \u003cp\u003eUsually, we will see that the probabilities of the smaller events are similar to each other.\u003c/p\u003e\n    \u003ch2 id=\"examples\"\u003eExamples\u003c/h2\u003e\n    \u003cul\u003e\n      \u003cli\u003e\u003ca href=\"../hypergraph-2coloring\"\u003eHypergraph 2 Coloring\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href=\"../coupons-collector-v1\"\u003eCoupons Collector 1\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003ch1 id=\"random-variables\"\u003eRandom Variables\u003c/h1\u003e\n    \u003cp\u003eAnother basic object in probability theory is the \u003cstrong\u003eRandom Variable\u003c/strong\u003e. A random variable $X$ is a function that assigns a real number for each element in the sample space, $X : \\Omega \\rightarrow \\mathbb{R}$.\u003c/p\u003e\n    \u003cp\u003eAll of the possible inputs and outputs of a random variable is known as it's distribution: ${ (\\omega, X(\\omega)) | \\omega \\in \\Omega }$.\u003c/p\u003e\n    \u003cp\u003eLet's think of the experiment of rolling a fair dice. The sample space is $\\Omega = { 1, 2, 3, 4, 5, 6 }$.\u003c/p\u003e\n    \u003cp\u003eLet's define the random variable $X(\\omega) = 1 \u003cdel\u003eif\u003c/del\u003e \\omega \\leq 2 \u003cdel\u003eand\u003c/del\u003e 0 \u003cdel\u003eotherwise\u003c/del\u003e$. Meaning, $X$ is 1 if the outcome is $1$ or $2$, otherwise it's zero. $X$'s distribution is $A = { (1, 1), (2, 1), (3, 0), (4, 0), (5, 0), (6, 0) }$. What is the probability for the event that $X = 1$? Combinatorically, we calculate that $Pr(X = 1) = \\frac{|{\\omega | X(\\omega) = 1 }|}{|A|} = \\frac{2}{6} = \\frac{1}{3}$. This is rather intuitive, we know that a third of the outcomes are less than or equal to 2.\u003c/p\u003e\n    \u003cp\u003eLet's define another random variable $Y(\\omega) = \\omega \\cdot 2$. The range of $Y$ is $D = { 2, 4, 6, 8, 10, 12 }$. What is the probability that $Y$ gets the value $4$? Again, combinatorically we see that $Pr(Y=4) = \\frac{|{\\omega | Y(\\omega) = 2}|}{|D|}=\\frac{1}{6}$. In fact, that is true for all $d \\in D$ that $Pr(Y = d) = \\frac{1}{6}$!\u003c/p\u003e\n    \u003cp\u003eThe random variables $X$ and $Y$ exhibit different, yet common distribution patterns. $X$ behaves like a predicate - it get's the value 1 if some condition holds or 0 if it doesn't. Therefore, the probability of ${ X = 1 }$ is the probability of the condition to be true. $Y$ is simple, the probability for it to achieve any value is the same probability - specifically, it is exactly $\\frac{1}{|Range(Y)|}$.\u003c/p\u003e\n    \u003cp\u003e$X$'s distribution is known as the \u003cstrong\u003eBernoulli\u003c/strong\u003e distribution with probability $p = \\frac{1}{3}$. Usually, the Bernoulli distribution with probability $p$ is notated by $B(p)$. We notate the fact that $X$'s distribution is $B(\\frac{1}{3})$ by $X \\sim B(\\frac{1}{3})$.\u003c/p\u003e\n    \u003cp\u003e$Y$'s distribution is known as the \u003cstrong\u003eUniform\u003c/strong\u003e distribution with $n = 6$. Simlirarly, we notate $Y \\sim Uniform(6)$.\u003c/p\u003e\n    \u003ch2 id=\"expectancy\"\u003eExpectancy\u003c/h2\u003e\n    \u003cp\u003eThe \u003cstrong\u003eExpectency\u003c/strong\u003e of a random variable is the value we would expect the random variable to achieve. For any random variable $V$ we define its expectency by:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      \\mathbb{E}(V) := \\sum_{v \\in Range(V)} vPr(V=v) = \\sum_{\\omega \\in \\Omega}Pr(\\omega)V(\\omega)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eLet's calculate the expectencies of $X$ and $Y$ from the previous section:\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003e\n        $\\mathbb{E}(X) = Pr(1)X(1) + Pr(2)X(2) + Pr(3)X(3) + ... + Pr(6)X(6) = \\frac{1}{6} \\cdot 1+\\frac{1}{6} \\cdot 1 + \\frac{1}{6} \\cdot 0 + ... + \\frac{1}{6} \\cdot 0 =\n        \\frac{2}{6} = \\frac{1}{3}$\n        \u003cul\u003e\n          \u003cli\u003eNot coincidently, the expectancy is exactly the probability $p = \\frac{1}{3}$\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n      \u003cli\u003e$\\mathbb{E}(Y) = \\sum_{\\omega \\in {1, 2, 3, 4, 5, 6}} Pr(\\omega)Y(\\omega) = \\sum_{\\omega \\in {1, 2, 3, 4, 5, 6}} \\frac{1}{6} (\\omega \\cdot 2) = \\frac{\\sum_{\\omega \\in {1, 2, 3, 4, 5, 6}} \\omega \\cdot 2}{6} = 8$\n        \u003cul\u003e\n          \u003cli\u003eNot coincidently, the expectancy is exactly the average of the possible values\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/li\u003e\n    \u003c/ul\u003e\n    \u003cp\u003eThe expectancy has an important characteristic, known as the \u003cstrong\u003eLinearity of expectation\u003c/strong\u003e: For any two random variables $V, U$ and two real numbers $\\alpha, \\beta$:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      \\mathbb{\\mathbb{E}(\\alpha U + \\beta V)} = \\alpha \\mathbb{E}(U) + \\beta \\mathbb{E}(V)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eThis doesn't seems much but it is. As we know from theoretical math, the less constraints a theorem has the more powerful and robust it is. This is the case for the linearity of expectation - It holds for \u003cstrong\u003eany\u003c/strong\u003e two random variables, now small print, that's it.\u003c/p\u003e\n    \u003ch2 id=\"variance\"\u003eVariance\u003c/h2\u003e\n    \u003cp\u003eObserve the two uniform distributions ${ 0, 100 }$ and ${ 49, 51 }$. Both of their expectancies are 50 but they are inherently different with respect to the distance of the values from it. A measurement for how far the values spread within the distribution is known as the \u003cstrong\u003eVariance\u003c/strong\u003e.\u003c/p\u003e\n    \u003cp\u003eHow will we define the variance then?\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eThe first idea is to subtract the random variable from it's expectency and take the expectancy of that. i.e., for the random variable $U$ it's variance could have been defined by (but it isn't): $\\mathbb{E}(U - \\mathbb{E}(U))$. The problem with this definition is that it is analytically hard to work with. When is it negative vs. positive?\u003c/li\u003e\n      \u003cli\u003eThe second idea is to improve upon the previous one by taking the absolute value and measure the distance of the random variable from it's expectancy. i.e. for the random variable $U$ it's variance could be defined by (but it isn't): $\\mathbb{E}(|U - \\mathbb{E}(U)|)$. The main reason which because it isn't a good definition is because the function of the absolute value is not differentiable at $0$. You may ask how differentiation has anything to do with random variables? Well, recall that random variables are just functions from the probability space. The probability space can also be continuous (we don't use it here though).\u003c/li\u003e\n    \u003c/ul\u003e\n    \u003cblockquote\u003e\n      \u003cp\u003eAs pointed out, we can define probability spaces as continuous spaces. In our case, we say that the random variables are \u003cstrong\u003eDiscrete\u003c/strong\u003e rather than \u003cstrong\u003eContinuous\u003c/strong\u003e. Roughly the extention to the continous case is straight forward and all we need to do is use integration instead of summation for the respective definitions (which makes the computations harder but the theory itself is not much more complex).\u003c/p\u003e\n    \u003c/blockquote\u003e\n    \u003cp\u003eWe define the variance of a random variable $U$ to be the expectancy of the squared distance from it's expectancy:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Var(U) := \\mathbb{E}((U - \\mathbb{E}(U))^2)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eLet's try to expand upon it a bit:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Var(U) = \\mathbb{E}((U - \\mathbb{E}(U))^2) = \\mathbb{E}(U^2 -2U\\mathbb{E}(U) + \\mathbb{E}(U)^2)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003e\n      By linearity of expectation we get that:\n      $$\n      Var(U) = \\mathbb{E}(U^2) - 2\\mathbb{E}(U)\\mathbb{E}(\\mathbb{E}(U))+\\mathbb{E}(U)^2\n      $$\n    \u003c/p\u003e\n    \u003cp\u003e\n      The expectancy itself is a real number, so the expectancy of an expectancy is itself:\n      $$\n      Var(U) = \\mathbb{E}(U^2) - 2\\mathbb{E}(U)^2 + \\mathbb{E}(U)^2\n      $$\n    \u003c/p\u003e\n    \u003cp\u003e\n      And we will get a useful formula for calculating the variance:\n      $$\n      Var(U) = \\mathbb{E}(U^2) - \\mathbb{E}(U)^2\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eThe variance is \u003cstrong\u003enot linear\u003c/strong\u003e. But we can say something about the variance of sums.\u003c/p\u003e\n    \u003cp\u003eFor \u003cstrong\u003emutually independent\u003c/strong\u003e random variables ${ U_i }$ the variance of the sum is the sum of the variances: $Var(\\sum U_i) = \\sum Var(U_i)$.\u003c/p\u003e\n    \u003cp\u003eSo what about variables that are not necessarily mutually independent? The variance of the sum can be expressed as:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Var(\\sum U_i) = \\sum Var(U_i) + \\sum_{i \\neq j}Cov(U_i, U_j)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eWhere $Cov(U, V)$ is the \u003cstrong\u003eCovariance\u003c/strong\u003e of $U$ and $V$ and it is defined by:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Cov(U, V) := \\mathbb{E}((U - \\mathbb{E}(U))(V - \\mathbb{E}(V)))\n      $$\n    \u003c/p\u003e\n    \u003cblockquote\u003e\n      \u003cp\u003eFormula of the variance of the sums can be easily reached by straight forward computations according to the expectancy definition\u003c/p\u003e\n    \u003c/blockquote\u003e\n    \u003cp\u003eA formula for calculating the covariance is given by:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Cov(U, V) = \\mathbb{E}(UV) - \\mathbb{E}(U)\\mathbb{E}(V)\n      $$\n    \u003c/p\u003e\n    \u003cblockquote\u003e\n      \u003cp\u003eWe reach this formula just by expanding the definition\u003c/p\u003e\n    \u003c/blockquote\u003e\n    \u003ch2 id=\"common-distributions\"\u003eCommon Distributions\u003c/h2\u003e\n    \u003cp\u003eWe previously saw 2 different common distributions. Let's cover them more generally.\u003c/p\u003e\n    \u003ch3 id=\"bernoulli-distribution\"\u003eBernoulli Distribution\u003c/h3\u003e\n    \u003cp\u003eThe \u003cstrong\u003eBernoulli\u003c/strong\u003e distribution is notated by $B(p)$. It models a single trial that can either \u003cstrong\u003esucceed\u003c/strong\u003e with probability $p$ in which case the value of the random variable is 1 or \u003cstrong\u003efail\u003c/strong\u003e with probability $1 - p$ in which case the value of the random variable is 0.\u003c/p\u003e\n    \u003cp\u003eA random variable $X \\sim B(p)$ is also called an \u003cstrong\u003eIndicator\u003c/strong\u003e.\u003c/p\u003e\n    \u003ch4 id=\"expectancy-1\"\u003eExpectancy\u003c/h4\u003e\n    \u003cp\u003eThe expectancy is given by $\\mathbb{E}(X) = p$.\u003c/p\u003e\n    \u003cp\u003e\u003cem\u003eProof\u003c/em\u003e\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      \\mathbb{E}(X \\sim B(p)) = 1 \\cdot Pr(X=1) + 0 \\cdot Pr(X=0) = Pr(X = 1) = p\n      $$\n    \u003c/p\u003e\n    \u003ch4 id=\"variance-1\"\u003eVariance\u003c/h4\u003e\n    \u003cp\u003eThe variance is given by $Var(X) = p(1 - p)$.\u003c/p\u003e\n    \u003cp\u003e\u003cem\u003eProof\u003c/em\u003e\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Var(X) = \\mathbb{E}(X^2) - \\mathbb{E}(X)^2 = p - p^2 = p(1 - p)\n      $$\n    \u003c/p\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"div\",null,{\"className\":\"article-page_container__5yaZl\",\"children\":[[\"$\",\"h1\",null,{\"children\":\"The Probabilistic Method\"}],[\"$\",\"div\",null,{\"className\":\"Taxonomy_container__C2Vdb\",\"children\":[\"$\",\"div\",null,{\"className\":\"Taxonomy_values__yvK16\",\"children\":[[\"$\",\"$Ld\",\"0\",{\"href\":\"/tags/Probabilistic Method\",\"children\":[\"$\",\"div\",null,{\"className\":\"Chip_container__q1AW2\",\"children\":\"Probabilistic Method\"}]}],[\"$\",\"$Ld\",\"1\",{\"href\":\"/tags/Probability\",\"children\":[\"$\",\"div\",null,{\"className\":\"Chip_container__q1AW2\",\"children\":\"Probability\"}]}],[\"$\",\"$Ld\",\"2\",{\"href\":\"/tags/Algorithms\",\"children\":[\"$\",\"div\",null,{\"className\":\"Chip_container__q1AW2\",\"children\":\"Algorithms\"}]}]]}]}],[\"$\",\"$Lf\",null,{\"content\":{\"raw\":\"$10\",\"html\":\"$11\"}}]]}]\n"])</script><script>self.__next_f.push([1,"6:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Article\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Personal site\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}],[\"$\",\"meta\",\"5\",{\"name\":\"next-size-adjust\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,""])</script></body></html>