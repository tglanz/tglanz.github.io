<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/fc3ec0f12aa27086.css" as="style"/><link rel="stylesheet" href="/_next/static/css/fc3ec0f12aa27086.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a7fabc11ce9fdee5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a7fabc11ce9fdee5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-20cc5a3cc3d233fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-97927b8cd08b2c1f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-2b3ff0d0be8e812a.js" defer=""></script><script src="/_next/static/chunks/175675d1-7de8b3bfdcedb0f1.js" defer=""></script><script src="/_next/static/chunks/113-d38bb2befbc77dc7.js" defer=""></script><script src="/_next/static/chunks/pages/_articles/%5B...articleId%5D-14c11b9e88d91c56.js" defer=""></script><script src="/_next/static/y-4YuGaAcIl1cKZu0-Kle/_buildManifest.js" defer=""></script><script src="/_next/static/y-4YuGaAcIl1cKZu0-Kle/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_container__K9hpm"><nav class="p-6 border border-r-2"><div class="flex flex-col items-center"><img src="/logo.png" width="100" height="100"/><span class="text-3xl font-semibold">Tal Glanzman</span><span class="text-lg">Software Engineer</span></div><div class="mt-6"><ul><li><a href="/">Home</a></li><li><a href="/_index/">Index</a></li><details><summary>Computer Science</summary><ul class="ml-4"><li><a href="/_articles/computer-science/linear-programming/">Linear Programming</a></li><li><a href="/_articles/probabilistic-method/probabilistic-method/">Probabilistic Method</a></li></ul></details><li><a href="/_articles/about/">About</a></li></ul></div><div class="mt-6"><div><form action="/_search" autoComplete="off" class="flex flex-col justify-center items-center"><input class="text-input" type="text" name="query" placeholder="Search"/><input class="button" type="submit" hidden="" value="Search"/></form></div></div></nav><header><div class=" p-2 flex flex-col items-center"><span class="text-4xl font-semibold">Bayesian Networks</span><span class="text-lg"></span></div></header><main><div class="text-sm m-4"><div><span>Categories<!-- -->: </span><span><span class="inline-block"><a href="/_categories/Intro%20to%20AI/">Intro to AI</a></span></span></div><div><span>Tags<!-- -->: </span><span><span class="inline-block"><a href="/_tags/AI/">AI</a></span><span class="inline-block">, <a href="/_tags/Probability/">Probability</a></span></span></div></div><div class="ArticleContent_md__52PoF"><!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
    <nav class="toc">
      <ol class="toc-level toc-level-1">
        <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#definition">Definition</a></li>
        <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#example">Example</a></li>
        <li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#semantics">Semantics</a></li>
      </ol>
    </nav>
    <p><strong>NOTE</strong>: Need to continue this.</p>
    <h2 id="definition">Definition</h2>
    <p>A <strong>Bayesian Network (BN)</strong> is a data structure that represents dependencies among different Random Variables. BNs represent the full joint distribution concisely which leads to more efficient query inferences.</p>
    <p>A Bayesian Network is a directed, acyclic graph whose nodes represent a random variable and the edges represent a parent-child relationship. For every node $X$ the network associates the conditioned probabilities of $X$ as an effect of it's parents, i.e. $P(X | Parents(X))$.</p>
    <p>Each node is attached with local probability information a.k.a <strong>conditional probability table (CPT)</strong>.</p>
    <h2 id="example">Example</h2>
    <p>Let's consider the following scenario. A burglary alarm in Paul's home can be set off by small earthquakes. Paul has two neighbors: Nina and Lei - they promised Paul to call him when they hear the alarm. Nina is very alert but Lei is always busy and is more likely not to hear Paul's alarm. Given a call, what is the probability of a burglary?</p>
    <p>Below is a BN describing the scenario:</p>
    <img src="https://www.plantuml.com/plantuml/png/IybCBqeio51mLwZcKW22QjV4efACmjB4x5GT1QVIelISnABAMWLTEmL782lN6gm8p0I9LVkaPZedvkGKwoZuPUObWfcrrbor0000">
    <p>And the CPT tables:</p>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th>$P(Burglary=true)$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>0.001</td>
          </tr>
        </tbody>
      </table>
    </div>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th>$P(Earthquake=true)$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>0.002</td>
          </tr>
        </tbody>
      </table>
    </div>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th>$Burglary$</th>
            <th>$Earthquake$</th>
            <th>$P(Alarm=true \mid Burglary, Earthquake)$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>true</td>
            <td>true</td>
            <td>0.95</td>
          </tr>
          <tr>
            <td>true</td>
            <td>false</td>
            <td>0.94</td>
          </tr>
          <tr>
            <td>false</td>
            <td>true</td>
            <td>0.29</td>
          </tr>
          <tr>
            <td>false</td>
            <td>false</td>
            <td>0.001</td>
          </tr>
        </tbody>
      </table>
    </div>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th>$Alarm$</th>
            <th>$P(NinaCalls=true \mid Alarm)$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>true</td>
            <td>0.9</td>
          </tr>
          <tr>
            <td>false</td>
            <td>0.05</td>
          </tr>
        </tbody>
      </table>
    </div>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th>$Alarm$</th>
            <th>$P(LeiCalls=true \mid Alarm)$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>true</td>
            <td>0.7</td>
          </tr>
          <tr>
            <td>false</td>
            <td>0.01</td>
          </tr>
        </tbody>
      </table>
    </div>
    <p class="hint tip">Notice we didn't need to write the complements in the CPTs since they are computable by "1-..."</p>
    <h2 id="semantics">Semantics</h2>
    <p>We defined the syntax of BNs above. The semantics we want to impose on BNs is that different variables are conditionall independent of each other <strong>given their parents</strong></p>
    <p>
      $$
      P(x_1, x_2, ..., x_n) = \Pi_{i=1}^{n}{P(x_i | Parents(x_i))}
      $$
    </p>
    <p>In general, we can reduce the joint distribution by iteratively invoking the <strong>product rule</strong>:</p>
    <p>
      $$
      \begin{align*}
      P(x_1, x_2, ..., x_n) &#x26;= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_1, x_2, ..., x_{n-1}) \\
      &#x26;= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_{n-1} | x_1, x_2, ..., x_{n=2}) P(x_1, x_2, ..., x_{n-2}) \\
      &#x26;= ... \\
      &#x26;= \Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})
      \end{align*}
      $$
    </p>
    <p>This is a very important formula and is known as the <strong>chain rule</strong>:</p>
    <p>
      $$
      P(x_1, x_2, ..., x_n) = \Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})
      $$
    </p>
    <p>Combining the chain rule with the first formula we desire the following equality:</p>
    <p>
      $$
      \Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1}) = \Pi_{i=1}^{n}{P(x_i | Parents(x_i))}
      $$
    </p>
    <p>Or in vector form:</p>
    <p>
      $$
      P(X_i | X_1, ..., X_{i-1}) = P(X_i | Parents(X_1, ..., X_{i-1}))
      $$
    </p>
    <p>We get this by enforcing <strong>topological ordering</strong> and linking nodes to their parents in such a way that they are conditionally independent of any other node given their parents.</p>
  </body>
</html>
</div></main><footer><div class=" border-t-2 p-4 flex flex-row justify-center items-center space-x-4"><a href="https://github.com/tglanz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://il.linkedin.com/in/tal-glanzman"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"article":{"id":"intro-to-ai/bayesian-networks","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/intro-to-ai/bayesian-networks.md","metadata":{"title":"Bayesian Networks","description":null,"priority":0,"tags":["AI","Probability"],"categories":["Intro to AI"],"toc":true},"content":{"raw":"\n**NOTE**: Need to continue this.\n\n## Definition\n\nA **Bayesian Network (BN)** is a data structure that represents dependencies among different Random Variables. BNs represent the full joint distribution concisely which leads to more efficient query inferences.\n\nA Bayesian Network is a directed, acyclic graph whose nodes represent a random variable and the edges represent a parent-child relationship. For every node $X$ the network associates the conditioned probabilities of $X$ as an effect of it's parents, i.e. $P(X | Parents(X))$.\n\nEach node is attached with local probability information a.k.a **conditional probability table (CPT)**.\n\n## Example\n\nLet's consider the following scenario. A burglary alarm in Paul's home can be set off by small earthquakes. Paul has two neighbors: Nina and Lei - they promised Paul to call him when they hear the alarm. Nina is very alert but Lei is always busy and is more likely not to hear Paul's alarm. Given a call, what is the probability of a burglary?\n\nBelow is a BN describing the scenario:\n\n```plantuml\ndigraph G {\n    {Earthquake, Burglary} -\u003e Alarm;\n    Alarm -\u003e {LeiCalls, NinaCalls};\n}\n```\n\nAnd the CPT tables:\n\n$P(Burglary=true)$|\n----------|\n0.001|\n\n$P(Earthquake=true)$|\n----------|\n0.002|\n\n$Burglary$ | $Earthquake$ | $P(Alarm=true \\mid Burglary, Earthquake)$ |\n-----------|--------------|---------------|\ntrue|true|0.95\ntrue|false|0.94\nfalse|true|0.29\nfalse|false|0.001\n\n$Alarm$ | $P(NinaCalls=true \\mid Alarm)$ |\n--------|--------------------------------|\ntrue | 0.9\nfalse | 0.05\n\n$Alarm$ | $P(LeiCalls=true \\mid Alarm)$ |\n--------|--------------------------------|\ntrue | 0.7\nfalse | 0.01\n\n!\u003e Notice we didn't need to write the complements in the CPTs since they are computable by \"1-...\"\n\n## Semantics\n\nWe defined the syntax of BNs above. The semantics we want to impose on BNs is that different variables are conditionall independent of each other **given their parents**\n\n$$\nP(x_1, x_2, ..., x_n) = \\Pi_{i=1}^{n}{P(x_i | Parents(x_i))}\n$$\n\nIn general, we can reduce the joint distribution by iteratively invoking the **product rule**: \n\n$$\n\\begin{align*}\nP(x_1, x_2, ..., x_n) \u0026= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_1, x_2, ..., x_{n-1}) \\\\\\\\\n  \u0026= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_{n-1} | x_1, x_2, ..., x_{n=2}) P(x_1, x_2, ..., x_{n-2}) \\\\\\\\\n  \u0026= ... \\\\\\\\\n  \u0026= \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})\n\\end{align*}\n$$\n\nThis is a very important formula and is known as the **chain rule**:\n\n$$\nP(x_1, x_2, ..., x_n) = \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})\n$$\n\nCombining the chain rule with the first formula we desire the following equality:\n\n$$\n\\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1}) = \\Pi_{i=1}^{n}{P(x_i | Parents(x_i))}\n$$\n\nOr in vector form:\n\n$$\nP(X_i | X_1, ..., X_{i-1}) = P(X_i | Parents(X_1, ..., X_{i-1}))\n$$\n\nWe get this by enforcing **topological ordering** and linking nodes to their parents in such a way that they are conditionally independent of any other node given their parents.  \n","html":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003cnav class=\"toc\"\u003e\n      \u003col class=\"toc-level toc-level-1\"\u003e\n        \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#definition\"\u003eDefinition\u003c/a\u003e\u003c/li\u003e\n        \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#example\"\u003eExample\u003c/a\u003e\u003c/li\u003e\n        \u003cli class=\"toc-item toc-item-h2\"\u003e\u003ca class=\"toc-link toc-link-h2\" href=\"#semantics\"\u003eSemantics\u003c/a\u003e\u003c/li\u003e\n      \u003c/ol\u003e\n    \u003c/nav\u003e\n    \u003cp\u003e\u003cstrong\u003eNOTE\u003c/strong\u003e: Need to continue this.\u003c/p\u003e\n    \u003ch2 id=\"definition\"\u003eDefinition\u003c/h2\u003e\n    \u003cp\u003eA \u003cstrong\u003eBayesian Network (BN)\u003c/strong\u003e is a data structure that represents dependencies among different Random Variables. BNs represent the full joint distribution concisely which leads to more efficient query inferences.\u003c/p\u003e\n    \u003cp\u003eA Bayesian Network is a directed, acyclic graph whose nodes represent a random variable and the edges represent a parent-child relationship. For every node $X$ the network associates the conditioned probabilities of $X$ as an effect of it's parents, i.e. $P(X | Parents(X))$.\u003c/p\u003e\n    \u003cp\u003eEach node is attached with local probability information a.k.a \u003cstrong\u003econditional probability table (CPT)\u003c/strong\u003e.\u003c/p\u003e\n    \u003ch2 id=\"example\"\u003eExample\u003c/h2\u003e\n    \u003cp\u003eLet's consider the following scenario. A burglary alarm in Paul's home can be set off by small earthquakes. Paul has two neighbors: Nina and Lei - they promised Paul to call him when they hear the alarm. Nina is very alert but Lei is always busy and is more likely not to hear Paul's alarm. Given a call, what is the probability of a burglary?\u003c/p\u003e\n    \u003cp\u003eBelow is a BN describing the scenario:\u003c/p\u003e\n    \u003cimg src=\"https://www.plantuml.com/plantuml/png/IybCBqeio51mLwZcKW22QjV4efACmjB4x5GT1QVIelISnABAMWLTEmL782lN6gm8p0I9LVkaPZedvkGKwoZuPUObWfcrrbor0000\"\u003e\n    \u003cp\u003eAnd the CPT tables:\u003c/p\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth\u003e$P(Burglary=true)$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd\u003e0.001\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth\u003e$P(Earthquake=true)$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd\u003e0.002\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth\u003e$Burglary$\u003c/th\u003e\n            \u003cth\u003e$Earthquake$\u003c/th\u003e\n            \u003cth\u003e$P(Alarm=true \\mid Burglary, Earthquake)$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd\u003etrue\u003c/td\u003e\n            \u003ctd\u003etrue\u003c/td\u003e\n            \u003ctd\u003e0.95\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd\u003etrue\u003c/td\u003e\n            \u003ctd\u003efalse\u003c/td\u003e\n            \u003ctd\u003e0.94\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd\u003efalse\u003c/td\u003e\n            \u003ctd\u003etrue\u003c/td\u003e\n            \u003ctd\u003e0.29\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd\u003efalse\u003c/td\u003e\n            \u003ctd\u003efalse\u003c/td\u003e\n            \u003ctd\u003e0.001\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth\u003e$Alarm$\u003c/th\u003e\n            \u003cth\u003e$P(NinaCalls=true \\mid Alarm)$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd\u003etrue\u003c/td\u003e\n            \u003ctd\u003e0.9\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd\u003efalse\u003c/td\u003e\n            \u003ctd\u003e0.05\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth\u003e$Alarm$\u003c/th\u003e\n            \u003cth\u003e$P(LeiCalls=true \\mid Alarm)$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd\u003etrue\u003c/td\u003e\n            \u003ctd\u003e0.7\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd\u003efalse\u003c/td\u003e\n            \u003ctd\u003e0.01\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cp class=\"hint tip\"\u003eNotice we didn't need to write the complements in the CPTs since they are computable by \"1-...\"\u003c/p\u003e\n    \u003ch2 id=\"semantics\"\u003eSemantics\u003c/h2\u003e\n    \u003cp\u003eWe defined the syntax of BNs above. The semantics we want to impose on BNs is that different variables are conditionall independent of each other \u003cstrong\u003egiven their parents\u003c/strong\u003e\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      P(x_1, x_2, ..., x_n) = \\Pi_{i=1}^{n}{P(x_i | Parents(x_i))}\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eIn general, we can reduce the joint distribution by iteratively invoking the \u003cstrong\u003eproduct rule\u003c/strong\u003e:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      \\begin{align*}\n      P(x_1, x_2, ..., x_n) \u0026#x26;= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_1, x_2, ..., x_{n-1}) \\\\\n      \u0026#x26;= P(x_n | x_1, x_2, ..., x_{n-1}) P(x_{n-1} | x_1, x_2, ..., x_{n=2}) P(x_1, x_2, ..., x_{n-2}) \\\\\n      \u0026#x26;= ... \\\\\n      \u0026#x26;= \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})\n      \\end{align*}\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eThis is a very important formula and is known as the \u003cstrong\u003echain rule\u003c/strong\u003e:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      P(x_1, x_2, ..., x_n) = \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1})\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eCombining the chain rule with the first formula we desire the following equality:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      \\Pi_{i=1}^{n} P(x_i | x_1, ..., x_{i-1}) = \\Pi_{i=1}^{n}{P(x_i | Parents(x_i))}\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eOr in vector form:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      P(X_i | X_1, ..., X_{i-1}) = P(X_i | Parents(X_1, ..., X_{i-1}))\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eWe get this by enforcing \u003cstrong\u003etopological ordering\u003c/strong\u003e and linking nodes to their parents in such a way that they are conditionally independent of any other node given their parents.\u003c/p\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"}}},"__N_SSG":true},"page":"/_articles/[...articleId]","query":{"articleId":["intro-to-ai","bayesian-networks"]},"buildId":"y-4YuGaAcIl1cKZu0-Kle","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>