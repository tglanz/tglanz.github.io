<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/fc3ec0f12aa27086.css" as="style"/><link rel="stylesheet" href="/_next/static/css/fc3ec0f12aa27086.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a7fabc11ce9fdee5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a7fabc11ce9fdee5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-20cc5a3cc3d233fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-97927b8cd08b2c1f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-2b3ff0d0be8e812a.js" defer=""></script><script src="/_next/static/chunks/175675d1-7de8b3bfdcedb0f1.js" defer=""></script><script src="/_next/static/chunks/113-d38bb2befbc77dc7.js" defer=""></script><script src="/_next/static/chunks/pages/_articles/%5B...articleId%5D-14c11b9e88d91c56.js" defer=""></script><script src="/_next/static/2UtthYsk4Izfh9PIWGXxM/_buildManifest.js" defer=""></script><script src="/_next/static/2UtthYsk4Izfh9PIWGXxM/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="Layout_container__K9hpm"><nav class="p-6 border border-r-2"><div class="flex flex-col items-center"><img src="/logo.png" width="100" height="100"/><span class="text-3xl font-semibold">Tal Glanzman</span><span class="text-lg">Software Engineer</span></div><div class="mt-6"><ul><li><a href="/">Home</a></li><li><a href="/_index/">Index</a></li><details><summary>Computer Science</summary><ul class="ml-4"><li><a href="/_articles/computer-science/linear-programming/">Linear Programming</a></li><li><a href="/_articles/probabilistic-method/probabilistic-method/">Probabilistic Method</a></li></ul></details><li><a href="/_articles/about/">About</a></li></ul></div><div class="mt-6"><div><form action="/_search" autoComplete="off" class="flex flex-col justify-center items-center"><input class="text-input" type="text" name="query" placeholder="Search"/><input class="button" type="submit" hidden="" value="Search"/></form></div></div></nav><header><div class=" p-2 flex flex-col items-center"><span class="text-4xl font-semibold">k-Wise independence</span><span class="text-lg"></span></div></header><main><div class="text-sm m-4"><div><span>Categories<!-- -->: </span><span><span class="inline-block"><a href="/_categories/Probabilistic%20Method/">Probabilistic Method</a></span></span></div><div><span>Tags<!-- -->: </span><span><span class="inline-block"><a href="/_tags/Probabilistic%20Method/">Probabilistic Method</a></span></span></div></div><div class="ArticleContent_md__52PoF"><!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
    <h1 id="k-wise-independence">k-wise independence</h1>
    <p><strong>Definition</strong> The $n$ random variables $X_1, X_2, ..., X_n$ are said to be <strong>k-wise independent</strong> iff any subset of $k$ random variables $X_{i_1}, X_{i_2}, ..., X_{i_k}$ consists of randomly independent variables, i.e.:</p>
    <p>
      $$
      Pr(X_{i_1}, X_{i_2}, ..., X_{i_k}) = \prod_{j=1}^k Pr(X_{i_j})
      $$
    </p>
    <p>Combinatorically, there are $n \choose k$ different constraints.</p>
    <p>Given $n$, for every $k &#x3C; n -1$ we can construct a set of $n$ random variables that are k-wise indpendent but not (k+1)-wise independent. Let's see a specific example:</p>
    <h2 id="example-2-but-not-3-wise-independence">Example, 2 but not 3 wise independence</h2>
    <p>For an example, we will show a group of 3 random variables that are 2-wise independent and are not 3-wise independent.</p>
    <p>Let $X, Y$ be uniformly random bits (i.e. they are random variables that can assume the values 0 or 1).</p>
    <p>The truth table, with the probability of of the entry:</p>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th align="center">Pr(X, Y)</th>
            <th align="center">$X$</th>
            <th align="center">$Y$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">0</td>
            <td align="center">0</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">0</td>
            <td align="center">1</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">1</td>
            <td align="center">0</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">1</td>
            <td align="center">1</td>
          </tr>
        </tbody>
      </table>
    </div>
    <p>We can see that $Pr(X, Y) = Pr(X)Pr(Y)$ so obsiously $X$ and $Y$ are independent.</p>
    <p>Now, let's define $Z := X \oplus Y$ where $\oplus$ is the XOR operation. We can write the truth table:</p>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th align="center">$X$</th>
            <th align="center">$Y$</th>
            <th align="center">$Z$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center">0</td>
            <td align="center">0</td>
            <td align="center">0</td>
          </tr>
          <tr>
            <td align="center">0</td>
            <td align="center">1</td>
            <td align="center">1</td>
          </tr>
          <tr>
            <td align="center">1</td>
            <td align="center">0</td>
            <td align="center">1</td>
          </tr>
          <tr>
            <td align="center">1</td>
            <td align="center">1</td>
            <td align="center">0</td>
          </tr>
        </tbody>
      </table>
    </div>
    <p>Let's examine only $X$ and $Z$:</p>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th align="center">Pr(X, Z)</th>
            <th align="center">$X$</th>
            <th align="center">$Z$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">0</td>
            <td align="center">0</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">0</td>
            <td align="center">1</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">1</td>
            <td align="center">1</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">1</td>
            <td align="center">0</td>
          </tr>
        </tbody>
      </table>
    </div>
    <p>We can see that $Pr(X, Z) = Pr(X)Pr(Z)$ so obsiously $X$ and $Z$ are independent.</p>
    <p>Let's examine only $Y$ and $Z$:</p>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th align="center">Pr(Y, Z)</th>
            <th align="center">$Y$</th>
            <th align="center">$Z$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">0</td>
            <td align="center">0</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">1</td>
            <td align="center">1</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">0</td>
            <td align="center">1</td>
          </tr>
          <tr>
            <td align="center">$\frac{1}{4}$</td>
            <td align="center">1</td>
            <td align="center">0</td>
          </tr>
        </tbody>
      </table>
    </div>
    <p>We can see that $Pr(Y, Z) = Pr(Y)Pr(Z)$ so obsiously $Y$ and $Z$ are independent.</p>
    <p>All in all, we saw that every pair from $X, Y$ and $Z$ are independent. But of course they are not 3-wise indpeendent because by the definition of $Z$ it is not random at all! $Z$ is defined as the XOR of $X$ and $Y$ and is not assuming random values. For example, $Pr(X=0, Y=0, Z=1) = 0$ rather than $\frac{1}{2}^3$.</p>
    <h2 id="the-construction-of-vandermonde-vdm">The construction of Vandermonde (VDM)</h2>
    <p>The construction of VDM is a construction of $N$ random variables that are uniformly distributed in ${ 0, 1, ..., N }$ that are k-wise independent.</p>
    <p>Let $\mathbb{F}$ be a field such that $\mathbb{|F|} = N$ and $N$ is a power of a primary number.</p>
    <blockquote>
      <p>We limited the genrality a bit by limiting $N$</p>
    </blockquote>
    <p>Let $a_0, a_1, ..., a_k \in \mathbb{F}$ be $k$ independent uniformly random variables. We define a unfiormly random polynomail $p(x)$ of degree $k$ by:</p>
    <p>
      $$
      p(x) = \sum_{i = 0}^{k-1} a_i x^i
      $$
    </p>
    <p>For every $\alpha \in \mathbb{F}$ the polynomial $p$ implicitly defines a random variable $p(\alpha)$.</p>
    <p>We will show that for every $k$ different elements $\alpha_0, \alpha_2, ..., \alpha_{k-1} \in \mathbb{F}$ the $k$ random variables $P = { p(\alpha_0), p(\alpha_1), ..., p(\alpha_{k-1}) }$ are independent and are uniformly distributed.</p>
    <p>Once we showed this, we showed that the $N$ random variables which are implicitly defined from all the elements in the field $\mathbb{F}$, are k-wise independent.</p>
    <p>To show that $P$ are independent we need to show that for every $v_0, v_1, ..., v_{k-1} \in \mathbb{F}$ it holds true that</p>
    <p>
      $$
      Pr(p(\alpha_0) = v_0, p(\alpha_1) = v_1, ..., p(\alpha_{k-1}) = v_{k-1}) = Pr(p(\alpha_0) = v_0) \cdot Pr(p(\alpha_1) = v_1) \cdot \cdot \cdot Pr(p(\alpha_{k-1}) = v_{k-1})
      $$
    </p>
    <p>Or in vector form:</p>
    <p>
      $$
      Pr(p(\alpha) = v) = \prod_{i=0}^{k-1} Pr(p(\alpha_i) = v_i)
      $$
    </p>
    <p>And to show that $P$ are uniformly distributed we need to show that</p>
    <p>
      $$
      Pr(p(\alpha) = v) = \prod_{i=0}^{k-1} Pr(p(\alpha_i) = v_i) = N^{-k}
      $$
    </p>
    <p>Let's get to work then. We start by expanding the expressions:</p>
    <p>
      \begin{align*}
      &#x26;p(\alpha_0) = \sum_{i=0}^{k-1} a_i \alpha_0^i = v_0 \\
      &#x26;p(\alpha_1) = \sum_{i=0}^{k-1} a_i \alpha_1^i = v_1 \\
      &#x26;... \\
      &#x26;p(\alpha_{k-1}) = \sum_{i=0}^{k-1} a_i \alpha_{k-1}^i = v_{k-1} \\
      \end{align*}
    </p>
    <p>Let $V$ be the matrix:</p>
    <p>
      $$
      V =
      \begin{pmatrix}
      \alpha_0^0 &#x26; \alpha_0^1 &#x26; ... &#x26; \alpha_0^{k-1} \\
      \alpha_1^0 &#x26; \alpha_1^1 &#x26; ... &#x26; \alpha_1^{k-1} \\
      \vdots &#x26; \vdots &#x26; \vdots &#x26; \vdots \\
      \alpha_{k-1}^0 &#x26; \alpha_{k-1}^1 &#x26; ... &#x26; \alpha_{k-1}^{k-1} \\
      \end{pmatrix}
      $$
    </p>
    <p>This kind of matrix is well known as the <strong>VDM</strong> matrix of $\alpha$.</p>
    <p>Using $V$ we can write the previous equations in matrix form:</p>
    <p>
      $$
      V a = p(\alpha) = v
      $$
    </p>
    <p>A simple calculation shows that $det(V) \neq 0$. We conclude then that $V$ is inversible.</p>
    <p>So,</p>
    <p>
      $$
      Pr(p(\alpha) = v) = Pr(Va = v) = Pr(a = V^{-1}v)
      $$
    </p>
    <p>Well, what is the probability $Pr(a = V^{-1}v)$? $V^{-1}v = u$ is just an arbitrary vector in $\mathbb{F}^k$. The probability of $a$ to be this exact vector is</p>
    <p>
      $$
      Pr \biggr[ a_0 = u_0, a_1 = u_1, ..., a_{k-1} = u_{k-1} \biggr]
      $$
    </p>
    <p>By definition, ${ a_i }_{i=0}^{k-1}$ are uniform and independent variables so we get that</p>
    <p>
      \begin{align*}
      Pr(p(\alpha) = v) =&#x26; Pr(Va = v) \\
      =&#x26; Pr(a = V^{-1}v) = Pr(a = u) = \prod_{i=0}^{k-1} \frac{1}{N} \\
      =&#x26; N^{k}
      \end{align*}
    </p>
    <p>As we wanted.</p>
  </body>
</html>
</div></main><footer><div class=" border-t-2 p-4 flex flex-row justify-center items-center space-x-4"><a href="https://github.com/tglanz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a href="https://il.linkedin.com/in/tal-glanzman"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"article":{"id":"probabilistic-method/k-wise-independence","filePath":"/home/runner/work/tglanz.github.io/tglanz.github.io/content/probabilistic-method/k-wise-independence.md","metadata":{"title":"k-Wise independence","description":null,"priority":0,"tags":["Probabilistic Method"],"categories":["Probabilistic Method"],"toc":false},"content":{"raw":"\n# k-wise independence\n\n**Definition** The $n$ random variables $X_1, X_2, ..., X_n$ are said to be **k-wise independent** iff any subset of $k$ random variables $X_{i_1}, X_{i_2}, ..., X_{i_k}$ consists of randomly independent variables, i.e.:\n\n$$\n    Pr(X_{i_1}, X_{i_2}, ..., X_{i_k}) = \\prod_{j=1}^k Pr(X_{i_j})\n$$\n\nCombinatorically, there are $n \\choose k$ different constraints.\n\nGiven $n$, for every $k \u003c n -1$ we can construct a set of $n$ random variables that are k-wise indpendent but not (k+1)-wise independent. Let's see a specific example:\n\n\n## Example, 2 but not 3 wise independence\n\nFor an example, we will show a group of 3 random variables that are 2-wise independent and are not 3-wise independent.\n\nLet $X, Y$ be uniformly random bits (i.e. they are random variables that can assume the values 0 or 1).\n\n\nThe truth table, with the probability of of the entry:\n\nPr(X, Y) | $X$ | $Y$\n:-:|:-:|:-:\n$\\frac{1}{4}$ |0|0\n$\\frac{1}{4}$ |0|1\n$\\frac{1}{4}$ |1|0\n$\\frac{1}{4}$ |1|1\n\nWe can see that $Pr(X, Y) = Pr(X)Pr(Y)$ so obsiously $X$ and $Y$ are independent.\n\nNow, let's define $Z := X \\oplus Y$ where $\\oplus$ is the XOR operation. We can write the truth table:\n\n$X$ | $Y$ | $Z$\n:-:|:-:|:-:\n0|0|0\n0|1|1\n1|0|1\n1|1|0\n\nLet's examine only $X$ and $Z$:\n\nPr(X, Z) | $X$ | $Z$\n:-:|:-:|:-:\n$\\frac{1}{4}$ |0|0\n$\\frac{1}{4}$ |0|1\n$\\frac{1}{4}$ |1|1\n$\\frac{1}{4}$ |1|0\n\nWe can see that $Pr(X, Z) = Pr(X)Pr(Z)$ so obsiously $X$ and $Z$ are independent.\n\nLet's examine only $Y$ and $Z$:\n\nPr(Y, Z) | $Y$ | $Z$\n:-:|:-:|:-:\n$\\frac{1}{4}$ |0|0\n$\\frac{1}{4}$ |1|1\n$\\frac{1}{4}$ |0|1\n$\\frac{1}{4}$ |1|0\n\nWe can see that $Pr(Y, Z) = Pr(Y)Pr(Z)$ so obsiously $Y$ and $Z$ are independent.\n\nAll in all, we saw that every pair from $X, Y$ and $Z$ are independent. But of course they are not 3-wise indpeendent because by the definition of $Z$ it is not random at all! $Z$ is defined as the XOR of $X$ and $Y$ and is not assuming random values. For example, $Pr(X=0, Y=0, Z=1) = 0$ rather than $\\frac{1}{2}^3$.\n\n## The construction of Vandermonde (VDM)\n\nThe construction of VDM is a construction of $N$ random variables that are uniformly distributed in $\\{ 0, 1, ..., N \\}$ that are k-wise independent.\n\nLet $\\mathbb{F}$ be a field such that $\\mathbb{|F|} = N$ and $N$ is a power of a primary number.\n\n\u003e We limited the genrality a bit by limiting $N$\n\nLet $a_0, a_1, ..., a_k \\in \\mathbb{F}$ be $k$ independent uniformly random variables. We define a unfiormly random polynomail $p(x)$ of degree $k$ by:\n\n$$\n    p(x) = \\sum_{i = 0}^{k-1} a_i x^i\n$$\n\nFor every $\\alpha \\in \\mathbb{F}$ the polynomial $p$ implicitly defines a random variable $p(\\alpha)$. \n\nWe will show that for every $k$ different elements $\\alpha_0, \\alpha_2, ..., \\alpha_{k-1} \\in \\mathbb{F}$ the $k$ random variables $P =  \\{ p(\\alpha_0), p(\\alpha_1), ..., p(\\alpha_{k-1}) \\}$ are independent and are uniformly distributed.\n\nOnce we showed this, we showed that the $N$ random variables which are implicitly defined from all the elements in the field $\\mathbb{F}$, are k-wise independent.\n\nTo show that $P$ are independent we need to show that for every $v_0, v_1, ..., v_{k-1} \\in \\mathbb{F}$ it holds true that\n\n$$\n  Pr(p(\\alpha_0) = v_0, p(\\alpha_1) = v_1, ..., p(\\alpha_{k-1}) = v_{k-1}) = Pr(p(\\alpha_0) = v_0) \\cdot Pr(p(\\alpha_1) = v_1) \\cdot \\cdot \\cdot Pr(p(\\alpha_{k-1}) = v_{k-1})\n$$\n\nOr in vector form:\n\n$$\n    Pr(p(\\alpha) = v) = \\prod_{i=0}^{k-1} Pr(p(\\alpha_i) = v_i)\n$$\n\nAnd to show that $P$ are uniformly distributed we need to show that\n\n$$\n    Pr(p(\\alpha) = v) = \\prod_{i=0}^{k-1} Pr(p(\\alpha_i) = v_i) = N^{-k}\n$$\n\nLet's get to work then. We start by expanding the expressions:\n\n\\begin{align*}\n\u0026p(\\alpha_0) = \\sum_{i=0}^{k-1} a_i \\alpha_0^i = v_0 \\\\\\\\\n\u0026p(\\alpha_1) = \\sum_{i=0}^{k-1} a_i \\alpha_1^i = v_1 \\\\\\\\\n\u0026... \\\\\\\\\n\u0026p(\\alpha_{k-1}) = \\sum_{i=0}^{k-1} a_i \\alpha_{k-1}^i = v_{k-1} \\\\\\\\\n\\end{align*}\n\nLet $V$ be the matrix:\n\n$$\nV = \n\\begin{pmatrix}\n\\alpha_0^0 \u0026 \\alpha_0^1 \u0026 ... \u0026 \\alpha_0^{k-1} \\\\\\\\\n\\alpha_1^0 \u0026 \\alpha_1^1 \u0026 ... \u0026 \\alpha_1^{k-1} \\\\\\\\\n\\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \\\\\\\\\n\\alpha_{k-1}^0 \u0026 \\alpha_{k-1}^1 \u0026 ... \u0026 \\alpha_{k-1}^{k-1} \\\\\\\\\n\\end{pmatrix}\n$$\n\nThis kind of matrix is well known as the **VDM** matrix of $\\alpha$.\n\nUsing $V$ we can write the previous equations in matrix form:\n\n$$\n    V a = p(\\alpha) = v\n$$\n\nA simple calculation shows that $det(V) \\neq 0$. We conclude then that $V$ is inversible.\n\nSo,\n\n$$\n    Pr(p(\\alpha) = v) = Pr(Va = v) = Pr(a = V^{-1}v)\n$$\n\nWell, what is the probability $Pr(a = V^{-1}v)$? $V^{-1}v = u$ is just an arbitrary vector in $\\mathbb{F}^k$. The probability of $a$ to be this exact vector is\n\n$$\n    Pr \\biggr[ a_0 = u_0, a_1 = u_1, ..., a_{k-1} = u_{k-1} \\biggr]\n$$\n\nBy definition, $\\{ a_i \\}_{i=0}^{k-1}$ are uniform and independent variables so we get that\n\n\\begin{align*}\n    Pr(p(\\alpha) = v) =\u0026 Pr(Va = v) \\\\\\\\\n    =\u0026 Pr(a = V^{-1}v) = Pr(a = u) = \\prod_{i=0}^{k-1} \\frac{1}{N} \\\\\\\\\n    =\u0026 N^{k}\n\\end{align*}\n\nAs we wanted.","html":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003ch1 id=\"k-wise-independence\"\u003ek-wise independence\u003c/h1\u003e\n    \u003cp\u003e\u003cstrong\u003eDefinition\u003c/strong\u003e The $n$ random variables $X_1, X_2, ..., X_n$ are said to be \u003cstrong\u003ek-wise independent\u003c/strong\u003e iff any subset of $k$ random variables $X_{i_1}, X_{i_2}, ..., X_{i_k}$ consists of randomly independent variables, i.e.:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(X_{i_1}, X_{i_2}, ..., X_{i_k}) = \\prod_{j=1}^k Pr(X_{i_j})\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eCombinatorically, there are $n \\choose k$ different constraints.\u003c/p\u003e\n    \u003cp\u003eGiven $n$, for every $k \u0026#x3C; n -1$ we can construct a set of $n$ random variables that are k-wise indpendent but not (k+1)-wise independent. Let's see a specific example:\u003c/p\u003e\n    \u003ch2 id=\"example-2-but-not-3-wise-independence\"\u003eExample, 2 but not 3 wise independence\u003c/h2\u003e\n    \u003cp\u003eFor an example, we will show a group of 3 random variables that are 2-wise independent and are not 3-wise independent.\u003c/p\u003e\n    \u003cp\u003eLet $X, Y$ be uniformly random bits (i.e. they are random variables that can assume the values 0 or 1).\u003c/p\u003e\n    \u003cp\u003eThe truth table, with the probability of of the entry:\u003c/p\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth align=\"center\"\u003ePr(X, Y)\u003c/th\u003e\n            \u003cth align=\"center\"\u003e$X$\u003c/th\u003e\n            \u003cth align=\"center\"\u003e$Y$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cp\u003eWe can see that $Pr(X, Y) = Pr(X)Pr(Y)$ so obsiously $X$ and $Y$ are independent.\u003c/p\u003e\n    \u003cp\u003eNow, let's define $Z := X \\oplus Y$ where $\\oplus$ is the XOR operation. We can write the truth table:\u003c/p\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth align=\"center\"\u003e$X$\u003c/th\u003e\n            \u003cth align=\"center\"\u003e$Y$\u003c/th\u003e\n            \u003cth align=\"center\"\u003e$Z$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cp\u003eLet's examine only $X$ and $Z$:\u003c/p\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth align=\"center\"\u003ePr(X, Z)\u003c/th\u003e\n            \u003cth align=\"center\"\u003e$X$\u003c/th\u003e\n            \u003cth align=\"center\"\u003e$Z$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cp\u003eWe can see that $Pr(X, Z) = Pr(X)Pr(Z)$ so obsiously $X$ and $Z$ are independent.\u003c/p\u003e\n    \u003cp\u003eLet's examine only $Y$ and $Z$:\u003c/p\u003e\n    \u003cdiv class=\"table-container\"\u003e\n      \u003ctable\u003e\n        \u003cthead\u003e\n          \u003ctr\u003e\n            \u003cth align=\"center\"\u003ePr(Y, Z)\u003c/th\u003e\n            \u003cth align=\"center\"\u003e$Y$\u003c/th\u003e\n            \u003cth align=\"center\"\u003e$Z$\u003c/th\u003e\n          \u003c/tr\u003e\n        \u003c/thead\u003e\n        \u003ctbody\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n          \u003c/tr\u003e\n          \u003ctr\u003e\n            \u003ctd align=\"center\"\u003e$\\frac{1}{4}$\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e1\u003c/td\u003e\n            \u003ctd align=\"center\"\u003e0\u003c/td\u003e\n          \u003c/tr\u003e\n        \u003c/tbody\u003e\n      \u003c/table\u003e\n    \u003c/div\u003e\n    \u003cp\u003eWe can see that $Pr(Y, Z) = Pr(Y)Pr(Z)$ so obsiously $Y$ and $Z$ are independent.\u003c/p\u003e\n    \u003cp\u003eAll in all, we saw that every pair from $X, Y$ and $Z$ are independent. But of course they are not 3-wise indpeendent because by the definition of $Z$ it is not random at all! $Z$ is defined as the XOR of $X$ and $Y$ and is not assuming random values. For example, $Pr(X=0, Y=0, Z=1) = 0$ rather than $\\frac{1}{2}^3$.\u003c/p\u003e\n    \u003ch2 id=\"the-construction-of-vandermonde-vdm\"\u003eThe construction of Vandermonde (VDM)\u003c/h2\u003e\n    \u003cp\u003eThe construction of VDM is a construction of $N$ random variables that are uniformly distributed in ${ 0, 1, ..., N }$ that are k-wise independent.\u003c/p\u003e\n    \u003cp\u003eLet $\\mathbb{F}$ be a field such that $\\mathbb{|F|} = N$ and $N$ is a power of a primary number.\u003c/p\u003e\n    \u003cblockquote\u003e\n      \u003cp\u003eWe limited the genrality a bit by limiting $N$\u003c/p\u003e\n    \u003c/blockquote\u003e\n    \u003cp\u003eLet $a_0, a_1, ..., a_k \\in \\mathbb{F}$ be $k$ independent uniformly random variables. We define a unfiormly random polynomail $p(x)$ of degree $k$ by:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      p(x) = \\sum_{i = 0}^{k-1} a_i x^i\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eFor every $\\alpha \\in \\mathbb{F}$ the polynomial $p$ implicitly defines a random variable $p(\\alpha)$.\u003c/p\u003e\n    \u003cp\u003eWe will show that for every $k$ different elements $\\alpha_0, \\alpha_2, ..., \\alpha_{k-1} \\in \\mathbb{F}$ the $k$ random variables $P = { p(\\alpha_0), p(\\alpha_1), ..., p(\\alpha_{k-1}) }$ are independent and are uniformly distributed.\u003c/p\u003e\n    \u003cp\u003eOnce we showed this, we showed that the $N$ random variables which are implicitly defined from all the elements in the field $\\mathbb{F}$, are k-wise independent.\u003c/p\u003e\n    \u003cp\u003eTo show that $P$ are independent we need to show that for every $v_0, v_1, ..., v_{k-1} \\in \\mathbb{F}$ it holds true that\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(p(\\alpha_0) = v_0, p(\\alpha_1) = v_1, ..., p(\\alpha_{k-1}) = v_{k-1}) = Pr(p(\\alpha_0) = v_0) \\cdot Pr(p(\\alpha_1) = v_1) \\cdot \\cdot \\cdot Pr(p(\\alpha_{k-1}) = v_{k-1})\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eOr in vector form:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(p(\\alpha) = v) = \\prod_{i=0}^{k-1} Pr(p(\\alpha_i) = v_i)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eAnd to show that $P$ are uniformly distributed we need to show that\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(p(\\alpha) = v) = \\prod_{i=0}^{k-1} Pr(p(\\alpha_i) = v_i) = N^{-k}\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eLet's get to work then. We start by expanding the expressions:\u003c/p\u003e\n    \u003cp\u003e\n      \\begin{align*}\n      \u0026#x26;p(\\alpha_0) = \\sum_{i=0}^{k-1} a_i \\alpha_0^i = v_0 \\\\\n      \u0026#x26;p(\\alpha_1) = \\sum_{i=0}^{k-1} a_i \\alpha_1^i = v_1 \\\\\n      \u0026#x26;... \\\\\n      \u0026#x26;p(\\alpha_{k-1}) = \\sum_{i=0}^{k-1} a_i \\alpha_{k-1}^i = v_{k-1} \\\\\n      \\end{align*}\n    \u003c/p\u003e\n    \u003cp\u003eLet $V$ be the matrix:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      V =\n      \\begin{pmatrix}\n      \\alpha_0^0 \u0026#x26; \\alpha_0^1 \u0026#x26; ... \u0026#x26; \\alpha_0^{k-1} \\\\\n      \\alpha_1^0 \u0026#x26; \\alpha_1^1 \u0026#x26; ... \u0026#x26; \\alpha_1^{k-1} \\\\\n      \\vdots \u0026#x26; \\vdots \u0026#x26; \\vdots \u0026#x26; \\vdots \\\\\n      \\alpha_{k-1}^0 \u0026#x26; \\alpha_{k-1}^1 \u0026#x26; ... \u0026#x26; \\alpha_{k-1}^{k-1} \\\\\n      \\end{pmatrix}\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eThis kind of matrix is well known as the \u003cstrong\u003eVDM\u003c/strong\u003e matrix of $\\alpha$.\u003c/p\u003e\n    \u003cp\u003eUsing $V$ we can write the previous equations in matrix form:\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      V a = p(\\alpha) = v\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eA simple calculation shows that $det(V) \\neq 0$. We conclude then that $V$ is inversible.\u003c/p\u003e\n    \u003cp\u003eSo,\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr(p(\\alpha) = v) = Pr(Va = v) = Pr(a = V^{-1}v)\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eWell, what is the probability $Pr(a = V^{-1}v)$? $V^{-1}v = u$ is just an arbitrary vector in $\\mathbb{F}^k$. The probability of $a$ to be this exact vector is\u003c/p\u003e\n    \u003cp\u003e\n      $$\n      Pr \\biggr[ a_0 = u_0, a_1 = u_1, ..., a_{k-1} = u_{k-1} \\biggr]\n      $$\n    \u003c/p\u003e\n    \u003cp\u003eBy definition, ${ a_i }_{i=0}^{k-1}$ are uniform and independent variables so we get that\u003c/p\u003e\n    \u003cp\u003e\n      \\begin{align*}\n      Pr(p(\\alpha) = v) =\u0026#x26; Pr(Va = v) \\\\\n      =\u0026#x26; Pr(a = V^{-1}v) = Pr(a = u) = \\prod_{i=0}^{k-1} \\frac{1}{N} \\\\\n      =\u0026#x26; N^{k}\n      \\end{align*}\n    \u003c/p\u003e\n    \u003cp\u003eAs we wanted.\u003c/p\u003e\n  \u003c/body\u003e\n\u003c/html\u003e\n"}}},"__N_SSG":true},"page":"/_articles/[...articleId]","query":{"articleId":["probabilistic-method","k-wise-independence"]},"buildId":"2UtthYsk4Izfh9PIWGXxM","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>